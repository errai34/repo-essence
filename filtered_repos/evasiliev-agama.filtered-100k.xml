<?xml version="1.0" ?>
<compressed_repository total_tokens="99680">
  <file_summary>
    
This section contains a summary of this file.


    <purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>
    


    <file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>
    


    <usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>
    


    <notes>
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.
</notes>
    


    <additional_info>

For more information about Repomix, visit: https://github.com/yamadashy/repomix
</additional_info>
    


  </file_summary>
  <repository_structure>
data/
  BT08.ini
  Cautun20.ini
  Irrgang13.ini
  McMillan11_best.ini
  McMillan11_convenient.ini
  McMillan17.ini
  MWPotential2014.ini
  MWPotential2014galpy.ini
  phaseflow_bahcallwolfcusp.ini
  phaseflow_corecollapse.ini
  Piffl14.ini
  PriceWhelan17.ini
  PriceWhelan22.ini
  raga_corecollapse.ini
  schwarzschild_axisym.ini
  SCM_MW.ini
  SCM.ini
  SCM3.ini
doc/
  readme_raga.tex
  reference.tex
py/
  agamacolormaps.py
  alltest.py
  example_actions_nbody.py
  example_adiabatic_contraction.py
  example_amuse_raga.py
  example_amuse.py
  example_basis_set.py
  example_deprojection.py
  example_df_fit.py
  example_forstand.py
  example_gala.py
  example_galpy.py
  example_gizmo_snapshot.py
  example_lmc_mw_interaction.py
  example_mw_bar_potential.py
  example_mw_nsd.py
  example_mw_potential_hunter24.py
  example_nbody_simulation_arepo.param
  example_nbody_simulation_arepo.patch
  example_nbody_simulation_gadget4.param
  example_nbody_simulation_gadget4.patch
  example_nbody_simulation.py
  example_poincare.py
  example_schwarzschild_flattened_rotating.py
  example_schwarzschild_triaxial.py
  example_self_consistent_model_flattened.py
  example_self_consistent_model_mw.py
  example_self_consistent_model_simple.py
  example_self_consistent_model.py
  example_self_consistent_model3.py
  example_smoothing_spline.py
  example_spiral.py
  example_target.py
  example_tidal_stream.py
  example_time_dependent_potential.py
  example_torus.py
  example_vdf_fit_bspline.py
  gc_modelparamsE.py
  gc_modelparamsJ.py
  gc_resample.py
  gc_runfit.py
  interface_amuse.py
  measureshape.py
  nemofile.py
  pygama.py
  schwarzlib.py
  schwarzschild.py
  test_actions.py
  test_amuse.py
  test_batch_computations.py
  test_compositions.py
  test_coordinates.py
  test_math.py
  test_orbit.py
  test_self_consistent_model.py
  test_spline.py
  test_threads.py
  test_user_profiles.py
  tutorial_potential_orbits.ipynb
  tutorial_streams.ipynb
src/
  torus/
    CHB.cc
    CHB.h
    Constants.h
    Fit.cc
    Fit.h
    Fit2.cc
    GeneratingFunction.cc
    GeneratingFunction.h
    Maps.h
    Orb.cc
    Orb.h
    Pi.h
    PJM_utils.h
    PJMNum.cc
    PJMNum.h
    Point_ClosedOrbitCheby.cc
    Point_ClosedOrbitCheby.h
    Point_None.cc
    Point_None.h
    Potential.h
    Torus.cc
    Torus.h
    Toy_Isochrone.cc
    Toy_Isochrone.h
    Types.h
    Units.h
    WD_FreeMemory.h
    WD_Matrix.h
    WD_Numerics.cc
    WD_Numerics.h
    WD_Numerics.templates
    WD_Vector.h
  actions_base.h
  actions_factory.cpp
  actions_factory.h
  actions_focal_distance_finder.cpp
  actions_focal_distance_finder.h
  actions_isochrone.cpp
  actions_isochrone.h
  actions_spherical.cpp
  actions_spherical.h
  actions_staeckel.cpp
  actions_staeckel.h
  actions_torus.cpp
  actions_torus.h
  coord.cpp
  coord.h
  cubature.cpp
  cubature.h
  debug_utils.h
  df_base.cpp
  df_base.h
  df_disk.cpp
  df_disk.h
  df_factory.cpp
  df_factory.h
  df_halo.cpp
  df_halo.h
  df_spherical.cpp
  df_spherical.h
  galaxymodel_base.cpp
  galaxymodel_base.h
  galaxymodel_densitygrid.cpp
  galaxymodel_densitygrid.h
  galaxymodel_fokkerplanck.cpp
  galaxymodel_fokkerplanck.h
  galaxymodel_jeans.cpp
  galaxymodel_jeans.h
  galaxymodel_losvd.cpp
  galaxymodel_losvd.h
  galaxymodel_selfconsistent.cpp
  galaxymodel_selfconsistent.h
  galaxymodel_spherical.cpp
  galaxymodel_spherical.h
  galaxymodel_target.h
  galaxymodel_velocitysampler.cpp
  galaxymodel_velocitysampler.h
  interface_amuse.cpp
  interface_c.cpp
  interface_c.h
  interface_fortran.cpp
  interface_nemo.cpp
  interface_python.cpp
  math_base.h
  math_core.cpp
  math_core.h
  math_fit.cpp
  math_fit.h
  math_gausshermite.cpp
  math_gausshermite.h
  math_geometry.cpp
  math_geometry.h
  math_glquadrature.h
  math_linalg.cpp
  math_linalg.h
  math_ode.cpp
  math_ode.h
  math_optimization.cpp
  math_optimization.h
  math_random.cpp
  math_random.h
  math_sample.cpp
  math_sample.h
  math_simple_cubature.h
  math_specfunc.cpp
  math_specfunc.h
  math_sphharm.cpp
  math_sphharm.h
  math_spline.cpp
  math_spline.h
  orbit_variational.cpp
  orbit_variational.h
  orbit.cpp
  orbit.h
  particles_base.h
  particles_io.cpp
  particles_io.h
  potential_analytic.cpp
  potential_analytic.h
  potential_base.cpp
  potential_base.h
  potential_composite.cpp
  potential_composite.h
  potential_cylspline.cpp
  potential_cylspline.h
  potential_dehnen.cpp
  potential_dehnen.h
  potential_disk.cpp
  potential_disk.h
  potential_factory.cpp
  potential_factory.h
  potential_ferrers.cpp
  potential_ferrers.h
  potential_king.cpp
  potential_king.h
  potential_multipole.cpp
  potential_multipole.h
  potential_perfect_ellipsoid.cpp
  potential_perfect_ellipsoid.h
  potential_spheroid.cpp
  potential_spheroid.h
  potential_utils.cpp
  potential_utils.h
  raga_base.h
  raga_binary.cpp
  raga_binary.h
  raga_core.cpp
  raga_core.h
  raga_losscone.cpp
  raga_losscone.h
  raga_potential.cpp
  raga_potential.h
  raga_relaxation.cpp
  raga_relaxation.h
  raga_trajectory.cpp
  raga_trajectory.h
  shared_ptr.h
  smart.h
  units.h
  utils_config.cpp
  utils_config.h
  utils.cpp
  utils.h
tests/
  example_actions_nbody.cpp
  example_df_fit.cpp
  example_doublepowerlaw.cpp
  example_self_consistent_model_mw.cpp
  example_self_consistent_model.cpp
  mkspherical.cpp
  phaseflow.cpp
  raga.cpp
  test_action_finder.cpp
  test_actions_isochrone.cpp
  test_actions_spherical.cpp
  test_actions_staeckel.cpp
  test_actions_torus.cpp
  test_coord.cpp
  test_density_grid.cpp
  test_df_halo.cpp
  test_df_spherical.cpp
  test_fortran.f
  test_galaxymodel.cpp
  test_losvd.cpp
  test_math_core.cpp
  test_math_linalg.cpp
  test_math_spline.cpp
  test_orbit_integr.cpp
  test_orbit_variational.cpp
  test_potential_expansions.cpp
  test_potential_modifiers.cpp
  test_potentials.cpp
  test_units.cpp
  test_utils.cpp
__init__.py
.gitignore
Doxyfile
INSTALL
LICENSE
Makefile
Makefile.list
Makefile.local.template
Makefile.msvc
NEWS
README
setup.py
</repository_structure>
  <repository_files>
    <file path="data/schwarzschild_axisym.ini">
# Example input file for the schwarzschild.py program
# This parameter file constructs a three-component disk-bulge-halo system as in Vasiliev&amp;Athanassoula(2015)

# first we list density ingredients (each section name should start with 'density' and have no spaces)
[Density_bulge]
type=Sersic
sersicIndex=2
mass=0.25
scaleRadius=0.215
axisratioz=0.8

[Density_disk]
type=Disk
mass=1
scaleRadius=1
scaleHeight=-0.0625

[Density_halo]
type=Spheroid
mass=20
gamma=1
beta=3
scaleRadius=5
outerCutoffRadius=55
cutoffStrength=2.5

# next we define two potential solvers - disky density components are delegated to CylSpline,
# and spheroidal components - to Multipole.
# section names should start with 'Potential' and are otherwise arbitrary;
# the total potential will contain all such components
# (e.g. one could add a central massive black hole by defining an extra Plummer potential with scaleRadius=0)

[Potential_disk]
# list the section names of corresponding density components
density=density_Disk
# potential solver type
type=cylspline
# number of azumuthal harmonics - 0 means axisymmetry
mmax=0
# grid parameters
gridsizer=20
gridsizez=25
rmin=0.1
rmax=10
zmin=0.02
zmax=10

[potential_spher]
density=density_bulge, density_halo
type=multipole
lmax=2
gridSizeR=30

# now comes the list of separate components of the Schwarzschild model.
# each section should start with 'Component', and corresponds to a complete orbit-based model
# (definition of the density profile and its discretization, kinematic constraints,
# initial conditions for the orbit library, orbit integration and storage parameters,
# and finally the parameters for exporting an N-body model).
# All models are constructed in the same total potential, but the density profiles
# may be selected at will (e.g., be a combination of one or more density components defined above,
# even if these components do not contribute to the potential).

[Component_bulge]
# list of density models (section names) that define the density profile of this component:
# here we only have one per component, but in general there could be more than one comma-separated names
density=Density_bulge

# subsection: density constraints
# type of the density discretization model
type=DensityClassicLinear
# radial grid
gridr=numpy.linspace(0.04, 1, 30)
# number of subdivision lines per each of three panes in one radial shell
stripsPerPane=2
# flattening factor of the spatial grid
axisRatioZ=0.8

# subsection: kinematic constraints
# number of radial points in kinematic grid
kinemgrid=numpy.linspace(0.05, 0.5, 10)
# degree of B-spline basis function for recording the density-weighted velocity dispersions
# (0 to 3: zero means histograms, 3 is for cubic splines)
kinemDegree=2
# constraint for the velocity anisotropy in the solution (if omitted, it will not be constrained)
beta=0

# section: orbit library params
# integration time measured in orbital periods (actual time is different for each orbit)
intTime=100
# number of orbits in this components - should generally be larger than the number of constraints
# by at least a factor of few, maybe even ten
numOrbits=5000

# section: N-body model params
# number of particles drawn from this component
nbody=40000


[Component_disk]
density=density_disk

# density constraints
type=DensityCylindricalLinear
gridR=agama.nonuniformGrid(20, 0.2, 5)
gridZ=agama.nonuniformGrid(20, 0.02, 0.5)
mmax=0

# orbit library params
numOrbits=20000
# parameters of initial condition generation that also define the method for assigning velocities:
# if neither icbeta nor ickappa is specified, this means Eddington (isotropic velocities drawn from a DF);
# if icbeta is given, this means spherical Jeans model with a constant anisotropy coefficient;
# if both icbeta and ickappa are given, this means axisymmetric Jeans Anisotropic Model.
icbeta=0.6
ickappa=1.0
intTime=100
# note that for this component we do not constrain the velocity in the solution (beta=...),
# only specify the parameters of the initial conditions generator

# N-body output
nbody=160000


[Component_halo]
density=Density_halo
# density constraints
type=DensityClassicLinear
gridR=agama.nonuniformGrid(50, 0.2, 80.0)
stripsPerPane=2
# kinematic constraints
kinemgrid=agama.nonuniformGrid(20, 0.4, 80.0)
kinemDegree=2
beta=0
# orbit library params
intTime=100
numOrbits=25000
# N-body output
nbody=800000
</file>
    <file path="py/alltest.py">
#!/usr/bin/python
def alltest():
    import sys,os,glob,subprocess,time
    exe = glob.glob(&quot;../exe/test_*.exe&quot;)
    py  = [ (sys.executable, f) for f in glob.glob(&quot;../py/test_*.py&quot;) ]
    allprogs = exe + py
    passed = 0
    failed = 0
    skipped= 0
    unknown= 0
    for prog in allprogs:
        progname = os.path.basename(prog[1] if isinstance(prog, tuple) else prog)
        sys.stdout.write(progname)
        sys.stdout.flush()
        filler = ' ' * (32-len(progname))
        try:
            tstart = time.time()
            proc = subprocess.Popen(prog, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
            result = proc.communicate()[0].decode()
            elapsed = filler + &quot;%5.1f s, &quot; % (time.time()-tstart)
            if &quot;ALL TESTS PASSED&quot; in result:
                print(elapsed+&quot;OK&quot;)
                passed+=1
            elif &quot;SOME TESTS FAILED&quot; in result or &quot;FAILED TO IMPORT&quot; in result:
                print(elapsed+&quot;FAILED&quot;)
                failed+=1
            elif &quot;SKIPPED DUE TO&quot; in result:
                print(elapsed+&quot;SKIPPED&quot;)
                skipped+=1
            else:
                print(elapsed+&quot;UNKNOWN&quot;)  # not a failure, nor a success
                unknown+=1
        except Exception as e:
            print(filler + &quot;NOT STARTED: &quot;+str(e))
            failed+=1
    print(str(passed)+&quot; TESTS PASSED&quot; + \
        ( &quot;, &quot;+str(failed)+&quot; FAILED&quot; if failed&gt;0 else &quot;, NONE FAILED&quot;) +
        ( &quot;, &quot;+str(skipped)+&quot; SKIPPED&quot; if skipped&gt;0 else &quot;&quot;) +
        ( &quot;, &quot;+str(unknown)+&quot; UNKNOWN&quot; if unknown&gt;0 else &quot;&quot;) )
    return failed==0

if __name__ == '__main__':
    alltest()
</file>
    <file path="py/example_actions_nbody.py">
#!/usr/bin/python
&quot;&quot;&quot;
    This example demonstrates the use of action finder (Staeckel approximation)
    to compute actions for particles from an N-body simulation.
    The N-body system consists of a disk and a halo,
    the two components being stored in separate text files.
    They are not provided in the distribution, but could be created by running
    example_self_consistent_model.py
    The potential is computed from the snapshot itself, by creating a suitable
    potential expansion for each component: Multipole for the halo and CylSpline
    for the disk. This actually takes most of the time. We save the constructed
    potentials to text files, and on the subsequent launches of this program
    they are loaded from these files, speeding up the initialization.
    Then we compute actions for all particles from the disk component,
    and store them in a text file.

    An equivalent example in C++ is located in tests folder.
&quot;&quot;&quot;
import agama, numpy
try: from time import process_time as clock  # Python 3.3+
except ImportError: from time import clock   # older Python

#1. set units (in Msun, Kpc, km/s)
agama.setUnits(mass=1, length=1, velocity=1)

#2. get in N-body snapshots: columns 0 to 2 are position, 3 to 5 are velocity, 6 is mass
tbegin = clock()
try:
    diskParticles = numpy.loadtxt(&quot;model_stars_final&quot;)
    haloParticles = numpy.loadtxt(&quot;model_dm_final&quot;)
except:
    exit(&quot;Input snapshot files are not available; &quot; \
        &quot;you may create them by running example_self_consistent_model.py&quot;)

print(&quot;%g s to load %d disk particles (total mass=%g Msun) &quot; \
    &quot;and %d halo particles (total mass=%g Msun)&quot; % \
    ( clock()-tbegin, \
    diskParticles.shape[0], numpy.sum(diskParticles[:,6]), \
    haloParticles.shape[0], numpy.sum(haloParticles[:,6]) ) )


#3. create an axisymmetric potential from these snapshots

try:
    #3a. try to load potentials from previously stored text files instead of computing them
    diskPot = agama.Potential(&quot;model_stars_final.ini&quot;)
    haloPot = agama.Potential(&quot;model_dm_final.ini&quot;)

except:
    # 3b: these files don't exist on the first run, so we have to create the potentials
    tbegin  = clock()
    haloPot = agama.Potential( \
        type=&quot;Multipole&quot;, particles=(haloParticles[:,0:3], haloParticles[:,6]), \
        symmetry='a', gridsizeR=20, lmax=2)
    print(&quot;%f s to init %s potential for the halo; value at origin=%f (km/s)^2&quot; % \
        ((clock()-tbegin), haloPot, haloPot.potential(0,0,0)))
    tbegin  = clock()
    # manually specify the spatial grid for the disk potential,
    # although one may rely on the automatic choice of these parameters (as we did for the halo)
    diskPot = agama.Potential( \
        type=&quot;CylSpline&quot;, particles=(diskParticles[:,0:3], diskParticles[:,6]), \
        gridsizer=20, gridsizez=20, symmetry='a', Rmin=0.2, Rmax=100, Zmin=0.05, Zmax=50)
    print(&quot;%f s to init %s potential for the disk; value at origin=%f (km/s)^2&quot; % \
        ((clock()-tbegin), diskPot, diskPot.potential(0,0,0)))

    # save the potentials into text files; on the next call may load them instead of re-computing
    diskPot.export(&quot;model_stars_final.ini&quot;)
    haloPot.export(&quot;model_dm_final.ini&quot;)

#3c. combine the two potentials into a single composite one
totalPot  = agama.Potential(diskPot, haloPot)

#4. compute actions for disk particles
tbegin    = clock()
actFinder = agama.ActionFinder(totalPot)
print(&quot;%f s to init action finder&quot; % (clock()-tbegin))

tbegin    = clock()
actions   = actFinder(diskParticles[:,0:6])
print(&quot;%f s to compute actions for %i particles&quot; % (clock()-tbegin,  diskParticles.shape[0]))

#5. write out data
Rz        = numpy.vstack(
    ( numpy.sqrt(diskParticles[:,0]**2 + diskParticles[:,1]**2), diskParticles[:,2] ) ).T
energy    = (totalPot.potential(diskParticles[:,0:3]) + \
    0.5 * numpy.sum(diskParticles[:,3:6]**2, axis=1) ).reshape(-1,1)
numpy.savetxt( &quot;disk_actions.txt&quot;, numpy.hstack((Rz, actions, energy)), \
    header=&quot;R[Kpc]\tz[Kpc]\tJ_r[Kpc*km/s]\tJ_z[Kpc*km/s]\tJ_phi[Kpc*km/s]\tE[(km/s)^2]&quot;, \
    fmt=&quot;%.6g&quot;, delimiter=&quot;\t&quot; )
</file>
    <file path="py/example_adiabatic_contraction.py">
'''
Module for performing adiabatic contraction of dark matter (DM) halo due to baryons.
Two methods are implemented:
(1) `true' adiabatic contraction relies on the invariance of actions under slow changes of potential:
    first the DM distribution function corresponding to the given density/potential profile is constructed,
    then the DM-only potential is replaced with the sum of DM+baryonic potentials,
    and the DM density profile generated by the DF in the new potential is computed.
(2) `approximate' prescription for contraction, which uses empirical correction formula calibrated
    against N-body simulations to transform the initial DM density into the contracted one
    without explicitly working with the DF.
    A Milky Way potential corresponding to an adiabatically contracted NFW halo is provided in
    ../data/Cautun20.ini

The routine `contraction()' performs either of the two procedures for the given DM and baryon profiles.
When run as the main program, this script uses the above routine to illustrate both methods.

Authors: Tom Callingham, Marius Cautun, Tadafumi Matsuno, Eugene Vasiliev
Date: Nov 2021
'''
import numpy, agama

def contraction(pot_dm, pot_bar, method='C20', beta_dm=0.0, rmin=1e-2, rmax=1e4):
    '''
    Construct the contracted halo density profile for the given
    initial halo density and the baryonic density profiles.
    Arguments:
      pot_dm:  initial halo potential (assumed to be spherical!).
      pot_bar: potential of baryons (a spherical approximation to it will be used even if it was not spherical).
      method:  choice between two alternative approaches:
        'C20'  (default) uses the approximate correction procedure from Cautun+2020;
        'adiabatic'  uses the invariance of actions in conjunction with an internally constructed halo DF.
      beta_dm: anisotropy coefficient for the halo DF
        (only used with the adiabatic method, must be between -0.5 and 1, default 0 means isotropy).
      rmin (1e-2), rmax(1e4): min/max grid radii for representing the contracted density profile
        (default values are suitable for Milky Way-sized galaxies if expressed in kpc).
    Return:
      the spherically symmetric contracted halo potential.
    '''
    gridr = numpy.logspace(numpy.log10(rmin), numpy.log10(rmax), 101)
    xyz = numpy.column_stack((gridr, gridr*0, gridr*0))
    if method == 'adiabatic':
        # create a spherical DF for the DM-only potential/density pair with a constant anisotropy coefficient beta
        df_dm = agama.DistributionFunction(type='QuasiSpherical', potential=pot_dm, beta0=beta_dm)
        # create a sphericalized total potential (DM+baryons)
        pot_total_sph = agama.Potential(type='multipole', potential=agama.Potential(pot_dm, pot_bar),
            lmax=0, rmin=0.1*rmin, rmax=10*rmax)
        # compute the density generated by the DF in the new total potential at the radial grid
        dens_contracted = agama.GalaxyModel(pot_total_sph, df_dm).moments(xyz, dens=True, vel=False, vel2=False)
    elif method == 'C20':
        # use the differential (d/dr) form of Eq. (11) from Cautun et al (2020) to approximate the effect of contraction
        cumul_mass_dm = pot_dm. enclosedMass(gridr)  # cumulative mass profile of DM
        cumul_mass_bar= pot_bar.enclosedMass(gridr)  # same for baryons (sphericalized)
        valid_r = numpy.hstack([True, cumul_mass_bar[:-1] &lt; cumul_mass_bar[1:]*0.999])  # use only those radii where mass keeps increasing
        sph_dens_bar  = agama.Density(cumulmass=numpy.column_stack((gridr[valid_r], cumul_mass_bar[valid_r])))  # sphericalized baryon density profile
        f_bar = 0.157  # cosmic baryon fraction; the formula is calibrated against simulations only for this value
        eta_bar = cumul_mass_bar / cumul_mass_dm * (1.-f_bar) / f_bar  # the last two terms account for transforming the DM mass into the corresponding baryonic mass in dark-matter-only simulations
        first_factor = 0.45 + 0.41 * (eta_bar + 0.98)**0.53
        dens_dm_orig = pot_dm.density(xyz)
        temp         = sph_dens_bar.density(xyz) - eta_bar * dens_dm_orig * f_bar / (1.-f_bar)
        const_term   = 0.41 * 0.53 * (eta_bar + 0.98)**(0.53-1.) * (1.-f_bar) / f_bar * temp
        dens_contracted = dens_dm_orig * first_factor + const_term  # new values of DM density at the radial grid
    else:
        raise RuntimeError('Invalid choice of method')

    # create a cubic spline interpolator in log-log space
    valid_r = dens_contracted&gt;0  # make sure the input for log-spline is positive
    dens_contracted_interp = agama.Spline(numpy.log(gridr[valid_r]), numpy.log(dens_contracted[valid_r]), reg=True)
    # convert the grid-based density profile into a full-fledged potential
    contracted_pot = agama.Potential(type=&quot;Multipole&quot;, symmetry=&quot;spherical&quot;, rmin=rmin, rmax=rmax,
        density=lambda xyz: numpy.exp(dens_contracted_interp(numpy.log(numpy.sum(xyz**2, axis=1))*0.5)) )
    return contracted_pot


if __name__ == '__main__':
    # example of usage of the above function for the Milky Way potential from Cautun+ 2020
    agama.setUnits(mass=1., length=1., velocity=1.)  # Msun, kpc, km/s
    # DM halo
    fb = 4.825 / 30.7  # Planck 1 baryon fraction
    m200 = 0.969e12  # the DM halo mass
    conc = 8.76
    NFW_rho0 = 3486926.735447284
    NFW_rs = 25.20684733101539
    # Note subtletly in Cautun20 NFW definition, scaled overdensity changes from paper value!

    # bulge
    params_bulge = dict(type='Spheroid',
        densityNorm=1.03e11,
        axisRatioZ=0.5,
        gamma=0,
        beta=1.8,
        scaleRadius=0.075,
        outerCutoffRadius=2.1)
    # stellar disks
    params_thin_disk = dict(type='Disk',
        surfaceDensity=7.31e8,
        scaleRadius=2.63,
        scaleHeight=0.3)
    params_thick_disk = dict(type='Disk',
        surfaceDensity=1.01e8,
        scaleRadius=3.8,
        scaleHeight=0.9)
    # gas disks
    params_HI_disk = dict(type='disk',
        surfaceDensity=5.3e7,
        scaleRadius=7.0,
        scaleHeight=0.085,
        innerCutoffRadius=4.0)
    params_H2_disk = dict(type='disk',
        surfaceDensity=2.2e9,
        scaleRadius=1.5,
        scaleHeight=0.045,
        innerCutoffRadius=12.0)
    # CGM
    params_CGM = dict(type='Spheroid',
        densityNorm=7.615e2,
        gamma=1.46,
        beta=1.46,
        scaleRadius=219,
        outerCutoffRadius=2*219,
        cutoffStrength=2)
    # uncontracted DM halo
    params_halo = dict(type='Spheroid',
        densityNorm=3.487e6,
        gamma=1,
        beta=3,
        scaleRadius=25.2)

    pot_baryon = agama.Potential(params_bulge, params_thin_disk, params_thick_disk, params_HI_disk, params_H2_disk, params_CGM)
    pot_dm_init= agama.Potential(params_halo)
    # several variants of contracted halo potentials
    pot_dm_C20 = contraction(pot_dm_init, pot_baryon, method='C20')
    pot_dm_iso = contraction(pot_dm_init, pot_baryon, method='adiabatic', beta_dm= 0.0)
    pot_dm_rad = contraction(pot_dm_init, pot_baryon, method='adiabatic', beta_dm=+0.5)
    pot_dm_tan = contraction(pot_dm_init, pot_baryon, method='adiabatic', beta_dm=-0.5)
    # plot profiles
    import numpy, matplotlib.pyplot as plt
    r = numpy.logspace(-2,3,101)
    xyz = numpy.column_stack((r, r*0, r*0))
    ax = plt.subplots(1, 2, figsize=(10,5))[1]
    pots  = [pot_baryon, pot_dm_init, pot_dm_C20, pot_dm_iso, pot_dm_rad, pot_dm_tan]
    names = ['baryons', 'initial halo', 'contracted Cautun+2020', 'contracted isotropic', 'contracted radial', 'contracted tangential']
    colors= ['k', 'c', 'g', 'm', 'r', 'b']
    dashes= [[1000,1], [2,2], [5,2], [4,1,1,1], [7,3,2,3], [2,1,1,1]]
    for pot, name, color, dash in zip(pots, names, colors, dashes):
        ax[0].plot(r, pot.density(xyz),  label=name, color=color, dashes=dash)
        ax[1].plot(r, (-r*pot.force(xyz)[:,0])**0.5, color=color, dashes=dash)
    ax[0].set_xscale('log')
    ax[0].set_yscale('log')
    ax[1].set_xscale('log')
    ax[0].legend(loc='lower left', frameon=False)
    ax[0].set_xlabel('R [kpc]')
    ax[0].set_ylabel(r'$\rho\; \rm[M_\odot/kpc^3]$', fontsize=15)
    ax[1].set_xlabel('R [kpc]')
    ax[1].set_ylabel(r'$v_{\rm circ}\; \rm[km/s]$', fontsize=15)
    plt.tight_layout()
    plt.savefig('example_adiabatic_contraction.pdf')
    plt.show()
</file>
    <file path="py/example_amuse_raga.py">
&quot;&quot;&quot;
Illustration of the use of Raga stellar-dynamical code from the AMUSE framework.

We create a Plummer model with a spectrum of masses, and follow the coupled
dynamical and stellar evolution represented by Raga and SeBa, respectively.
&quot;&quot;&quot;

useRaga = True or False   # choose whether to use Raga or a conventional N-body code (much slower!)

import numpy, matplotlib.pyplot as plt
from amuse.lab import *
from amuse.community.agama.interface import Agama

if __name__ in ('__main__', '__plot__'):

    # set up parameters:
    numpy.random.seed(42)  # make experiments repeatable
    N         = 16384
    Rcluster  = 1. | units.parsec
    #masses   = new_kroupa_mass_distribution(N)
    masses    = new_powerlaw_mass_distribution(N, mass_min=0.4|units.MSun, mass_max=20|units.MSun, alpha=-2.5)
    Mcluster  = masses.sum()
    converter = nbody_system.nbody_to_si(Mcluster, Rcluster)
    particles = new_plummer_model(N, converter)
    particles.mass = masses
    stellarevol = SeBa(redirection='null')
    stellarevol.particles.add_particles(particles)
    particles.radius = stellarevol.particles.radius
    if useRaga:
        cluster = Agama(converter, redirection='none', number_of_workers=8,
        updatepotential=True, coulombLog=5.0, symmetry='s',
        filelog='raga_multimass_plummer.log', fileoutputpotential='raga_multimass_plummer.pot',
        fileoutputrelaxation='raga_multimass_plummer.rel', fileoutput='raga_multimass_plummer.out', fileoutputformat='nemo',
        outputinterval=1. | units.Myr,
        numSamplesPerEpisode=10 )#, particles=particles)
    else:
        #cluster = ph4(converter, channel_type='sockets', number_of_workers=8, parameters=[(&quot;epsilon_squared&quot;, (0.01 | units.parsec)**2)])
        cluster = ph4(converter, channel_type='sockets', mode='gpu', parameters=[(&quot;epsilon_squared&quot;, (0.01 | units.parsec)**2)])
        #cluster = Gadget2(converter, channel_type='sockets', number_of_workers=8, parameters=[(&quot;epsilon_squared&quot;, (0.01 | units.parsec)**2)], redirection='null')
        #cluster = Bonsai(converter, channel_type='sockets', parameters=[(&quot;epsilon_squared&quot;, (0.01 | units.parsec)**2)], redirection='null')
    cluster.particles.add_particles(particles)

    channel_from_stellar_to_gravity   = stellarevol.particles.new_channel_to(cluster.particles, attributes=['mass'])
    channel_from_gravity_to_framework = cluster.particles.new_channel_to(particles)

    # evolve and make plots
    times = numpy.linspace(0,20,21) | units.Myr

    print(&quot;Start evolution&quot;)
    for i,t in enumerate(times):
        print(&quot;Evolve gravity&quot;)
        cluster.evolve_model(t)
        print(&quot;Evolve stars&quot;)
        stellarevol.evolve_model(t)
        channel_from_stellar_to_gravity.copy()
        channel_from_gravity_to_framework.copy()

        print(&quot;Evolved the system to time %.1f Myr&quot; % t.value_in(units.Myr) +
            &quot;, total mass=%.1f Msun&quot;                % particles.mass.sum().value_in(units.MSun) +
            &quot;, Ekin=%.4g Msun*(km/s)^2&quot;             % cluster.kinetic_energy.value_in(units.MSun*units.kms**2) + 
            &quot;, Etot=%.4g Msun*(km/s)^2&quot;             % (cluster.potential_energy + cluster.kinetic_energy).value_in(units.MSun*units.kms**2))
        x=particles.x.value_in(units.parsec)
        y=particles.y.value_in(units.parsec)
        plt.figure(figsize=(6,6))
        plt.scatter(x, y, marker='.', s=5*particles.mass.value_in(units.MSun)**0.5, edgecolors=None, c='k', alpha=0.2)
        plt.xlim(-5,5)
        plt.ylim(-5,5)
        plt.title(&quot;t=%.1f Myr&quot; % t.value_in(units.Myr))
        basename = 'example_amuse_raga' if useRaga else 'example_amuse_nbody'
        plt.savefig('%s_%i.png' % (basename, i))
        plt.close()

    cluster.stop()
    stellarevol.stop()
</file>
    <file path="py/example_amuse.py">
&quot;&quot;&quot;
Illustration of the Agama plugin for the AMUSE framework.

Evolves a cluster in the potention of the galactic center,
using the bridge integrator to couple different codes
(a static potential of the galaxy provided by the instance of Agama potential,
and the evolving N-body system representing a stellar cluster on the orbit in the galaxy).
&quot;&quot;&quot;

import numpy
from amuse.units import units
from amuse.units import constants
from amuse.units import nbody_system
from amuse.ext.bridge import bridge
from amuse.community.hermite0.interface import Hermite
from amuse.community.agama.interface import Agama
from matplotlib import pyplot
from amuse.ic.kingmodel import new_king_model

if __name__ in ('__main__', '__plot__'):

    # set up parameters:
    N = 100
    W0 = 3
    Rinit = 50. | units.parsec
    timestep = 0.01 | units.Myr
    Mcluster = 4.e4 | units.MSun
    Rcluster = 0.7 | units.parsec
    converter = nbody_system.nbody_to_si(Mcluster,Rcluster)

    # create a globular cluster model
    particles = new_king_model(N, W0, convert_nbody=converter)
    particles.radius = 0.0| units.parsec
    cluster = Hermite(converter, parameters=[(&quot;epsilon_squared&quot;, (0.01 | units.parsec)**2)], redirection='null', channel_type='sockets')

    # create the external potential of the Galaxy
    galaxy = Agama(converter, type=&quot;Dehnen&quot;, gamma=1.8, \
        rscale=1000.| units.parsec, mass=1.6e10 | units.MSun, channel_type='sockets')

    # shift the cluster to an orbit around Galactic center
    acc,_,_ = galaxy.get_gravity_at_point(0|units.kpc, Rinit, 0|units.kpc, 0|units.kpc)
    vcirc = (-acc * Rinit)**0.5
    print(&quot;Vcirc=%f km/s&quot; % vcirc.value_in(units.kms))
    particles.x  += Rinit
    particles.vy += vcirc
    cluster.particles.add_particles(particles)

    # set up bridge; cluster is evolved under influence of the galaxy
    sys = bridge(verbose=False)
    sys.add_system(cluster, (galaxy,), False)

    # evolve and make plots
    times = units.Myr([0.,0.2,0.4,0.6,0.8,1.0,1.2,1.4])
    f = pyplot.figure(figsize=(16,8))

    for i,t in enumerate(times):
        sys.evolve_model(t, timestep=timestep)
        print(&quot;Evolved the system to time %f Myr&quot; % t.value_in(units.Myr))

        x=sys.particles.x.value_in(units.parsec)
        y=sys.particles.y.value_in(units.parsec)

        subplot=f.add_subplot(2,4,i+1)
        subplot.plot(x,y,'r .')
        subplot.plot([0.],[0.],'b +')
        subplot.set_xlim(-60,60)
        subplot.set_ylim(-60,60)
        subplot.set_title(&quot;%g Myr&quot; % t.value_in(units.Myr))
        if i==7:
            subplot.set_xlabel('parsec')

    cluster.stop()
    galaxy.stop()
    pyplot.show()
#    pyplot.savefig('test.eps')
</file>
    <file path="py/example_basis_set.py">
#!/usr/bin/python

'''
Example of basis-set potential expansions in agama, galpy and gala.
The latter two libraries implement the Hernquist-Ostriker basis set,
while agama provides a more general Zhao basis set (of which HO is a special case).
We set up a squashed, rotated and shifted Plummer model (so that it has no symmetry at all),
and also sample this analytic density profile with particles.
Then we create an agama BasisSet expansion from both analytic model and particle snapshot;
they do not exactly match because of discreteness noise in the latter case
(it can be reduced by increasing the particle number, but then it would take ages to i
Then we compare the results with the SCF potentials from galpy and gala;
galpy can create the expansion from an analytic density model,
while gala offers both analytic and n-body initialization (but the former one is too slow).
The expansion coefficients computed by either code can be converted into agama-compatible
INI file, from which a native agama BasisSet potential is constructed, and its value and
derivatives are compared to those of the two libraries.
If using the same set of coefficients (i.e. agama potential constructed from foreign coefs),
the results agree to machine precision; the computation of coefficients from an n-body snapshot
also produces identical results in agama and gala, while the initialization from an analytic
density profile in galpy gives slightly different coefs due to integration inaccuracies.
Both construction and evaluation of basis-set potentials is significantly faster in agama;
however, for most practical purposes, the Multipole potential from agama is preferrable
for better performance and accuracy than BasisSet.
'''
import numpy, agama, time
numpy.random.seed(42)

def createPlummer(nbody=100000, rscale=1.2, p=0.8, q=0.6,
    alpha=1.0, beta=2.0, gamma=3.0, offset=numpy.array([0.1,0.2,0.3])):
    # create a triaxial Plummer model with axis ratios y/x=p, z/x=q,
    # rotated w.r.t. principal axes by Euler angles alpha,beta,gamma and shifted from origin by offset
    radius = rscale * (numpy.random.random(size=nbody)**(-2./3) - 1)**-0.5
    costheta = numpy.random.random(size=nbody)*2-1
    sintheta = (1-costheta**2)**0.5
    phi = numpy.random.random(size=nbody) * 2*numpy.pi
    xyz = numpy.column_stack((
        radius*sintheta*numpy.cos(phi),
        radius*sintheta*numpy.sin(phi) * p,
        radius*costheta * q))
    rotmat = agama.makeRotationMatrix(alpha, beta, gamma)
    xyzrot = xyz.dot(rotmat) + offset
    norm = rscale**2 * 3./(4*numpy.pi*p*q)
    def densfnc(xyzrot):
        xyz = (xyzrot-offset).dot(rotmat.T)
        return norm * (rscale**2 + xyz[:,0]**2 + (xyz[:,1]/p)**2 + (xyz[:,2]/q)**2)**-2.5
    return xyzrot, numpy.ones(nbody)/nbody, densfnc

particles, masses, densfnc = createPlummer()
# a small fraction of particle positions are used to compare the potentials
points = particles[:5000]
den_true = densfnc(points)
nmax = 8   # order of radial expansion
lmax = 6   # order of angular expansion
r0   = 1.5 # scale radius of basis functions


print('creating and evaluating agama BasisSet potential')
t0 = time.time()
pot_agama_nbody = agama.Potential(type='BasisSet', nmax=nmax, lmax=lmax, eta=1.0, r0=r0,
    symmetry='none', particles=(particles,masses))
pot_agama_nbody.export('example_basis_set_nbody.ini')
pot_agama_densfnc = agama.Potential(type='BasisSet', nmax=nmax, lmax=lmax, eta=1.0, r0=r0,
    symmetry='none', density=densfnc)
pot_agama_densfnc.export('example_basis_set_densfnc.ini')

Phi_agama_nbody   = pot_agama_nbody.  potential(points)
Phi_agama_densfnc = pot_agama_densfnc.potential(points)
acc_agama_nbody   = pot_agama_nbody  .force(points)
acc_agama_densfnc = pot_agama_densfnc.force(points)
den_agama_nbody   = pot_agama_nbody  .density(points)
den_agama_densfnc = pot_agama_densfnc.density(points)
print('time for constructing and evaluating agama BasisSet potentials: %.3g s' % (time.time()-t0))
print('potential difference between BasisSet potentials initialized from nbody and analytic density: %g' %
    numpy.mean( (Phi_agama_nbody / Phi_agama_densfnc - 1)**2 )**0.5 )
print('acceleration difference between BasisSet potentials initialized from nbody and analytic density: %g' %
    numpy.mean( numpy.sum((acc_agama_nbody-acc_agama_densfnc)**2, axis=1)**0.5 /
        numpy.sum(acc_agama_densfnc**2, axis=1)**0.5 ) )
print('density difference between the true density and BasisSet initialized from analytic density: %g' %
    numpy.mean( (den_agama_densfnc / den_true - 1)**2 )**0.5 )
print('density difference between the true density and BasisSet initialized from nbody snapshot: %g' %
    numpy.mean( (den_agama_nbody / den_true - 1)**2 )**0.5 )

### in addition to BasisSet potentials, we construct and evaluate Multipole potentials
### from both analytic density profile and n-body snapshot
print('creating and evaluating agama Multipole potential')
t0 = time.time()
pot_multipole_nbody = agama.Potential(type='Multipole', lmax=lmax,
    symmetry='none', particles=(particles,masses))
pot_multipole_densfnc = agama.Potential(type='Multipole', lmax=lmax, rmin=0.01,rmax=100,
    symmetry='none', density=densfnc)
print('time for constructing and evaluating agama Multipole potentials: %.3g s' % (time.time()-t0))
print('density difference between the true density and Multipole initialized from analytic density: %g' %
    numpy.mean( (pot_multipole_densfnc.density(points) / den_true - 1)**2 )**0.5 )
print('density difference between the true density and Multipole initialized from nbody snapshot: %g' %
    numpy.mean( (pot_multipole_nbody.density(points) / den_true - 1)**2 )**0.5 )


def convertCoefsToAgamaPotential(r0, Acos, Asin=None, filename='tmppotential.ini'):
    '''
    convert the arrays of cosine and sine coefs from galpy or gala into the agama input format,
    and create the equivalent agama BasisSet potential
    '''
    nmax = Acos.shape[0]-1
    lmax = Acos.shape[1]-1
    assert Acos.shape[2]==lmax+1
    if Asin is None: Asin=numpy.zeros(Acos.shape)
    with open(filename, 'w') as inifile:
        inifile.write('[Potential]\ntype=BasisSet\nnmax=%i\nlmax=%i\nr0=%g\nCoefficients\n#Phi\n#(array)\n' %
            (nmax, lmax, r0))
        for n in range(nmax+1):
            inifile.write(str(n))
            for l in range(lmax+1):
                # first come sine terms in reverse order: m=l, l-1, ..., 1
                for m in range(l):
                    inifile.write('\t%.15g' % (Asin[n,l,l-m] * 0.5**0.5))
                # then come cosine terms in normal order: m=0, 1, ..., l
                for m in range(l+1):
                    inifile.write('\t%.15g' % (Acos[n,l,m] * (0.5**0.5 if m&gt;0 else 1)))
            inifile.write('\n')
    return agama.Potential(filename)

def testGalpy():
    try: import galpy.potential
    except ImportError:
        print('galpy not available, skipping test')
        return
    print('creating galpy scf potential')
    t0=time.time()
    Acos,Asin = galpy.potential.scf_compute_coeffs(
        lambda R,z,phi: densfnc(numpy.array([[R*numpy.cos(phi),R*numpy.sin(phi),z]]))[0],
        N=nmax+1, L=lmax+1, a=r0, phi_order=40)
    pot_galpy_native= galpy.potential.SCFPotential(Acos=Acos, Asin=Asin, a=r0)
    if hasattr(pot_galpy_native, 'phitorque'):  # renamed from phiforce in newer versions
        pot_galpy_native.phiforce = pot_galpy_native.phitorque
    t1=time.time()
    print('evaluating agama scf potential initialized from galpy coefficients')
    Acos[:,:,0] *= 0.5; Asin[:,:,0] *= 0.5  # by some strange convention, m=0 terms are doubled in galpy
    pot_agama_galpy = convertCoefsToAgamaPotential(r0, Acos, Asin, 'example_basis_set_galpy.ini')
    Phi_agama_galpy = pot_agama_galpy.potential(points)
    acc_agama_galpy = pot_agama_galpy.force(points)
    print('evaluating galpy scf potential')
    t2=time.time()
    # need to convert from cylindrical to cartesian coords
    pointscyl = [(points[:,0]**2+points[:,1]**2)**0.5, points[:,2], numpy.arctan2(points[:,1],points[:,0])]
    Phi_galpy_native= pot_galpy_native(*pointscyl)
    acc_galpy_R     = pot_galpy_native.Rforce(*pointscyl)
    acc_galpy_z     = pot_galpy_native.zforce(*pointscyl)
    acc_galpy_phi   = pot_galpy_native.phiforce(*pointscyl)
    acc_galpy_native= numpy.column_stack((
        acc_galpy_R*numpy.cos(pointscyl[2]) - acc_galpy_phi*numpy.sin(pointscyl[2])/pointscyl[0],
        acc_galpy_R*numpy.sin(pointscyl[2]) + acc_galpy_phi*numpy.cos(pointscyl[2])/pointscyl[0],
        acc_galpy_z))
    print('time for constructing galpy scf potential: %.3g s, evaluating it: %.3g s' %
        (t1-t0, time.time()-t2))
    print('potential difference between agama(native) and agama(from galpy): %g' %
        numpy.mean( (Phi_agama_galpy/Phi_agama_densfnc - 1)**2 )**0.5 )
    print('potential difference between galpy(native) and agama(from galpy): %g' %
        numpy.mean( (Phi_agama_galpy/Phi_galpy_native  - 1)**2 )**0.5 )
    print('acceleration difference between agama(native) and agama(from galpy): %g' %
        numpy.mean( numpy.sum((acc_agama_galpy-acc_agama_densfnc)**2, axis=1)**0.5 /
            numpy.sum(acc_agama_nbody**2, axis=1)**0.5 ) )
    print('acceleration difference between galpy(native) and agama(from galpy): %g' %
        numpy.mean( numpy.sum((acc_agama_galpy-acc_galpy_native )**2, axis=1)**0.5 /
            numpy.sum( acc_galpy_native**2, axis=1)**0.5 ) )

def testGala():
    try: import gala.potential
    except ImportError:
        print('gala not available, skipping test')
        return
    print('creating gala scf potential')
    t0=time.time()
    Acos,Asin = gala.potential.scf.compute_coeffs_discrete(
        particles, mass=masses, nmax=nmax, lmax=lmax, r_s=r0)
    # the initialization of gala scf from analytic density is too slow
    #(Acos,_),(Asin,_) = gala.potential.scf.compute_coeffs(
    #    lambda x,y,z: densfnc(numpy.array([[x,y,z]]),
    #    nmax=nmax, lmax=lmax, M=1, r_s=r0, args=(), skip_m=False)
    pot_gala_native = gala.potential.scf.SCFPotential(Snlm=Acos, Tnlm=Asin, m=1, r_s=r0)
    t1=time.time()
    print('evaluating agama scf potential initialized from gala coefficients')
    pot_agama_gala  = convertCoefsToAgamaPotential(r0, Acos, Asin, 'example_basis_set_gala.ini')
    Phi_agama_gala  = pot_agama_gala.potential(points)
    acc_agama_gala  = pot_agama_gala.force(points)
    print('evaluating gala scf potential')
    t2=time.time()
    Phi_gala_native = pot_gala_native.energy(points.T)
    acc_gala_native = pot_gala_native.acceleration(points.T).T
    print('time for constructing gala scf potential: %.3g s, evaluating it: %.3g s' %
        (t1-t0, time.time()-t2))
    print('potential difference between agama(native) and agama(from gala): %g' %
        numpy.mean( (Phi_agama_gala/Phi_agama_nbody - 1)**2 )**0.5 )
    print('potential difference between  gala(native) and agama(from gala): %g' %
        numpy.mean( (Phi_agama_gala/ Phi_gala_native - 1)**2 )**0.5 )
    print('acceleration difference between agama(native) and agama(from gala): %g' %
        numpy.mean( numpy.sum((acc_agama_gala-acc_agama_nbody)**2, axis=1)**0.5 /
            numpy.sum(acc_agama_nbody**2, axis=1)**0.5 ) )
    print('acceleration difference between  gala(native) and agama(from gala): %g' %
        numpy.mean( numpy.sum((acc_agama_gala- acc_gala_native)**2, axis=1)**0.5 /
            numpy.sum( acc_gala_native**2, axis=1)**0.5 ) )

testGalpy()
testGala()
</file>
    <file path="py/example_deprojection.py">
#!/usr/bin/python
__docstring__ = &quot;&quot;&quot;
This example program shows an interactive plot illustrating the projection and
deprojection of a triaxial ellipsoid, viewed at an arbitrary orientation.
The axis lengths Sx,Sy,Sz of the ellipsoid may be provided as command-line
arguments, otherwise they have default values 1.5, 1.0, 0.7.
The orientation of the ellipsoid relative to the observer is controlled by
three viewing angles -- Euler rotation angles of the transformation between
the intrinsic coordinate system associated with the object and the image plane.
The angles can be adjusted by mouse movement: when the left button is pressed,
horizontal movement changes the angle alpha of the rotation in the equatorial
plane of the ellipsoid, and vertical movement changes the inclination angle beta;
when the right button is pressed, the movement changes the rotation angle gamma
in the image plane.
The ellipsoid is drawn by a triangulated surface, coloured according to the
intrinsic coordinates x,y,z: red for large |x| - at the long-axis endpoints,
green for large |y| - intermediate axis, and blue for large |z| - short axis;
additionally, the brightness shows the scattered and reflected light coming
from the direction of observer -- parts of the surface that are parallel
to the image plane are brighter.
The intrinsic coordinate axes x,y,z are shown by red, green and blue lines:
solid if they point towards the observer, dashed if behind the image plane.
The position angles (PA) of the projected principal axes x,y,z are printed
in the top left corner (measured counter-clockwise from the vertical axis/north).
The projected shape is shown by black ellipse, and its axis lengths and
orientation in the image plane are also displayed in the top left corner.
Right part of the plot shows four possible deprojections of this ellipse
for the fixed assumed axis lengths of the triaxial ellipsoid; they differ by
the inferred viewing angles, and the correct one is highlighted in green.
Alternatively, the intrinsic shape of the ellipsoid can be inferred from the
observed ellipse and the assumed viewing angles, except when it is projected
along one if its principal planes; it is shown in the bottom of the left panel.
&quot;&quot;&quot;
import sys, numpy, agama, traceback
import matplotlib.pyplot as plt, matplotlib.patches, matplotlib.collections, matplotlib.backend_bases
sin=numpy.sin
cos=numpy.cos
pi=numpy.pi

# orientation angles
alpha = numpy.random.randint(0,180)*pi/180
beta  = numpy.random.randint(0, 90)*pi/180
gamma = 0
# axes of the ellipsoid
Sx    = 1.5  # default values
Sy    = 1.0
Sz    = 0.7
if len(sys.argv)&gt;=4:  # may be overriden in the command line
    Sx = float(sys.argv[1])
    Sy = float(sys.argv[2])
    Sz = float(sys.argv[3])
    if 2&lt;Sx or Sx&lt;Sy or Sy&lt;Sz or Sz&lt;0:
        raise ValueError(&quot;Axes must be sorted in order of increase&quot;)

# lighting and shading
ampScattered = 0.4
ampDirection = 0.5
ampSpecular  = 0.5
powSpecular  = 8

def getColor(xyz):
    return 0.3 + xyz**2 * numpy.array([0.5 * Sx**-2, 0.3 * Sy**-2, 0.9 * Sz**-2])

# grid for ray tracing
Ngrid  = round(90*Sx)
gridn  = numpy.linspace(-Sx, Sx, Ngrid+1)
gridc  = 0.5*(gridn[1:]+gridn[:-1])
X      = numpy.tile  (gridc, len(gridc))
Y      = numpy.repeat(gridc, len(gridc))

# polygons for triangulated surface plotting
points = numpy.array([[0,1,0],[1,0,0],[0,0,1],[-1,0,0],[0,0,-1],[0,-1,0],[0.967,0,0.255],[0.665,0.665,0.339],[0.828,0.561,0],[0.561,0,0.828],[0.339,0.665,0.665],[0.967,0.255,0],[0.31,0.899,0.31],[0.899,0.31,0.31],[0.561,0.828,0],[0.255,0,0.967],[0.665,0.339,0.665],[0.828,0,0.561],[0.31,0.31,0.899],[0.255,0.967,0],[-0.255,0,0.967],[-0.339,0.665,0.665],[0,0.561,0.828],[-0.828,0,0.561],[-0.665,0.665,0.339],[0,0.255,0.967],[-0.31,0.899,0.31],[-0.31,0.31,0.899],[0,0.828,0.561],[-0.967,0,0.255],[-0.665,0.339,0.665],[-0.561,0,0.828],[-0.899,0.31,0.31],[0,0.967,0.255],[-0.967,0,-0.255],[-0.665,0.665,-0.339],[-0.828,0.561,0],[-0.561,0,-0.828],[-0.339,0.665,-0.665],[-0.967,0.255,0],[-0.31,0.899,-0.31],[-0.899,0.31,-0.31],[-0.561,0.828,0],[-0.255,0,-0.967],[-0.665,0.339,-0.665],[-0.828,0,-0.561],[-0.31,0.31,-0.899],[-0.255,0.967,0],[0.339,0.665,-0.665],[0,0.561,-0.828],[0.665,0.665,-0.339],[0,0.255,-0.967],[0.31,0.899,-0.31],[0.31,0.31,-0.899],[0,0.828,-0.561],[0.665,0.339,-0.665],[0.899,0.31,-0.31],[0,0.967,-0.255],[0.339,-0.665,0.665],[0.828,-0.561,0],[0.665,-0.665,0.339],[0.31,-0.899,0.31],[0.561,-0.828,0],[0.31,-0.31,0.899],[0.665,-0.339,0.665],[0.255,-0.967,0],[0.899,-0.31,0.31],[0.967,-0.255,0],[-0.339,-0.665,0.665],[0,-0.828,0.561],[-0.665,-0.339,0.665],[0,-0.967,0.255],[-0.31,-0.31,0.899],[-0.31,-0.899,0.31],[0,-0.561,0.828],[-0.665,-0.665,0.339],[-0.899,-0.31,0.31],[0,-0.255,0.967],[-0.665,-0.665,-0.339],[-0.561,-0.828,0],[-0.665,-0.339,-0.665],[-0.255,-0.967,0],[-0.899,-0.31,-0.31],[-0.31,-0.899,-0.31],[-0.828,-0.561,0],[-0.339,-0.665,-0.665],[-0.31,-0.31,-0.899],[-0.967,-0.255,0],[0.339,-0.665,-0.665],[0,-0.828,-0.561],[0.828,0,-0.561],[0.665,-0.339,-0.665],[0,-0.967,-0.255],[0.31,-0.31,-0.899],[0.561,0,-0.828],[0.31,-0.899,-0.31],[0,-0.561,-0.828],[0.665,-0.665,-0.339],[0.255,0,-0.967],[0.899,-0.31,-0.31],[0,-0.255,-0.967],[0.967,0,-0.255]])
faces  = numpy.array([[44,38,35],[41,35,36],[41,44,35],[7,14,8],[55,94,90],[51,4,98],[13,11,6],[17,13,6],[13,7,8],[11,13,8],[46,51,49],[38,46,49],[44,46,38],[46,44,37],[29,32,23],[27,21,22],[25,27,22],[63,15,9],[61,69,58],[10,12,7],[12,14,7],[47,57,0],[42,47,26],[35,42,36],[93,94,98],[53,51,98],[48,53,55],[94,53,98],[53,94,55],[51,53,49],[53,48,49],[50,48,55],[14,50,8],[50,14,52],[48,50,52],[86,43,37],[43,46,37],[43,4,51],[46,43,51],[44,45,37],[45,41,34],[41,45,44],[101,1,11],[11,1,6],[13,16,7],[16,13,17],[16,17,9],[16,10,7],[41,39,34],[39,32,29],[39,41,36],[32,39,36],[31,20,72],[20,31,27],[25,20,27],[70,31,72],[31,70,23],[31,30,27],[30,21,27],[30,31,23],[32,30,23],[17,64,9],[64,63,9],[63,64,58],[73,79,75],[12,19,14],[14,19,52],[57,19,0],[19,57,52],[28,10,22],[28,12,10],[21,28,22],[28,21,26],[54,38,49],[48,54,49],[54,48,52],[57,54,52],[38,40,35],[40,57,47],[40,42,35],[42,40,47],[54,40,38],[40,54,57],[21,24,26],[24,42,26],[42,24,36],[30,24,21],[24,32,36],[24,30,32],[4,100,98],[100,93,98],[100,43,86],[43,100,4],[56,101,11],[56,50,55],[56,55,90],[101,56,90],[56,11,8],[50,56,8],[25,18,15],[16,18,10],[10,18,22],[18,25,22],[15,18,9],[18,16,9],[87,3,29],[3,87,34],[39,3,34],[3,39,29],[2,25,15],[2,20,25],[68,70,72],[70,68,75],[68,73,75],[73,68,69],[76,87,29],[76,70,75],[76,29,23],[70,76,23],[94,91,90],[91,93,88],[93,91,94],[67,1,101],[1,67,6],[71,73,69],[71,69,61],[83,78,79],[78,83,85],[81,79,73],[81,71,5],[71,81,73],[81,83,79],[92,81,5],[83,81,92],[28,33,12],[19,33,0],[33,19,12],[33,28,26],[33,47,0],[47,33,26],[89,95,88],[95,89,92],[83,89,85],[89,83,92],[93,96,88],[100,96,93],[96,89,88],[89,96,85],[85,96,86],[96,100,86],[78,84,79],[79,84,75],[84,76,75],[76,84,87],[87,82,34],[82,45,34],[84,82,87],[82,84,78],[45,80,37],[80,78,85],[80,86,37],[80,85,86],[82,80,45],[80,82,78],[20,77,72],[2,77,20],[63,77,15],[77,2,15],[97,91,88],[95,97,88],[71,65,5],[65,71,61],[65,92,5],[65,95,92],[67,66,6],[66,17,6],[66,64,17],[66,67,59],[68,74,69],[69,74,58],[74,68,72],[77,74,72],[74,63,58],[74,77,63],[99,67,101],[97,99,91],[99,101,90],[91,99,90],[67,99,59],[99,97,59],[62,97,95],[65,62,95],[97,62,59],[62,65,61],[66,60,64],[60,66,59],[64,60,58],[62,60,59],[60,61,58],[60,62,61]], dtype=int)
points[:,0] *= Sx
points[:,1] *= Sy
points[:,2] *= Sz
# vertices of all triangular faces
fvert  = numpy.vstack([points[f] for f in faces]).reshape(len(faces), 3, 3)
fcent  = numpy.mean(fvert, axis=1)
fcolor = getColor(fcent)
fveca  = fvert[:,0]-fvert[:,1]
fvecb  = fvert[:,2]-fvert[:,1]
# normal vectors of all triangular faces
fnorm  = numpy.column_stack((
    fveca[:,1]*fvecb[:,2] - fveca[:,2]*fvecb[:,1],
    fveca[:,2]*fvecb[:,0] - fveca[:,0]*fvecb[:,2],
    fveca[:,0]*fvecb[:,1] - fveca[:,1]*fvecb[:,0] ))
fnorm /= (numpy.sum(fnorm**2, axis=1)**0.5)[:,None]

def getEllipse(Sxp, Syp, eta):
    angles = numpy.linspace(0, 2*pi, 49)
    xp = Sxp * numpy.hstack((cos(angles), 0, 0, 0))
    yp = Syp * numpy.hstack((sin(angles), 0, 1, 0))
    return numpy.column_stack((xp * sin(eta) + yp * cos(eta), xp * cos(eta) - yp * sin(eta)))

def clip(x):
    return numpy.maximum(0, (1-1/(1+x**5))**0.2)   # soft clipping into the interval [0..1]

def traceEllipsoid(alpha, beta, gamma):
    R = agama.makeRotationMatrix(alpha, beta, gamma)
    # ray tracing - find the (smallest) Z coordinate of ellipsoid for each point in the X,Y grid
    Q = numpy.einsum('ij,j,kj-&gt;ik', R, [Sx**-2, Sy**-2, Sz**-2], R)
    a =  Q[2,2]
    b = (Q[0,2]+Q[2,0]) * X + (Q[1,2]+Q[2,1]) * Y
    c =  Q[0,0] * X**2 + (Q[0,1]+Q[1,0]) * X*Y + Q[1,1] * Y**2 - 1
    d = 0.25*b*b - a*c
    Z = -0.5*b/a - numpy.abs(d**0.5/a)
    xyz = numpy.dot(numpy.column_stack((X,Y,Z)), R)
    pcolor   = getColor(xyz)
    pnorm    = xyz * numpy.array([Sx**-2, Sy**-2, Sz**-2])
    pnorm   /= (numpy.sum(pnorm**2, axis=1)**0.5)[:,None]
    angle    = numpy.maximum(0, -numpy.dot(pnorm, R[2]))
    intensity= ampScattered + ampDirection * angle + ampSpecular * angle**powSpecular
    return numpy.column_stack((clip(pcolor * intensity[:,None]),
        numpy.isfinite(Z))).reshape(len(gridc), len(gridc), 4)

def drawproj():
    Sxp, Syp, eta = agama.getProjectedEllipse(Sx, Sy, Sz, alpha, beta, gamma)
    R = agama.makeRotationMatrix(alpha, beta, gamma)
    prjfaces = numpy.dot(fvert.reshape(-1,3), R.T).reshape(-1, 3, 3)
    angle    = numpy.maximum(0, -numpy.dot(fnorm, R[2]))
    intensity= ampScattered + ampDirection * angle + ampSpecular * angle**powSpecular
    prjcolor = clip(fcolor * intensity[:,None])
    meanz    = numpy.mean(prjfaces[:,:,2], axis=1)
    order    = numpy.argsort(-meanz)
    figfaces.set_paths([matplotlib.patches.Polygon(f[:,0:2], closed=True) for f in prjfaces[order]])
    figfaces.set_facecolor(prjcolor[order])
    figfaces.set_edgecolor('gray')
    figarrowx.set_xy(numpy.vstack((Sx*R[0:2,0], 2*R[0:2,0])))
    figarrowy.set_xy(numpy.vstack((Sy*R[0:2,1], 2*R[0:2,1])))
    figarrowz.set_xy(numpy.vstack((Sz*R[0:2,2], 2*R[0:2,2])))
    figarrowx.set_zorder(-10 if R[2,0]&gt;0 else 10)
    figarrowy.set_zorder(-10 if R[2,1]&gt;0 else 10)
    figarrowz.set_zorder(-10 if R[2,2]&gt;0 else 10)
    figarrowx.set_linestyle('dotted' if R[2,0]&gt;0 else 'solid')
    figarrowy.set_linestyle('dotted' if R[2,1]&gt;0 else 'solid')
    figarrowz.set_linestyle('dotted' if R[2,2]&gt;0 else 'solid')
    figlabelx.set_x(2.2*R[0,0])
    figlabelx.set_y(2.2*R[1,0])
    figlabely.set_x(2.2*R[0,1])
    figlabely.set_y(2.2*R[1,1])
    figlabelz.set_x(2.2*R[0,2])
    figlabelz.set_y(2.2*R[1,2])
    figellips.set_xy(getEllipse(Sxp, Syp, eta))
    PAprojx = numpy.arctan2(R[0,0], R[1,0])
    PAprojy = numpy.arctan2(R[0,1], R[1,1])
    PAprojz = numpy.arctan2(R[0,2], R[1,2])
    figlabela.set_text('alpha=%.2f, beta=%.2f, gamma=%.2f' % (alpha*180/pi, beta*180/pi, gamma*180/pi) +
        '\nPAprojx=%.2f, PAprojy=%.2f, PAprojz=%.2f' % (PAprojx*180/pi, PAprojy*180/pi, PAprojz*180/pi) +
        '\nmajor=%.3f, minor=%.3f, PAmajor=%.2f' % (Sxp, Syp, eta*180/pi))
    try:
        getSx, getSy, getSz = agama.getIntrinsicShape(Sxp, Syp, eta, alpha, beta, gamma)
        figlabeld.set_text('deprojected A=%.9f, B=%.9f, C=%.9f' % (getSx, getSy, getSz))
        figlabeld.set_color('k' if abs(getSx-Sx)+abs(getSy-Sy)+abs(getSz-Sz) &lt; 1e-8 else 'r')
    except Exception as e:
        traceback.print_exc()
        figlabeld.set_text(str(e))
        figlabeld.set_color('r')
    # plot four possible deprojections
    try:
        cax.cla()
        cax.set_axis_off()
        getang = agama.getViewingAngles(Sxp, Syp, eta, Sx, Sy, Sz)
        images = []
        arrowf = []
        arrowb = []
        trueR  = R  # rotation matrix corresponding to the true orientation
        for i in range(4):
            getAlpha, getBeta, getGamma = getang[i]
            getSxp, getSyp, geteta = agama.getProjectedEllipse(Sx, Sy, Sz, getAlpha, getBeta, getGamma)
            R = agama.makeRotationMatrix(getAlpha, getBeta, getGamma)
            # check which orientation is equivalent to the true one, i.e. when the rotation matrix is
            # &quot;almost&quot; the same as the true one (up to a simultaneous change of sign in two axes),
            # the product of R and inverse of true R is a diagonal matrix with +-1 on diagonal and det=1.
            RtR = numpy.dot(trueR.T, R)
            tru = numpy.linalg.norm(numpy.abs(RtR) - numpy.eye(3)) &lt; 1e-8
            off = numpy.array([ ((i%2)*2-1)*Sx, ((i//2)*2-1)*Sx ])
            sign = numpy.where(R[2]&lt;=0, 1, -1)
            arrowf += [matplotlib.patches.Polygon(numpy.vstack((Sx*R[0:2,0], 2*R[0:2,0])) * sign[0] + off,
                edgecolor='r', fill=False, closed=False, linestyle='solid')]
            arrowb += [matplotlib.patches.Polygon(numpy.vstack((Sx*R[0:2,0], 2*R[0:2,0])) *-sign[0] + off,
                edgecolor='r', fill=False, closed=False, linestyle='dotted')]
            arrowf += [matplotlib.patches.Polygon(numpy.vstack((Sy*R[0:2,1], 2*R[0:2,1])) * sign[1] + off,
                edgecolor='g', fill=False, closed=False, linestyle='solid')]
            arrowb += [matplotlib.patches.Polygon(numpy.vstack((Sy*R[0:2,1], 2*R[0:2,1])) *-sign[1] + off,
                edgecolor='g', fill=False, closed=False, linestyle='dotted')]
            arrowf += [matplotlib.patches.Polygon(numpy.vstack((Sz*R[0:2,2], 2*R[0:2,2])) * sign[2] + off,
                edgecolor='b', fill=False, closed=False, linestyle='solid')]
            arrowb += [matplotlib.patches.Polygon(numpy.vstack((Sz*R[0:2,2], 2*R[0:2,2])) *-sign[2] + off,
                edgecolor='b', fill=False, closed=False, linestyle='dotted')]
            cax.add_artist(matplotlib.patches.Ellipse(off, getSxp*2, getSyp*2, angle=(pi/2-eta)*180/pi,
                fill=False, edgecolor='k', clip_on=False))
            cax.text(off[0]+Sx, off[1]+Sx,
                'alpha=%.9f\nbeta=%.9f\ngamma=%.9f' % (getAlpha*180/pi, getBeta*180/pi, getGamma*180/pi),
                color='g' if tru else 'k' if abs(getSxp-Sxp)+abs(getSyp-Syp)+abs(sin(geteta-eta)) &lt; 1e-8 else 'r',
                ha='left', va='top', fontsize=12)
            images += [traceEllipsoid(getAlpha, getBeta, getGamma)]
        im = numpy.hstack(numpy.hstack(numpy.array(images).reshape(2, 2, len(gridc), len(gridc), 4)))
        cax.imshow(im, extent=[-2*Sx, 2*Sx, -2*Sx, 2*Sx], origin='lower', interpolation='nearest', aspect='auto', zorder=0)
        arrowsf = matplotlib.collections.PatchCollection(arrowf, match_original=True)
        arrowsf.set_zorder(1)
        arrowsf.set_clip_on(False)
        arrowsb = matplotlib.collections.PatchCollection(arrowb, match_original=True)
        arrowsb.set_zorder(-1)
        arrowsb.set_clip_on(False)
        cax.add_artist(arrowsf)
        cax.add_artist(arrowsb)
        cax.set_xlim( 2*Sx,-2*Sx)
        cax.set_ylim(-2*Sx, 2*Sx)
    except Exception as e:
        traceback.print_exc()
        cax.text(0, 0, str(e), color='r', ha='center', va='center')
    # repaing the whole figure
    plt.draw()

def onmousepress(event):
    if event.xdata is None or event.button is None or event.inaxes!=ax: return
    global mousex, mousey
    mousex = event.xdata
    mousey = event.ydata

def onmousemove(event):
    if event.xdata is None or event.button is None or event.inaxes!=ax: return
    global alpha, beta, gamma, mousex, mousey
    if event.button==1:  # change inclination and/or intrinsic rotation
        deltax = (event.xdata - mousex) * pi/2
        deltay = (event.ydata - mousey) * pi/2
        alpha += deltax * cos(gamma) - deltay * sin(gamma)
        beta  -= deltay * cos(gamma) + deltax * sin(gamma)
    if event.button==3:  # change rotation in the image plane
        gamma += numpy.arctan2(event.xdata, event.ydata) - numpy.arctan2(mousex, mousey)
    # normalize angles to the default range
    while beta &gt; pi: beta -= 2*pi
    if beta &lt; 0: beta = -beta; alpha += pi; gamma += pi;
    while alpha &gt;   pi: alpha -= 2*pi
    while alpha &lt;= -pi: alpha += 2*pi
    while gamma &gt;   pi: gamma -= 2*pi
    while gamma &lt;= -pi: gamma += 2*pi
    mousex = event.xdata
    mousey = event.ydata
    drawproj()

def new_home_button(self, *args, **kwargs):
    # reset orientation to default when home button is pressed
    global alpha, beta, gamma
    alpha = 0; beta = 0; gamma = 0;
    drawproj()
    home_button(self, *args, **kwargs)

home_button = matplotlib.backend_bases.NavigationToolbar2.home
matplotlib.backend_bases.NavigationToolbar2.home = new_home_button
fig = plt.figure(figsize=(15, 7.5), dpi=80)
ax  = plt.axes([0.04, 0.08, 0.45, 0.9])
cax = plt.axes([0.52, 0.08, 0.45, 0.9])
ax.set_xlim(3, -3)
ax.set_ylim(-3, 3)
ax.set_xlabel('X')
ax.set_ylabel('Y')
figfaces  = matplotlib.collections.PatchCollection([matplotlib.patches.Polygon([[1,0], [0,0], [0,1]])])
figarrowx = matplotlib.patches.Polygon([[0,0], [0,0]], closed=False, color='r')
figarrowy = matplotlib.patches.Polygon([[0,0], [0,0]], closed=False, color='g')
figarrowz = matplotlib.patches.Polygon([[0,0], [0,0]], closed=False, color='b')
figellips = matplotlib.patches.Polygon([[0,0], [0,0]], closed=False, color='k', fill=False, zorder=9)
ax.add_artist(figfaces)
ax.add_patch(figarrowx)
ax.add_patch(figarrowy)
ax.add_patch(figarrowz)
ax.add_patch(figellips)
figlabelx = ax.text(0, 0, 'x',  ha='center', va='center', fontsize=12, color='r')
figlabely = ax.text(0, 0, 'y',  ha='center', va='center', fontsize=12, color='g')
figlabelz = ax.text(0, 0, 'z',  ha='center', va='center', fontsize=12, color='b')
figlabela = ax.text(2.9, 2.9, '', ha='left', va='top',    fontsize=12)
figlabeld = ax.text(2.9,-2.9, '', ha='left', va='bottom', fontsize=12)
fig.canvas.mpl_connect(&quot;button_press_event&quot;, onmousepress)
fig.canvas.mpl_connect(&quot;motion_notify_event&quot;, onmousemove)
drawproj()
print(__docstring__)
plt.show()
</file>
    <file path="py/example_df_fit.py">
#!/usr/bin/python

'''
    This example demonstrates how to find best-fit parameters of an action-based
    distribution function that matches the given N-body snapshot.

    The N-body model itself corresponds to a spherically-symmetric isotropic
    Hernquist profile, and we fit it with a double-power-law distribution function
    of Posti et al.2015. We use the exact potential (i.e., do not compute it
    from the N-body model itself, nor try to vary its parameters, although
    both options are possible), and compute actions for all particles only once.
    Then we scan the parameter space of DF, finding the maximum of the likelihood
    function with a multidimensional minimization algorithm.
    This takes a few hundred iterations to converge.

    This Python script is almost equivalent to the C++ test program example_df_fit.cpp,
    up to the difference in implementation of Nelder-Mead minimization algorithm.

    Additionally, we use the MCMC implementation EMCEE to explore the confidence
    intervals of model parameters around their best-fit values obtained at the first
    stage (deterministic search).
    Note that occasionally this first stage could get stuck in a local minimum,
    but the MCMC algorithm then usually finds its way towards the global minimum.
    In these cases one could see rather large fluctuations in the parameters
    explored by the chain.
'''
import agama, numpy
from scipy.optimize import minimize

labels = ['slopeIn', 'slopeOut', 'steepness', 'coef$J_r$', r'$\ln J_0$']

# convert from parameter space to DF params: note that we apply
# some non-trivial scaling to make the life easier for the minimizer
def dfparams(args):
    return dict(
        type = 'DoublePowerLaw',
        slopeIn   = args[0],
        slopeOut  = args[1],
        steepness = args[2],
        coefJrIn  = args[3],
        coefJzIn  = (3-args[3])/2,  # fix h_z=h_phi taking into account that h_r+h_z+h_phi=3
        coefJrOut = 1.,
        coefJzOut = 1.,
        J0        = numpy.exp(args[4]),
        norm = 1.)

# compute log-likelihood of DF with given params against an array of points
def model_likelihood(params, points):
    line = &quot;J0=%6.5g, slopeIn=%6.5g, slopeOut=%6.5g, steepness=%6.5g, coefJrIn=%6.5g: &quot; \
        % (params['J0'], params['slopeIn'], params['slopeOut'], params['steepness'], params['coefJrIn'])
    try:
        dpl = agama.DistributionFunction(**params)
        norm = dpl.totalMass()
        sumlog = numpy.sum( numpy.log(dpl(points)/norm) )
        print(line + (&quot;LogL=%.8g&quot; % sumlog))
        return sumlog
    except ValueError as err:
        print(line + &quot;Exception &quot; + str(err))
        return -1000.*len(points)

# function to minimize
def model_search_fnc(args, actions):
    return -model_likelihood(dfparams(args), actions)

# function to maximize
def model_search_emcee(args, actions):
    return model_likelihood(dfparams(args), actions)

# analytic expression for the ergodic distribution function f(E)
# in a Hernquist model with mass M, scale radius a, at energy E (it may be an array).
def dfHernquist(E):
    q = numpy.sqrt(-E)
    return 1 / (8 * 2**0.5 * numpy.pi**3) * (1-q*q)**-2.5 * \
        (3*numpy.arcsin(q) + q * numpy.sqrt(1-q*q) * (1-2*q*q) * (8*q**4 - 8*q*q - 3) )

# create an N-body representation of Hernquist model
def createHernquistModel(nbody):
    points      = numpy.zeros((nbody, 6))
    masses      = numpy.ones(nbody, dtype=numpy.float64) / nbody
    # 1. choose position:
    # assign the radius by inverting M(r), where M(r) is the enclosed mass - uniform in [0:1]
    radius      = 1 / (numpy.random.random(size=nbody)**-0.5 - 1)
    costheta    = numpy.random.uniform(-1, 1, size=nbody)
    sintheta    = (1-costheta**2)**0.5
    phi         = numpy.random.uniform(0, 2*numpy.pi, size=nbody)
    points[:,0] = radius * sintheta * numpy.cos(phi)
    points[:,1] = radius * sintheta * numpy.sin(phi)
    points[:,2] = radius * costheta
    # 2. assign velocity by rejection sampling
    potential   = -1 / (1 + radius)
    fmax        = 0.025 / radius**2 / (radius+3) # upper boundary on f(r,v) for rejection sampling
    velocity    = numpy.zeros(nbody)
    indices     = numpy.where(velocity == 0)[0]  # initially this contains all points
    while len(indices)&gt;0:
        E       = numpy.random.random(size=len(indices)) * potential[indices]
        vel     = 2**0.5 * (E-potential[indices])**0.5
        fE      = dfHernquist(E) * vel * 2**-0.5
        f       = numpy.random.random(size=len(indices)) * fmax[indices]
        if(numpy.any(fE &gt;= fmax[indices])):
            raise &quot;Invalid upper boundary on f(E)&quot;  # shouldn't happen
        assigned= numpy.where(f &lt; fE)[0]
        velocity[indices[assigned]] = vel[assigned]
        indices = numpy.where(velocity == 0)[0]  # find out the unassigned elements
    costheta    = numpy.random.uniform(-1, 1, size=nbody)
    sintheta    = (1-costheta**2)**0.5
    phi         = numpy.random.uniform(0, 2*numpy.pi, size=nbody)
    points[:,3] = velocity * sintheta * numpy.cos(phi)
    points[:,4] = velocity * sintheta * numpy.sin(phi)
    points[:,5] = velocity * costheta
    return points, masses


def main():
    pot = agama.Potential(type=&quot;Dehnen&quot;, mass=1, scaleRadius=1.)
    actf= agama.ActionFinder(pot)
    particles, masses = createHernquistModel(100000)
    actions = actf(particles)

    # do a parameter search to find best-fit distribution function describing these particles
    initparams = numpy.array([2.0, 4.0, 1.0, 1.0, 0.0])
    result = minimize(model_search_fnc, initparams, args=(actions,), method='Nelder-Mead',
        options=dict(maxiter=1000, maxfev=1000, disp=True))

    # explore the parameter space around the best-fit values using the MCMC chain
    try:
        import matplotlib.pyplot as plt, emcee, corner
    except ImportError as ex:
        print(str(ex) + &quot;\nYou need to install 'emcee' and 'corner' packages&quot;)
        exit()
    print(&quot;Starting MCMC&quot;)
    ndim = len(initparams)
    nwalkers = 16    # number of parallel walkers in the chain
    nsteps   = 300   # number of steps in MCMC chain
    nburnin  = 100   # number of initial steps to discard
    # initial coverage of parameter space - around the best-fit solution with a small dispersion
    initwalkers = [result.x + 0.01*numpy.random.randn(ndim) for i in range(nwalkers)]
    sampler = emcee.EnsembleSampler(nwalkers, ndim, model_search_emcee, args=(actions,))
    sampler.run_mcmc(initwalkers, nsteps)

    # show the time evolution of parameters carried by the ensemble of walkers (time=number of MC steps)
    fig,axes = plt.subplots(ndim+1, 1, sharex=True)
    for i in range(ndim):
        axes[i].plot(sampler.chain[:,:,i].T, color='k', alpha=0.5)
        axes[i].set_ylabel(labels[i])
    # last panel shows the evolution of log-likelihood for the ensemble of walkers
    axes[-1].plot(sampler.lnprobability.T, color='k', alpha=0.5)
    axes[-1].set_ylabel('log(L)')
    maxloglike = numpy.max(sampler.lnprobability)
    axes[-1].set_ylim(maxloglike-3*ndim, maxloglike)
    fig.tight_layout(h_pad=0.)
    plt.show()

    # show the posterior distribution of parameters
    samples = sampler.chain[:, nburnin:, :].reshape((-1, ndim))
    corner.corner(samples, labels=labels, quantiles=[0.16, 0.5, 0.84])
    plt.show()
    print(&quot;Acceptance fraction: %f&quot; % numpy.mean(sampler.acceptance_fraction))  # should be in the range 0.2-0.5
    #print(&quot;Autocorrelation time: %f&quot;% sampler.acor)  # should be considerably shorter than the total number of steps

main()
</file>
    <file path="py/example_forstand.py">
#!/usr/bin/python
'''
This program is an example of running observationally-constrained Schwarzschild models
(the FORSTAND code, Vasiliev&amp;Valluri 2020).
It has several modes of operation:

1.  Run a model for a particular choice of parameters for the potential, orbit library, etc.
    (actually, a series of models with the same potential/orbit, but different mass-to-light ratios,
    in which the velocities are rescaled before fitting to observational constraints).
    Normally one would launch several copies of the script with different parameters (e.g. Mbh),
    the results will be collected in a summary text file,
    and each model's best-fit LOSVD and orbit library will be stored in separate files.

2.  Display an interactive plot with several panels:
  - kinematic maps (v,sigma,Gauss-Hermite moments) of the data or the model(s),
    one may click on any aperture and examine the LOSVD profile in both the data and the current model;
  - a 2d plot of chi2 values as a function of potential parameters for a grid of models,
    one may choose a model from the grid, load its LOSVD and display corresponding kinematic maps;
  - LOSVD in the given aperture (both data constraints with uncertainties and the current model);
  - distribution of orbit weights of the current model in two projections of integral space:
    mean radius vs. normalized squared total angular momentum [L/Lcirc(E)]^2, or
    mean radius vs. orbit inclination Lz/L; the size of symbols indicates orbit weights.

3.  Display some diagnostic plots useful for assessing the overall setup before running any models:
    projected and 3d density profiles along major and minor axes, location and masses of spatial bins,
    circular-velocity curve of the potential, and the observed values of v0 and sigma.
    The surface density and especially the deprojected 3d density help to check the photometric model;
    they should be smooth and have a sensible shape. In the 3d density plot, we also show the nodes of
    the spatial discretization grid, which should cover the region of interest, especially the central
    cusp (if we are interested in measuring Mbh, we need to have at least a few bins in the density
    profile within the expected radius of influence).
    The top right panel shows the values of density constraints (essentially, cell masses);
    ideally they should be quite uniform (with the exception of the innermost ones, which may be
    smaller if the grid is deliberately made finer in the central region). If the dynamical range
    spans more than 3-4 orders of magnitude, there is a risk that the smallest bins don't get any
    suitable orbits passing through them, so these density constraints would be impossible to satisfy,
    and the model either will be infeasible (if the density tolerance is set to zero) or will have
    a large and unpredictably varying penalty for violating these density constraints, which is also
    bad. In these cases one would need to adjust the grid parameters or even change the density
    discretization scheme to a different kind (e.g. classic instead of cylindrical, or vice versa).
    The bottom right panel shows the circular-velocity curve (split between mass components)
    for the model with the currently chosen parameters (Mbh, stellar M/L, etc.). For comparison,
    the values of kinematic constraints (v0 and sigma) in all bins are plotted against radius.
    In a thin and cold disk observed edge-on, the maximum value of |v0| should be close to the
    amplitude of the total circular velocity, but in general it will be smaller by some factor.
    This plot may be used to get a rough idea about the expected M/L: the amplitude of Vcirc in
    the potential is scaled by sqrt(Upsilon), where Upsilon (provided as a command-line argument)
    is the starting value for scanning the M/L axis automatically performed by the code.

4.  Prepare mock data for running the first two tasks.
    For this, one needs an N-body snapshot - in this example it should be produced by running
    a separate script  example_self_consistent_model3.py, which creates a three-component galaxy model
    (disk + bulge + DM halo) with a central black hole.
    It should be straightforward to feed in any other N-body snapshot, adjusting a few parameters.

This script uses various routines from the submodule agama.schwarzlib, which are general enough
to be used in any model fitting task. The specifics of each particular galaxy are encoded as numerous
parameters scattered througout this file.
Almost all needed parameters have reasonable default values in this example, but of course these are
not necessarily optimal for other purposes.
When adapting this example to your particular dataset, you will need to modify/adjust many parameters;
those which likely need to be changed are marked by [REQ],
other parameters which may be adjusted but have reasonable default values are marked by [OPT].
It is convenient to assign default values at the beginning of the script, and optionally change
some of them by providing command-line arguments in the form  name=value.

To run a complete example of constructing a grid of Schwarzschild models, do the following:

1.  Construct an N-body snapshot which will be used for the mock data, by running
    example_self_consistent_model3.py
    Among other things, it will produce the two files model_disk_final, model_bulge_final,
    which together contain the stellar particles of the model galaxy.

2.  Prepare the mock photometric and kinematic datasets, by running
    example_forstand.py do=mock
    It requires two Python modules 'mgefit' and 'vorbin'.
    This will produce an MGE file with surface density, and two kinematic datasets
    (low-resolution covering a large part of the galaxy, and high-res for the central region).
    Kinematic data (LOSVDs) in ~200 Voronoi bins are provided in two alternative forms:
  - histogrammed LOSVDs with values and their uncertainties in ~15 bins across the velocity axis;
  - Gauss-Hermite moments of LOSVDs (v, sigma, h3, h4, h5, h6 and their uncertainties).
    The models could be run on either of these alternative datasets, the choice is controlled
    by the command-line argument  hist=[y/n]  (the mock data are always generated for both cases).

3.  Examine the model setup by running
    example_forstand.py do=test
    (this is less relevant for the mock dataset, but could be quite helpful when working
    with real data, to check if the parameters are sensible, or to diagnose possible problems).

4.  Now run several series of models with different values of Mbh:
    example_forstand.py do=run Mbh=...
    (of course, one may also adjust many other parameters, including hist=[true/false])
    Each series of models has the same gravitational potential, scaled by several values of M/L;
    the LOSVD and the orbit properties of each model series are written into separate .npz files,
    and the summary of all models (grid of parameters and chi2 values) are stored in a single file
    results***.txt (*** is either GH or Hist).
    For each series of models with a given potential, the one with a M/L that gives the lowest chi2
    is converted into an N-body representation and written into a separate text file.
    The true value of Mbh is 1e8, and M/L is 1; it makes sense to explore at least a few series of
    models with Mbh ranging from 0 to ~3-5 times the true value.

5.  Finally, one may explore the grid of models for all values of Mbh and M/L by running
    example_forstand.py do=plot [hist=... and other params]

When adapting this script to a particular galaxy with existing observational datasets,
start from step 4 (to make sure that the observed kinematic maps look reasonable and
geometric parameters of the model, such as viewing angles and grids, are correct),
and then go back to step 3 (run several series of models) before going to step 4 again.

This script is mainly tailored to axisymmetric systems, although the Forstand code is applicable
in a more general context (e.g., to rotating triaxial barred galaxies).
The main limitation is the lack of suitable deprojection methods: in this example we use
the Multi-Gaussian expansion to fit the 2d surface density profile of the N-body snapshot
and then deproject it into an ellipsoidally stratified 3d density profile.
In the case of triaxial systems, especially with radially varying axis ratios, this procedure
is much less reliable and may even fail to produce a reasonable deprojection if the actual
3d shape is not well described by ellipsoids.
For triaxial systems, there are two rather than one angle specifying the orientation:
inclination (beta) and the angle alpha between the major axis and the line of nodes,
and in the rotating case, the pattern speed Omega is also a free parameter.

The model parameters and corresponding chi^2 values are stored in a single file
resultsGH.txt (for Gauss-Hermite parametrization of the LOSVD) or
resultsHist.txt (for histograms), and the kinematic maps and orbit distribution of each series
of models with the same potential and varying M/L are stored in a separate .npz archive.
In the interactive plotting regime, the likelihood surface is shown as a function of two
model parameters (in this example, Mbh and M/L), but one may choose another pair of parameters
by providing different columns of the results file as &quot;aval&quot;, &quot;bval&quot; arguments for
agama.schwarzlib.runPlot(...); the values of remaining parameters should then be fixed and
specified as command-line arguments.
'''

import sys, numpy, agama

############### parse parameters from command-line arguments or assign default values #############
arglist = []
for arg in sys.argv[1:]:
    nameval = arg.split('=')
    if len(nameval)!=2:
        raise ValueError('Command-line arguments should be in the form  name=value')
    arglist.append([nameval[0].upper(), nameval[1]])
args = dict(arglist)

distance  = float(args.get('DISTANCE', 20626.5))# [REQ] assumed distance [kpc]
arcsec2kpc= distance * numpy.pi / 648000        # conversion factor (number of kiloparsecs in one arcsecond)
agama.setUnits(mass=1, length=arcsec2kpc, velocity=1)  # [OPT] units: mass = 1 Msun, length = 1&quot;, velocity = 1 km/s
Mbh       = float(args.get('MBH', 1e8))         # [REQ] mass of the central black hole  [Msun]
Omega     = float(args.get('OMEGA', 0))         # [REQ] pattern speed (relevant only for non-axisymmetric models) [km/s/length_unit]
halotype  =       args.get('HALOTYPE', 'nfw')   # [OPT] halo type: 'LOG' or 'NFW'
vhalo     = float(args.get('VHALO', 190))       # [OPT] asymptotic (LOG) or peak (NFW) circular velocity of the halo [km/s]
rhalo     = float(args.get('RHALO', 150))       # [OPT] core (LOG) or scale (NFW) radius of the halo [lenth_unit]
Upsilon   = float(args.get('UPSILON', 1.0))     # [OPT] initial value of mass-to-light ratio in the search
multstep  = float(args.get('MULTSTEP', 1.02))   # [OPT] multiplicative step for increasing/decreasing Upsilon during grid search
numOrbits = int  (args.get('NUMORBITS', 20000)) # [OPT] number of orbit in the model (size of orbit library)
intTime   = float(args.get('INTTIME', 100.0))   # [OPT] integration time in units of orbital period
regul     = float(args.get('REGUL', 1. ))       # [OPT] regularization parameter (larger =&gt; more uniform orbit weight distribution in models)
incl      = float(args.get('INCL', 60.0))       # [REQ] inclination angle (0 is face-on, 90 is edge-on) [degrees]
beta      = incl * numpy.pi/180                 # same in radians
alpha_deg = float(args.get('ALPHA', 0.0))       # [REQ] azimuthal angle of viewing direction in the model coordinates (relevant only for non-axisym)
alpha     = alpha_deg * numpy.pi/180            # same in radians
degree    = int  (args.get('DEGREE', 2))        # [OPT] degree of B-splines  (0 means histograms, 2 or 3 is preferred)
symmetry  = 'a'                                 # [OPT] symmetry of the model ('s'pherical, 'a'xisymmetric, 't'riaxial)
addnoise  =      (args.get('ADDNOISE', 'True')  # [OPT] whether to add a realistic amount of noise in generating mock datacubes
    .upper() in ('TRUE', 'T', 'YES', 'Y'))
nbody     = int  (args.get('NBODY', 100000))    # [OPT] number of particles for the N-body representation of the best-fit model
nbodyFormat = args.get('NBODYFORMAT', 'text')   # [OPT] format for storing N-body snapshots (text/nemo/gadget)
command   = args.get('DO', '').upper()          # [REQ] operation mode: 'RUN' - run a model, 'PLOT' - show the model grid and maps, 'TEST' - show diagnostic plots, 'MOCK' - create mock maps
variant   = args.get('VARIANT', 'GH').upper()   # [OPT] choice between three ways of representing and fitting LOSVDs (see below)
if 'HIST' not in variant and 'GH' not in variant and 'VS' not in variant:
    raise RuntimeError('parameter &quot;variant&quot; should be one of &quot;GH&quot; (Gauss-Hermite moments), &quot;VS&quot; (classical moments - v &amp; sigma), or &quot;HIST&quot; (LOSVD histograms)')
fileResult= 'results%s.txt' % variant           # [OPT] filename for collecting summary results for the entire model grid
seed      = int  (args.get('SEED', 99))         # [OPT] random seed (different values will create different realizations of mock data when do=MOCK, or initial conditions for the orbit library when do=RUN)
agama.setRandomSeed(seed)                       # note that Agama has its own
numpy.random.seed(seed)                         # make things repeatable when generating mock data (*not* related to the seed for the orbit library)
numpy.set_printoptions(precision=4, linewidth=9999, suppress=True)

# In this example, we use the Multi-Gaussian Expansion to parametrize
# the surface density profile and deproject it into the 3d density profile,
# but the code works with any other choice of 3d density model.
filenameMGE = 'mge_i%.0f.txt' % incl    # [REQ] file with parameters of the MGE model for the surface density profile (if MGE is used)

### common parameters for kinematic datasets (though in principle they may also differ between them)
gridv  = numpy.linspace(-500, 500, 26)  # [REQ] the grid in model velocity space (will be multiplied by sqrt(Upsilon) when comparing to data)
velpsf = 0.0                  # [OPT] velocity-space PSF (usually not needed, as the spectroscopic fits produce deconvolved LOSVDs)
# [OPT] define the degree and velocity grid for the observed LOSVD provided as histograms or (less likely) higher-degree B-splines;
# the following two lines are needed [REQ] only if the input is provided in the form of binned LOSVDs (usehist=True),
# but we also use these parameters to generate mock LOSVD histograms if command=='MOCK'
hist_degree = 0               # [OPT] B-spline degree for the observed LOSVDs (0 means histogram)
hist_gridv  = numpy.linspace(-400, 400, 17)  # [OPT] velocity grid for the observed LOSVDs (boundaries of velocity bins, not centers!)

### parameters of the 1st kinematic dataset
gamma1 = 25.0 * numpy.pi/180  # [REQ] CW rotation angle of the image-plane X axis relative to the line of nodes (=major axis for axisym.systems)
psf1   = 1.0                  # [REQ] width of the Gaussian PSF ( may use more than one component: [ [width1, weight1], [width2, weight2] ] )
kinemParams1 = dict(          # parameters passed to the constructor of the Target class
    type     = 'LOSVD',
    symmetry = symmetry,      # symmetry properties of the potential
    alpha    = alpha,         # two angles defining the orientation of the model
    beta     = beta,          # w.r.t. image plane (same for all kinematic datasets)
    gamma    = gamma1,        # third angle is the rotation of the image plane, may be different for each dataset
    psf      = psf1,          # spatial PSF
    velpsf   = velpsf,        # velocity-space PSF
    degree   = degree,        # parameters for the internal datacube represented by B-splines:
    gridv    = gridv,         # usually will be identical for all datasets (except gridx,gridy which is determined by apertures)
)
filenameVorBin1 = 'voronoi_bins_i%.0f_lr.txt' % incl # [REQ] Voronoi binning scheme for this dataset
filenameHist1   = 'kinem_hist_i%.0f_lr.txt'   % incl # [REQ] histogrammed representation of observed LOSVDs
filenameGH1     = 'kinem_gh_i%.0f_lr.txt'     % incl # [REQ] Gauss-Hermite parametrization of observed LOSVDs (usually only one of these two files is given)
filenameVS1     = 'kinem_vs_i%.0f_lr.txt'     % incl # [REQ] 

### same for the 2nd kinematic dataset [OPT] - may have only one dataset, or as many as needed
gamma2 = -10.0 * numpy.pi/180
psf2   = 0.1                  # in this case it's a high-resolution IFU datacube
kinemParams2 = dict(
    type     = 'LOSVD',
    symmetry = symmetry,
    alpha    = alpha,
    beta     = beta,
    gamma    = gamma2,
    psf      = psf2,
    velpsf   = velpsf,
    degree   = degree,
    gridv    = gridv,
)
filenameVorBin2 = 'voronoi_bins_i%.0f_hr.txt' % incl
filenameHist2   = 'kinem_hist_i%.0f_hr.txt'   % incl
filenameGH2     = 'kinem_gh_i%.0f_hr.txt'     % incl
filenameVS2     = 'kinem_vs_i%.0f_hr.txt'     % incl


def makeMockKin(kinemParams, gridxy, nbins, filenameVorBin, filenameHist, filenameGH, filenameVS):
    # 1st step: construct Voronoi bins for kinematic datasets
    print('Creating Voronoi bins')
    xc, yc, bintags = agama.schwarzlib.makeVoronoiBins(
        posvel,
        gridx = gridxy,   # [REQ] X-axis pixel boundaries for the 1st (LR) dataset
        gridy = gridxy,   # [REQ] same for Y axis
        nbins = nbins,    # [REQ] desired number of Voronoi bins (the result may differ somewhat)
        alpha = kinemParams['alpha'],  # orientation angles
        beta  = kinemParams['beta'],
        gamma = kinemParams['gamma']
    )
    # save the binning scheme to text file
    numpy.savetxt(filenameVorBin, numpy.column_stack((xc, yc, bintags)), fmt='%8.4f %8.4f %7d')

    # 2st step: construct the LOSVD target and apply it to the N-body snapshot
    print('Computing LOSVDs of input snapshot')
    apertures    = agama.schwarzlib.getBinnedApertures(xc, yc, bintags)      # obtain boundary polygons from Voronoi bins
    gridx, gridy = agama.schwarzlib.makeGridForTargetLOSVD(apertures, kinemParams['psf'])  # construct a suitable image-plane grid
    target       = agama.Target(apertures=apertures, gridx=gridx, gridy=gridy, **kinemParams)
    datacube     = target((posvel, mass)).reshape(len(apertures), -1)

    # datacube now contains the amplitudes of B-spline representation of LOSVDs in each aperture.
    # Assign the uncertainties on each amplitude assuming the Poisson noise;
    # for this we need to know the &quot;typical&quot; amplitude produced by one particle (e.g., placed at the center),
    # which is the particle mass divided by the bin size of the velocity grid.
    oneparticle = numpy.mean(mass) / (gridv[1]-gridv[0])
    noise = numpy.maximum(1, datacube / oneparticle)**0.5
    # it turns out that this noise level is very low in our example, so we multiply it by some factor &gt;1
    if '_lr' in filenameGH: noise *= 8
    else: noise *= 2
    # to propagate the uncertainties throughout subsequent computations, construct &quot;nboot&quot; realizations
    # of the original datacube perturbed by Gaussian noise
    nboot = 16
    datacubes = datacube + numpy.random.normal(size=(nboot,)+datacube.shape) * noise * oneparticle
    if addnoise:
        datacube = datacubes[0]   # take one perturbed realization as the input (noisy) data
    # else keep datacube as computed originally

    # 3th step, variant A: convert the B-splines to histograms, which are in fact 0th-degree B-splines;
    # we might have constructed model LOSVDs in terms of histograms directly, but this would have been less accurate
    # than rebinning the model LOSVDs onto the new velocity grid
    conv = numpy.linalg.solve(   # conversion matrix from the model B-splines into observed histograms
        agama.bsplineMatrix(hist_degree, hist_gridv),
        agama.bsplineMatrix(hist_degree, hist_gridv, degree, gridv) ).T
    hist_val = datacube.dot(conv)
    hist_err = numpy.std(datacubes.dot(conv), axis=0)
    hist_norm= numpy.sum(hist_val, axis=1)[:,None]
    # save the interleaved values and error estimates of the B-spline amplitudes in each aperture to a text file
    numpy.savetxt(filenameHist,
        numpy.dstack((hist_val/hist_norm, hist_err/hist_norm)).reshape(len(apertures), -1),
        fmt='%9.3g')

    # 3rd step, variant B: convert the B-spline LOSVDs to GH moments
    print('Computing Gauss-Hermite moments and their error estimates')
    ghorder = 6  # [OPT] order of GH expansion
    ghm_val = agama.ghMoments(degree=degree, gridv=gridv, ghorder=ghorder, matrix=datacube)
    ghm_err = numpy.std(
        agama.ghMoments(degree=degree, gridv=gridv, ghorder=ghorder,
            matrix=datacubes.reshape(-1, datacubes.shape[2])).
        reshape(nboot, len(apertures), -1),
        axis=0)
    ind = (1,2,6,7,8,9)  # keep only these columns, corresponding to v,sigma,h3,h4,h5,h6
    numpy.savetxt(filenameGH,
        numpy.dstack((ghm_val, ghm_err))[:,ind,:].reshape(len(apertures), -1),
        fmt='%8.3f', header='v        v_err    sigma    sigma_err '+
        'h3       h3_err    h4       h4_err    h5       h5_err    h6       h6_err')

    # 3th step, variant C: convert the B-splines to V and sigma
    i0 = agama.bsplineIntegrals(degree, gridv)
    i1 = agama.bsplineIntegrals(degree, gridv, power=1)
    i2 = agama.bsplineIntegrals(degree, gridv, power=2)
    datacube0  = datacube.dot(i0)
    datacubes0 = datacubes.dot(i0)
    meanv_val  = (datacube.dot(i1) / datacube0)
    sigma_val  = (datacube.dot(i2) / datacube0 - meanv_val**2)**0.5
    meanv_vals = (datacubes.dot(i1) / datacubes0)
    sigma_vals = (datacubes.dot(i2) / datacubes0 - meanv_vals**2)**0.5
    meanv_err  = numpy.std(meanv_vals, axis=0)
    sigma_err  = numpy.std(sigma_vals, axis=0)
    numpy.savetxt(filenameVS,
        numpy.column_stack((meanv_val, meanv_err, sigma_val, sigma_err)),
        fmt='%8.3f', header='v v_err sigma sigma_err')


# generate mock observations from an N-body model ([OPT] - of course this section is not needed when running the script on actual observations)
if command == 'MOCK':
    # here we use the N-body model generated by another example program:  example_self_consistent_model3.py
    # among other things, it outputs two N-body snapshot files - one for the disk, the other for the bulge component
    try:
        print('Reading input snapshot')
        snapshot1 = agama.readSnapshot('model_disk_final')
        snapshot2 = agama.readSnapshot('model_bulge_final')
        posvel    = numpy.vstack((snapshot1[0], snapshot2[0]))  # 2d Nx6 array of positions and velocities
        mass      = numpy.hstack((snapshot1[1], snapshot2[1]))  # 1d array of N particle masses
        # if your N-body snapshot is contained in a single file, just load it and assign posvel,mass arrays as specified above
    except:
        exit('You need to generate N-body snapshots by running example_self_consistent_model3.py')
    # convert the N-body model (which was set up in N-body units with G=1) to observational units defined at the beginning of this script
    rscale = 30.0   # [REQ] 1 length unit of the N-body snapshot corresponds to this many length units of this script (arcseconds)
    mscale = 4e10   # [REQ] 1 mass unit of the snapshot corresponds to this many mass units of this script (solar masses)
    vscale = (agama.G * mscale / rscale)**0.5  # same for the N-body velocity unit =&gt; km/s
    print('Scaling N-body model to physical units: 1 length unit = %g arcsec = %g kpc, 1 velocity unit = %g km/s, 1 mass unit = %g Msun' %
        (rscale, rscale * arcsec2kpc, vscale, mscale))
    posvel[:, 0:3] *= rscale
    posvel[:, 3:6] *= vscale
    mass *= mscale

    # 0th step: construct an MGE parameterization of the density (note: this is a commonly used, but not necessarily optimal approach)
    print('Creating MGE')
    mge = agama.schwarzlib.makeMGE(posvel, mass, beta, distance, plot=True)
    numpy.savetxt(filenameMGE, mge, fmt='%12.6g %11.3f %11.4f',
        header='MGE file\nsurface_density  width  axis_ratio\n[Msun/pc^2]   [arcsec]')

    # Low-resolution dataset with a FoV 1x1' and pixel size 1&quot; (comparable to ground-based IFU such as SAURON).
    # Note: make sure that the pixel size passed to makeVoronoiBins is rounded to at most 4 significant digits,
    # since this is the precision with which we save it later; otherwise the subsequent reading of Voronoi bins will fail
    makeMockKin(kinemParams1, numpy.linspace(-30.0, 30.0, 61), 150, filenameVorBin1, filenameHist1, filenameGH1, filenameVS1)
    # High-resolution dataset similar to AO-assisted IFU such as NIFS (2x2&quot;, pixel size 0.1&quot;)
    makeMockKin(kinemParams2, numpy.linspace(- 1.0,  1.0, 21),  50, filenameVorBin2, filenameHist2, filenameGH2, filenameVS2)

    print('Finished creating mock datasets, now you may run this script with the argument  do=plot  or  do=run')
    exit()


### assemble the datasets (Targets and constraints)
datasets = []

### 0: photometry =&gt; 3d density profile and its discretization scheme for a density Target

# read the input MGE file, skipping the first three lines as comments, deproject it and construct the Density object.
# Instead of MGE, one may use any other parametric density profile, e.g. one or more Sersic components with parameters
# determined by photometric fitting software such as Galfit
try:
    mge = numpy.loadtxt(filenameMGE)   # [REQ] file with MGE parametrization of surface density profile
except:
    print('%s not found; you need to generate the mock data first, as explained at the beginning of this file' % filenameMGE)
    exit()

densityStars = agama.schwarzlib.makeDensityMGE(mge, distance, arcsec2kpc, beta)
#densityStars = agama.Density(agama.Density('dens_disk'), agama.Density('dens_bulge'))  # true profiles of this mock dataset

### parameters for the density dataset
# the choice of discretization scheme depends on the morphological type of the galaxy being modelled:
# for disky systems, DensityCylindrical[TopHat/Linear] is preferred, either in the axisymmetric regime
# (mmax=0), or more generally with mmax&gt;0;
# for spheroidal systems, DensityClassic[TopHat/Linear] or DensitySphHarm may be more suitable,
# and in any case, the choice of radial [and possibly vertical] grid requires careful consideration.
# Here we do it automatically to ensure that the grid covers almost the entire model
# and has roughly equal mass in each shell (for spherical) or slab (for cylindrical grids),
# but this might not be suitable for every case; in particular, one may wish to make the grids
# denser in the central region to better constrain the 3d density profile near the black hole.
densityParams = dict(type = (
    'DensityClassicTopHat',
    'DensityClassicLinear',
    'DensitySphHarm',
    'DensityCylindricalTopHat',
    'DensityCylindricalLinear')[4])   # [REQ] choose one of these types!
# use the discrete samples from the density profile to choose the grid parameters
samples = densityStars.sample(10000)[0]
if densityParams['type'] == 'DensityClassicTopHat' or densityParams['type'] == 'DensityClassicLinear':
    # create a grid in elliptical radius with axis ratio chosen to [roughly] match those of the density profile
    axes = numpy.percentile(numpy.abs(samples), 90, axis=0)  # three principal axes in the outer part of the profile
    axes/= numpy.exp(numpy.mean(numpy.log(axes)))  # normalize so that the product of three axes is unity
    ellrad = numpy.sum((samples / axes)**2, axis=1)**0.5
    # [OPT] make the inner grid segment contain 1% of the total mass
    # (to better constrain the density near the black hole, though this may need some further tuning),
    # and the remaining segments contain roughly equal fractions of mass up to 99% of the total mass
    densityParams['gridr'] = numpy.hstack([0, numpy.percentile(ellrad, tuple(numpy.linspace(1, 99, 24))) ])
    densityParams['axisRatioY'] = axes[1] / axes[0]
    densityParams['axisRatioZ'] = axes[2] / axes[0]
    print('%s grid in elliptical radius: %s, axis ratios: y/x=%.3g, z/x=%.3g' %
        (densityParams['type'], densityParams['gridr'], densityParams['axisRatioY'], densityParams['axisRatioZ']))
    # [OPT] each shell in the elliptical radius is divided in three equal 'panes'
    # adjacent to each of the principal axes, and then each pane is further divided
    # into a square grid of cells with stripsPerPane elements on each side
    densityParams['stripsPerPane'] = 2
elif densityParams['type'] == 'DensitySphHarm':
    # this discretization scheme uses a grid in spherical radius and a spherical-harmonic expansion in angles
    sphrad = numpy.sum(samples**2, axis=1)**0.5
    # [OPT] same procedure as above, using roughly equal-mass bins in spherical radius except the innermost one
    densityParams['gridr'] = numpy.hstack([0, numpy.percentile(sphrad, tuple(numpy.linspace(1, 99, 24))) ])
    # [OPT] order of angular spherical-harmonic expansion in theta and phi (must be even)
    densityParams['lmax'] = 0 if symmetry[0]=='s' else 8
    densityParams['mmax'] = 0 if symmetry[0]!='t' else 6
    print('%s grid in spherical radius: %s, lmax=%i, mmax=%i' %
        (densityParams['type'], densityParams['gridr'], densityParams['lmax'], densityParams['mmax']))
elif densityParams['type'] == 'DensityCylindricalTopHat' or densityParams['type'] == 'DensityCylindricalLinear':
    sampleR = (samples[:,0]**2 + samples[:,1]**2)**0.5
    samplez = abs(samples[:,2])
    # [OPT] choose the grids in R and z so that each 'slab' (1d projection along the complementary coordinate)
    # contains approximately equal mass, though this doesn't guarantee that the 2d cells would be even roughly balanced
    densityParams['gridR'] = numpy.hstack([0, numpy.percentile(sampleR, tuple(numpy.linspace(1, 99, 20))) ])
    densityParams['gridz'] = numpy.hstack([0, numpy.percentile(samplez, tuple(numpy.linspace(1, 99, 15))) ])
    # [OPT] number of azimuthal-harmonic coefficients (0 for axisymmetric systems)
    densityParams['mmax']  = 0 if symmetry[0]!='t' else 6
    print('%s grid in R: %s, z: %s, mmax=%i' %
        (densityParams['type'], densityParams['gridR'], densityParams['gridz'], densityParams['mmax']))

datasets.append(agama.schwarzlib.DensityDataset(
    density=densityStars,
    # [OPT] fractional tolerance (e.g., 0.01) on the values of density constraints;
    # may be 0, requiring to satisfy them exactly, but in this case the solution may be infeasible
    tolerance=0.01,
    alpha=alpha,     # the orientation of intrinsic model coordinates w.r.t. the observed ones,
    beta=beta,       # specified by two Euler angles (used only for plotting the projected density)
    **densityParams  # remaining parameters set above
) )


### 1: 1st kinematic dataset

# read the Voronoi binning scheme and convert it to polygons (aperture boundaries)
vorbin1    = numpy.loadtxt(filenameVorBin1)
apertures1 = agama.schwarzlib.getBinnedApertures(xcoords=vorbin1[:,0], ycoords=vorbin1[:,1], bintags=vorbin1[:,2])
# note that when using real observational data, the coordinate system in the image plane is usually
# right-handed, with Y pointing up and X pointing right. This is different from the convention used
# in Agama, where X points left. Therefore, one will need to invert the X axis of the observed dataset:
# getBinnedApertures(xcoords=-vorbin[:,0], ...)

# use either histograms, GH moments, or classical moments (v &amp; sigma) as input data
if 'HIST' in variant:
    # [REQ] read the input kinematic data in the form of histograms;
    # if using the mock data as produced by this script, each line contains both values and errors for each velocity bin
    # in a given aperture, but when using data coming from other sources, may need to adjust the order of columns below
    kindat1 = numpy.loadtxt(filenameHist1)
    datasets.append(agama.schwarzlib.KinemDatasetHist(
        density   = densityStars,
        tolerance = 0.01,              # [REQ] relative error in fitting aperture mass constraints
        obs_val   = kindat1[:, 0::2],  # [REQ] values of velocity histograms
        obs_err   = kindat1[:, 1::2],  # [REQ] errors in these values
        obs_degree= hist_degree,
        obs_gridv = hist_gridv,
        apertures = apertures1,
        **kinemParams1
    ) )
elif 'GH' in variant:
    # [REQ] read the input kinematic data (V, sigma, higher Gauss-Hermite moments);
    # if using the mock data produced by this script, each line contains interleaved values and errors of v,sigma,h3...h6,
    # but when using data coming from other sources, may need to adjust the order of columns below
    kindat1 = numpy.loadtxt(filenameGH1)
    datasets.append(agama.schwarzlib.KinemDatasetGH(
        density   = densityStars,
        tolerance = 0.01,              # [REQ] relative error in fitting aperture mass constraints
        ghm_val   = kindat1[:, 0::2],  # [REQ] values of v,sigma,h3,h4...
        ghm_err   = kindat1[:, 1::2],  # [REQ] errors in the same order
        apertures = apertures1,
        **kinemParams1
    ) )
elif 'VS' in variant:
    # [REQ] read the input kinematic data (v and sigma, which have a different meaning here than in the case of
    # Gauss-Hermite moments above; specifically, v is the mean velocity and sigma is its standard deviation,
    # while for the GH parameterization, v and sigma are the center and width of the best-fit Gaussian);
    # data format used in this script: v, v_error, sigma, sigma_error, one line per aperture
    kindat1 = numpy.loadtxt(filenameVS1)
    datasets.append(agama.schwarzlib.KinemDatasetVS(
        density   = densityStars,
        tolerance = 0.01,              # [REQ] relative error in fitting aperture mass constraints
        vs_val   = kindat1[:, 0::2],   # [REQ] values of v,sigma
        vs_err   = kindat1[:, 1::2],   # [REQ] errors in the same order
        apertures = apertures1,
        **kinemParams1
    ) )


### 2: [OPT] same for the 2nd kinematic dataset (and similarly for all subsequent ones)
vorbin2     = numpy.loadtxt(filenameVorBin2)
apertures2  = agama.schwarzlib.getBinnedApertures(xcoords=vorbin2[:,0], ycoords=vorbin2[:,1], bintags=vorbin2[:,2])
if 'HIST' in variant:
    kindat2 = numpy.loadtxt(filenameHist2)
    datasets.append(agama.schwarzlib.KinemDatasetHist(
        density   = densityStars,
        tolerance = 0.01,
        obs_val   = kindat2[:, 0::2],
        obs_err   = kindat2[:, 1::2],
        obs_degree= hist_degree,
        obs_gridv = hist_gridv,
        apertures = apertures2,
        **kinemParams2
    ) )
elif 'GH' in variant:
    kindat2 = numpy.loadtxt(filenameGH2)
    if True: datasets.append(agama.schwarzlib.KinemDatasetGH(
        density   = densityStars,
        tolerance = 0.01,
        ghm_val   = kindat2[:, 0::2],
        ghm_err   = kindat2[:, 1::2],
        apertures = apertures2,
        **kinemParams2
    ) )
elif 'VS' in variant:
    kindat2 = numpy.loadtxt(filenameVS2)
    datasets.append(agama.schwarzlib.KinemDatasetVS(
        density   = densityStars,
        tolerance = 0.01,
        vs_val   = kindat2[:, 0:4:2],
        vs_err   = kindat2[:, 1:4:2],
        apertures = apertures2,
        **kinemParams2
    ) )


# create a dark halo according to the provided parameters (type, scale radius and circular velocity)
if rhalo&gt;0 and vhalo&gt;0:
    if   halotype.upper() == 'LOG':
        densityHalo = agama.schwarzlib.makeDensityLogHalo(rhalo, vhalo)
    elif halotype.upper() == 'NFW':
        densityHalo = agama.schwarzlib.makeDensityNFWHalo(rhalo, vhalo)
    else:
        raise ValueError('Invalid halo type')
else:
    densityHalo = agama.Density(type='Plummer', mass=0, scaleRadius=1)  # no halo

# additional density component for constructing the initial conditions:
# create more orbits at small radii to better resolve the kinematics around the central black hole
densityExtra = agama.Density(type='Dehnen', scaleradius=1)

# fiducialMbh: Mbh used to construct initial conditions (may differ from Mbh used to integrate orbits;
# the idea is to keep fiducialMbh fixed between runs with different Mbh, so that the initial conditions
# for the orbit library are the same, compensating one source of noise in chi2 due to randomness)
fiducialMbh = densityStars.totalMass() * 0.01

# potential of the galaxy, excluding the central BH
pot_gal   = agama.Potential(type='Multipole',
    density=agama.Density(densityStars, densityHalo),  # all density components together
    lmax=32,  # lmax is set to a large value to accurately represent a disky density profile
    mmax=0 if symmetry[0]!='t' else 6, gridSizeR=40)  # mmax&gt;0 only for triaxial systems
# potential of the central BH
pot_bh    = agama.Potential(type='Plummer', mass=Mbh, scaleRadius=1e-4)
# same for the fiducial BH
pot_bhfidu= agama.Potential(type='Plummer', mass=fiducialMbh, scaleRadius=1e-4)
# total potential of the model (used to integrate the orbits)
pot_total = agama.Potential(pot_gal, pot_bh)
# total potential used to generate initial conditions only
pot_fidu  = agama.Potential(pot_gal, pot_bhfidu)


### finally, decide what to do
if command == 'RUN':

    # prepare initial conditions - use the same total potential independent of the actual Mbh
    # [OPT]: choose the sampling method: isotropic IC drawn from Eddington DF are created by
    #   density.sample(numorbits, potential)
    # while IC with preferential rotation (for disky models) are constructed from axisymmetric Jeans eqns by
    #   density.sample(numorbits, potential, beta={0-0.5}, kappa={1 or -1, depending on sign of rotation})
    # Here we add together two sets of IC - the majority of orbits sampled with axisymmetric Jeans eqns,
    # plus a small fraction additionally sampled from the central region to improve coverage.
    ic = numpy.vstack((
        densityStars.sample(int(numOrbits*0.85), potential=pot_fidu, beta=0.3, kappa=1)[0],
        densityExtra.sample(int(numOrbits*0.15), potential=pot_fidu)[0] ))


    # launch the orbit library and perform fits for several values of Upsilon;
    agama.schwarzlib.runModel(datasets=datasets, potential=pot_total, ic=ic,
        intTime=intTime, Upsilon=Upsilon, multstep=multstep, regul=regul, Omega=Omega,
        # [OPT] prefix - common part of the file name storing LOSVDs of each model in this series;
        # the value of Upsilon is appended to each filename;  here one may adjust the string format or the list of parameters to store
        filePrefix = 'M%.3g_O%.3g_Rh%.3g_Vh%.3g_i%.0f_a%.0f_N%d_R%.2f_%s' %
            (Mbh, Omega, rhalo, vhalo, incl, alpha_deg, numOrbits, regul, variant),
        # [OPT] data stored at the beginning of each line (= a separate model with a given Upsilon) in the results/summary file;
        # usually should contains the same parameters as in filePrefix, but separated by tabs.
        # Keep track of the order of parameters - when reading the results file in the plotting part of this script, the order should be the same.
        # After the linePrefix, each line in the result file will contain the value of Upsilon, values of chi2 for each dataset,
        # regularization penalty, and the name of the file with LOSVD of that model.
        linePrefix = '\t'.join([ '%.3g' % Mbh, '%.3g' % Omega, '%.3g' % rhalo, '%.3g' % vhalo,
            '%.0f' % incl, '%.0f' % alpha_deg, '%d' % numOrbits, '%.2f' % regul ]),
        # [OPT] results/summary file
        fileResult = fileResult,
        # [OPT] parameters for the N-body snapshot representing the best-fit model
        nbody = nbody, nbodyFormat = nbodyFormat )

elif command == 'TEST':

    # plot various diagnostics to check if the parameters of the model are reasonable
    import matplotlib.pyplot as plt
    ax = plt.subplots(2, 2, figsize=(12,8), dpi=100)[1].reshape(-1)
    # radial range of these plots is somewhat arbitrary, but should encompass the extent of kinematic data (may need adjustment)
    gridrmajor = numpy.logspace(numpy.log10(0.05), numpy.log10(200))
    gridrminor = numpy.logspace(numpy.log10(0.05), numpy.log10(100))
    # surface density along the major and minor axes
    Sigmamajor = densityStars.projectedDensity(numpy.column_stack((gridrmajor, gridrmajor*0)), beta=beta, alpha=alpha)
    Sigmaminor = densityStars.projectedDensity(numpy.column_stack((gridrminor*0, gridrminor)), beta=beta, alpha=alpha)
    ax[0].loglog(gridrmajor, Sigmamajor, color='b', label=r'$\Sigma(R)$ major')
    ax[0].loglog(gridrminor, Sigmaminor, color='r', label=r'$\Sigma(R)$ minor')
    ax[0].set_xlabel('projected radius')
    ax[0].set_ylabel('surface density')
    ax[0].legend(loc='lower left', frameon=False)
    ax[0].set_xlim(min(gridrmajor), max(gridrmajor))
    ax[0].set_ylim(min(Sigmamajor), max(Sigmamajor))

    # deprojected 3d density along the major (x) and minor (z) axes
    rhomajor = densityStars.density(numpy.column_stack((gridrmajor, gridrmajor*0, gridrmajor*0)))
    rhominor = densityStars.density(numpy.column_stack((gridrminor*0, gridrminor*0, gridrminor)))
    ax[2].loglog(gridrmajor, rhomajor, color='b', label=r'$\rho(R,z=0)$')
    ax[2].loglog(gridrminor, rhominor, color='r', label=r'$\rho(R=0,z)$')
    ax[2].set_xlabel('radius')
    ax[2].set_ylabel('3d density')
    ax[2].legend(loc='lower left', frameon=False)
    ax[2].set_xlim(min(gridrmajor), max(gridrmajor))
    ax[2].set_ylim(min(rhomajor)/5, max(rhomajor))
    # also show the location of nodes of the 3d density discretization grid
    if 'gridR' in densityParams: gridnodesmajor = densityParams['gridR']
    if densityParams['type'] == 'DensityCylindricalTopHat' or densityParams['type'] == 'DensityCylindricalLinear':
        ax[2].plot(densityParams['gridR'], numpy.interp(densityParams['gridR'], gridrmajor, rhomajor), 'b|', ms=6)
        ax[2].plot(densityParams['gridz'], numpy.interp(densityParams['gridz'], gridrminor, rhominor), 'r|', ms=6)
    else:
        if 'axisRatioZ' in densityParams:   # elliptical grid in DensityClassic[TopHat/Linear]
            multX = (densityParams['axisRatioY'] * densityParams['axisRatioZ'])**(-1./3)  # scaling along the X (major) axis
            multZ =  densityParams['axisRatioZ'] * multX                                  # scaling along the Z (minor) axis
        else:
            multX = multZ = 1
        ax[2].plot(densityParams['gridr']*multX, numpy.interp(densityParams['gridr']*multX, gridrmajor, rhomajor), 'b|', ms=6)
        ax[2].plot(densityParams['gridr']*multZ, numpy.interp(densityParams['gridr']*multZ, gridrminor, rhominor), 'r|', ms=6)

    # values of discretized density constraints: this is rather technical, but a large spread in values
    # (more than a few orders of magnitude) may present trouble for the solution - then one would need
    # to change some grid parameters, so that the distribution of cell masses is more uniform
    ax[1].plot(datasets[0].cons_val[1:])
    ax[1].set_xlabel('constraint index')
    ax[1].set_ylabel('density constraint value')
    ax[1].set_yscale('log')

    # plot observed parameters of GH expansion v0 and sigma against radius
    if 'HIST' not in variant:
        aperture_radii1 = numpy.array([numpy.mean(ap[:,0]**2+ap[:,1]**2)**0.5  for ap in apertures1])
        aperture_radii2 = numpy.array([numpy.mean(ap[:,0]**2+ap[:,1]**2)**0.5  for ap in apertures2])
        ax[3].scatter(aperture_radii1, abs(kindat1[:,0]), label='v', c='y', linewidths=0)
        ax[3].scatter(aperture_radii1, kindat1[:,2],  label='sigma', c='c', linewidths=0)
        ax[3].scatter(aperture_radii2, abs(kindat2[:,0]), c='y', marker='x')
        ax[3].scatter(aperture_radii2, kindat2[:,2],      c='c', marker='x')
    # plot circular-velocity curves of each potential component
    for name, pot in [
        ['stars', agama.Potential(type='Multipole', density=densityStars, mmax=0, lmax=32)],
        ['halo',  agama.Potential(type='Multipole', density=densityHalo)],
        ['BH',    pot_bh],
        ['total', pot_total] ]:
        vcirc = (-gridrmajor * pot.force(numpy.column_stack((gridrmajor, gridrmajor*0, gridrmajor*0)))[:,0] * Upsilon)**0.5
        ax[3].plot(gridrmajor, vcirc, label=name)
    ax[3].legend(loc='upper left', scatterpoints=1, ncol=(2 if 'HIST' in variant else 3), frameon=False)
    ax[3].set_xscale('log')
    ax[3].set_xlim(min(gridrmajor), max(gridrmajor))
    ax[3].set_ylim(0, max(vcirc)*1.25)
    ax[3].set_xlabel('radius')
    ax[3].set_ylabel('circular velocity')

    plt.tight_layout()
    plt.show()

elif command == 'PLOT':

    try:
        tab = numpy.loadtxt(fileResult, dtype=str)
        # keep only the models with the same parameters as given in the command-line arguments (or their default values),
        # except the two parameters (Mbh and M/L) that are shown on the chi2 plane 
        # [OPT]: may choose different fixed/free params, but make sure the order of columns corresponds to that provided to runModel
        filt = (
            (tab[:,1].astype(float) == Omega) *
            (tab[:,2].astype(float) == rhalo) *
            (tab[:,3].astype(float) == vhalo) *
            (tab[:,4].astype(float) == incl) *
            (tab[:,5].astype(float) == alpha_deg) *
            (tab[:,6].astype(int  ) == numOrbits) *
            (tab[:,7].astype(float) == regul)
        )
        tab = tab[filt]
        if len(tab) == 0:
            print('No models satisfying all criteria are found in %s' % fileResult)
    except:
        print('File not found: %s' % fileResult)
        tab = numpy.zeros((0,12))
    filenames = tab[:,-1]                 # last column is the filename of LOSVD file for each model
    tab = tab[:,:-1].astype(float)        # remaining columns are numbers
    Mbh = tab[:,0] * tab[:,8]             # the order of parameters is the same as in linePrefix provided to runModel
    ML  = tab[:,8]                        # Upsilon is appended as the first column after those provided in linePrefix
    chi2= numpy.sum(tab[:,10:-1], axis=1) # chi2 values are stored separately for each dataset, but here we combine all of them except regularization penalty
    # launch interactive plot with [OPT] Mbh vs M/L as the two coordinate axes displayed in chi2 plane (may choose a different pair of parameters)
    agama.schwarzlib.runPlot(datasets=datasets, aval=Mbh, bval=ML, chi2=chi2, filenames=filenames,
        # [OPT] various adjustable parameters for the plots (ranges, names, etc.) - most have reasonable default values
        alabel='Mbh', blabel='M/L', alim=(0, 4e8), blim=(0.9, 1.2), vlim=(-500,500),
        v0lim=(-150,150), sigmalim=(40,160), v0err=15.0, sigmaerr=15.0, potential=pot_total)

else:
    exit('Nothing to do!')
</file>
    <file path="py/example_gala.py">
import numpy, agama, gala.potential, time; from timeit import timeit
numpy.set_printoptions(linewidth=100, precision=8)
numpy.random.seed(42)

gpot1=gala.potential.PlummerPotential(1,1) # native Gala potential
Gpot1=agama.GalaPotential(gpot1)           # chimera object providing both Gala and Agama interfaces
apot1=agama.Potential(type='plummer')      # native Agama potential
Apot1=agama.GalaPotential(type='plummer')  # exactly the same functionality for Agama, but adds a Gala interface

gpot2=gala.potential.MiyamotoNagaiPotential(m=1, a=1, b=0.1)
Gpot2=agama.GalaPotential(gpot2)
Apot2=agama.GalaPotential(type='miyamotonagai', scaleradius=1, scaleheight=0.1)

gpot3=gala.potential.HernquistPotential(m=2.3, c=4.5)
Gpot3=agama.GalaPotential(gpot3)
Apot3=agama.GalaPotential(type='dehnen', gamma=1, mass=2.3, scaleradius=4.5)

gpot4=gala.potential.NFWPotential(m=1.2, r_s=3.4)
Gpot4=agama.GalaPotential(gpot4)
Apot4=agama.GalaPotential(type='nfw', mass=1.2, scaleradius=3.4)

### this one fails probably because of some bug in handling vectorized inputs in gala.KuzminPotential
#gpot5=gala.potential.KuzminPotential(m=1, a=1, units=None)   # pure-python potential
gpot5=gala.potential.HarmonicOscillatorPotential(omega=1.0)  # another pure-python potential
Gpot5=agama.GalaPotential(gpot5)
Apot5=agama.GalaPotential(type='harmonic', omega=1.0)

# some random test points
points=numpy.random.normal(size=(5,3))  # positions
pointv=numpy.random.normal(size=(20,6))  # positions and velocities

def test(gpot, Gpot, Apot, test_hessian=False):
    '''
    gpot is the native gala potential;
    Gpot is the same one accessed through wrapper;
    Apot is the equivalent native agama potential
    '''
    print(&quot;\nTesting G=%s and A=%s&quot; % (Gpot, Apot))
    #0. retrieve dimensional factors for converting the output of agama-related methods
    # to the potential's unit system (assuming it is identical for both potentials)
    lu = Gpot.units['length']
    pu = Gpot.units['energy'] / Gpot.units['mass']
    vu = Gpot.units['length'] / Gpot.units['time']
    fu = Gpot.units['length'] / Gpot.units['time']**2
    du = Gpot.units['mass'] / Gpot.units['length']**3
    #1. test that the values of potential coincide, using both interfaces
    print(&quot;G energy vs potential: %.3g&quot; % numpy.max(abs(Gpot.energy(points.T) / Gpot.potential(points)/pu - 1)))
    print(&quot;A energy vs potential: %.3g&quot; % numpy.max(abs(Apot.energy(points.T) / Apot.potential(points)/pu - 1)))
    print(&quot;G energy vs A energy:  %.3g&quot; % numpy.max(abs(Gpot.energy(points.T) / Apot.energy(points.T) - 1)))
    #2. test the accelerations - these don't exactly match,
    # because agama evaluates them by finite-differencing if initialized from a &quot;foreign&quot; gala potential
    print(&quot;G acceleration vs force:  %.3g&quot; % numpy.max(abs(Gpot.acceleration(points.T).T / Gpot.force(points)/fu - 1)))
    print(&quot;A acceleration vs force:  %.3g&quot; % numpy.max(abs(Apot.acceleration(points.T).T / Apot.force(points)/fu - 1)))
    print(&quot;G gradient vs A gradient: %.3g&quot; % numpy.max(abs(Gpot.gradient(points.T) / Apot.gradient(points.T) - 1)))
    #3. test the hessian
    print(&quot;G acc.deriv vs A acc.deriv:  %.3g&quot; % numpy.max(abs(Gpot.eval(points,der=1) / Apot.eval(points,der=1) - 1)))
    print(&quot;G hessian vs A hessian:      %.3g&quot; % numpy.max(abs(Gpot.hessian(points.T) / Apot.hessian(points.T) - 1)))
    #4. test density - again no exact match since it is computed by finite differences in Gpot
    print(&quot;G density [gala] vs [agama]: %.3g&quot; % numpy.max(abs(Gpot.density(points.T) / Gpot.agamadensity(points)/du - 1)))
    print(&quot;A density [gala] vs [agama]: %.3g&quot; % numpy.max(abs(Apot.density(points.T) / Apot.agamadensity(points)/du - 1)))
    print(&quot;G density vs A density:      %.3g&quot; % numpy.max(abs(Gpot.density(points.T) / Apot.density(points.T) - 1)))
    #5. test orbit integration using both gala and agama routines with either potential
    # create some initial conditions for orbits:
    # take the positions and assign velocity to be comparable to circular velocity at each point
    ic = numpy.hstack((points, numpy.random.normal(size=points.shape) * Apot.circular_velocity(points.T)[:,None] / vu))
    t0 = time.time()
    g_orb_g = gpot.integrate_orbit(ic.T, dt=10, n_steps=100, Integrator=gala.integrate.DOPRI853Integrator, Integrator_kwargs=dict(rtol=1e-8,atol=0))
    t1 = time.time()
    g_orb_G = Gpot.integrate_orbit(ic.T, dt=10, n_steps=100, Integrator=gala.integrate.DOPRI853Integrator, Integrator_kwargs=dict(rtol=1e-8,atol=0))
    t2 = time.time()
    g_orb_A = Apot.integrate_orbit(ic.T, dt=10, n_steps=100, Integrator=gala.integrate.DOPRI853Integrator, Integrator_kwargs=dict(rtol=1e-8,atol=0))
    t3 = time.time()
    a_orb_G = numpy.dstack(agama.orbit(potential=Gpot, ic=ic, time=1000, trajsize=101, dtype=float)[:,1])
    t4 = time.time()
    a_orb_A = numpy.dstack(agama.orbit(potential=Apot, ic=ic, time=1000, trajsize=101, dtype=float)[:,1])
    t5 = time.time()
    print(&quot;gala  orbit integration for g (native): %.4g s&quot; % (t1-t0) +
         &quot;, G (wrapper): %.4g s&quot; % (t2-t1) + &quot;, A: %.4g s&quot; % (t3-t2))
    print(&quot;agama orbit integration for G: %.4g s&quot; % (t4-t3) + &quot;, A: %.4g s&quot; % (t5-t4))
    deltaEg = numpy.max(abs(g_orb_G.energy()[-1] / g_orb_G.energy()[0] - 1))
    Eainit  = Apot.potential(a_orb_A[0, 0:3].T) + 0.5*numpy.sum(a_orb_A[0, 3:6]**2, axis=0)
    Eafinal = Apot.potential(a_orb_A[-1,0:3].T) + 0.5*numpy.sum(a_orb_A[-1,3:6]**2, axis=0)
    deltaEa = numpy.max(abs(Eafinal / Eainit - 1))
    # shape of the output is different: for gala, it is 3 x nsteps x norbits; for agama (dstack'ed) - nsteps x 6 x norbits
    g_orb_G = g_orb_G.xyz.reshape(3, len(g_orb_G.t), len(ic))
    g_orb_A = g_orb_A.xyz.reshape(3, len(g_orb_A.t), len(ic))
    a_orb_G = numpy.swapaxes(a_orb_G*lu, 0, 1)[0:3]  # now the shape is 3 x nsteps x norbits
    a_orb_A = numpy.swapaxes(a_orb_A*lu, 0, 1)[0:3]
    maxrad  = numpy.max(numpy.sum(a_orb_A**2, axis=0)**0.5, axis=0)  # normalization factor for relative deviations in position
    print(&quot;gala  orbits G vs A: %.3g&quot; % numpy.max(numpy.sum(abs(g_orb_G - g_orb_A), axis=0) / maxrad))
    print(&quot;agama orbits G vs A: %.3g&quot; % numpy.max(numpy.sum(abs(a_orb_G - a_orb_A), axis=0) / maxrad))
    print(&quot;gala vs agama: %.3g&quot;       % numpy.max(numpy.sum(abs(g_orb_G - a_orb_G), axis=0) / maxrad))
    print(&quot;energy error in gala: %.3g, agama: %.3g&quot; % (deltaEg, deltaEa))
    # illustrate that the hessian is broken (?) - compute it once for all points, then for each point in a loop
    if test_hessian:
        print(&quot;Checking vectorization of hessian for G: the two arrays should be equivalent, but they are not&quot;)
        print(&quot;Vectorized:\n&quot;, Gpot.hessian(points.T))
        print(&quot;Pointwise:\n&quot;, numpy.dstack([Gpot.hessian(point) for point in points]))
        print(&quot;Checking vectorization of hessian for A: the two arrays should be equivalent&quot;)
        print(&quot;Vectorized:\n&quot;, Apot.hessian(points.T))
        print(&quot;Pointwise:\n&quot;, numpy.dstack([Apot.hessian(point) for point in points]))


test(gpot1, Gpot1, Apot1)
test(gpot2, Gpot2, Apot2)
test(gpot3, Gpot3, Apot3)
test(gpot4, Gpot4, Apot4)
#test(gpot5, Gpot5, Apot5)  #### this one also fails because of hessian (and the absense of density method in gala)

# now test potentials defined with units
agama.setUnits(length=1, mass=1, velocity=977.792594852689)  # velocity unit = 1 kpc / 1 Myr
gpot6=gala.potential.MilkyWayPotential()
Gpot6=agama.GalaPotential(gpot6)
Apot6=agama.GalaPotential(
    dict(type='miyamotonagai', mass=6.8e10, scaleradius=3.0, scaleheight=0.28),  # disk
    dict(type='dehnen', mass=5.00e9, scaleradius=1.0),   # bulge
    dict(type='dehnen', mass=1.71e9, scaleradius=0.07),  # nucleus
    dict(type='nfw',    mass=5.4e11, scaleradius=15.62), # halo
    units=Gpot6.units)

test(gpot6, Gpot6, Apot6, test_hessian=False)
</file>
    <file path="py/example_galpy.py">
#!/usr/bin/python
&quot;&quot;&quot;
This script illustrates the use of the class agama.GalpyPotential, which is a subclass of
both galpy.potential.Potential and agama.Potential, and provides both interfaces
suitable for orbit integration and action finder routines.
Internally, this potential can represent either a native galpy potential or a native agama potential,
depending on how it is constructed, but the public API is the same in both cases.
Of course, routines from agama will be much more efficient when this object represents an agama-native
potential internally; the reverse is not necessarily true, since galpy does not know whether this
object internally represents a galpy-native or agama-native potential, and hence C acceleration
will not be used even if the galpy-native potential supports it.
&quot;&quot;&quot;

import agama
import galpy.potential, galpy.actionAngle, galpy.orbit
import numpy, time, matplotlib.pyplot as plt

### galpy uses these units, so instruct agama to do the same
agama.setUnits( mass=1., length=8., velocity=220.)  # Msun, kpc, km/s

### set up galpy potential
g_pot_native = galpy.potential.MWPotential2014

### set up a chimera potential that is initialized from the existing galpy potential,
### and provides both galpy and agama interfaces - when used with galpy routines,
### its behaviour (but not performance!) should be identical to g_pot_native
g_pot_hybrid = agama.GalpyPotential(g_pot_native)

### set up equivalent potential from the agama library (up to a constant offset)
a_pot_native = agama.Potential(&quot;../data/MWPotential2014galpy.ini&quot;)

### set up another chimera that is now initialized from the existing agama potential,
### and again provides both interfaces -- when used with agama classes and routines,
### its behaviour and performance are identical to a_pot_native
a_pot_hybrid = agama.GalpyPotential(a_pot_native)

### note: the same effect is achieved by initializing the hybrid potential directly from the file
a_pot_hybrid = agama.GalpyPotential(&quot;../data/MWPotential2014galpy.ini&quot;)

### since a galpy-native potential has poor performance in computationally heavy tasks within agama,
### we construct an approximation for it represented by a native CylSpline potential expansion
dt = time.time()
### note: the CylSpline expansion would be better suited for the disky potential, but unfortunately,
### it cannot be used because some of galpy potentials do not return a valid value at r=0;
### instead we use a Multipole expansion (which never needs the value of the original potential at 0);
### it is less accurate in this case, but still acceptable
#g_pot_approx = agama.Potential(type='CylSpline', potential=g_pot_hybrid, symmetry='axi', rmin=0.01, rmax=10, zmin=0.01, zmax=10)
g_pot_approx = agama.Potential(type='Multipole', potential=g_pot_hybrid, symmetry='axi', rmin=0.01, rmax=10, lmax=20)
#g_pot_approx.export('example_galpy.ini')  # may save the potential coefs for later use
print('Time to set up a CylSpline approximation to galpy potential: %.4g s' % (time.time()-dt))

### initialization of the action finder needs to be done once for the given potential
dt = time.time()
a_actfinder = agama.ActionFinder(a_pot_hybrid, interp=False)
print('Time to set up agama action finder: %.4g s' % (time.time()-dt))
### we have a faster but less accurate &quot;interpolated action finder&quot;, which takes a bit longer to initialize
dt = time.time()
i_actfinder = agama.ActionFinder(a_pot_hybrid, interp=True)
print('Time to set up agama interpolated action finder: %.4g s' % (time.time()-dt))

### conversion from prolate spheroidal to cylindrical coords
def ProlSphToCyl(la, nu, fd):
    return ( ((la - fd*fd) * (1 - abs(nu)/fd**2))**0.5, (la*abs(nu))**0.5 / fd * numpy.sign(nu) )

### show coordinate grid in prolate spheroidal coords
def plotCoords(fd, maxR):
    la = numpy.linspace(0, maxR, 32)**2 + fd**2
    ls = numpy.linspace(0, 1, 21)
    nu = ls*ls*(3-2*ls)*fd**2
    for i in range(len(la)):
        lineR, linez = ProlSphToCyl(la[i], nu, fd)
        plt.plot(lineR, linez, 'grey', lw=0.5)
        plt.plot(lineR,-linez, 'grey', lw=0.5)
    for i in range(len(nu)):
        lineR, linez = ProlSphToCyl(la, nu[i], fd)
        plt.plot(lineR, linez, 'grey', lw=0.5)
        plt.plot(lineR,-linez, 'grey', lw=0.5)

### convert position/velocity from cylindrical coordinates (in the galpy convention) to cartesian
def toCyl(car):
    x, y, z, vx, vy, vz = numpy.array(car).T
    R = (x**2 + y**2)**0.5
    phi = numpy.arctan2(y, x)
    cosphi, sinphi = numpy.cos(phi), numpy.sin(phi)
    vR   = vx*cosphi + vy*sinphi
    vphi = vy*cosphi - vx*sinphi
    return numpy.array([R, vR, vphi, z, vz, phi]).T

### convert position/velocity from cartesian to cylindrical system in the galpy convention
def toCar(cyl):
    R, vR, vphi, z, vz, phi = numpy.array(cyl).T
    cosphi, sinphi = numpy.cos(phi), numpy.sin(phi)
    return numpy.array([R*cosphi, R*sinphi, z, vR*cosphi-vphi*sinphi, vR*sinphi+vphi*cosphi, vz]).T

### run tests for the given input point and orbit size;
### ic is the array of initial conditions in the galpy convention: R, vR, vphi, z, vz, phi
def compare(ic, inttime, numsteps):
    times = numpy.linspace(0, inttime, numsteps)
    times1 = times[:numsteps//10]   # compute only 1/10th of the orbit to save time in galpy

    ### integrate the orbit in galpy using the native MWPotential2014 from galpy
    g_orb_obj = galpy.orbit.Orbit(ic)
    dt = time.time()
    g_orb_obj.integrate(times, g_pot_native)
    g_orb_g_native = g_orb_obj.getOrbit()
    print('Time to integrate the orbit in galpy, using galpy-native potential [1]: %.4g s' % (time.time()-dt))

    ### integrate the orbit again with the galpy routine, but now using the chimera potential
    ### representing a galpy-native underlying potential.
    ### since galpy has no idea that this potential has a C implementation, it switches to a slower
    ### pure-Python integration algorithm, so to save time, we compute only 1/10th of the orbit
    dt = time.time()
    g_orb_obj.integrate(times1, g_pot_hybrid)
    g_orb_g_hybrid = g_orb_obj.getOrbit()
    print('Time to integrate 1/10th of the orbit in galpy, using galpy-hybrid potential [2]: %.4g s' %
        (time.time()-dt))

    ### integrate the orbit with the galpy routine, but using the chimera potential
    ### representing an agama-native underlying potential instead
    ### (also much slower because of repeated transfer of control between C++ and Python)
    dt = time.time()
    g_orb_obj.integrate(times1, a_pot_hybrid)
    g_orb_a_hybrid = g_orb_obj.getOrbit()
    print('Time to integrate 1/10th of the orbit in galpy, using agama-hybrid potential [3]: %.4g s' %
        (time.time()-dt))

    ### integrate the orbit with the agama routine, using the galpy-native potential through the chimera
    ### (note different calling conventions and the use of cartesian coordinates)
    dt = time.time()
    a_orb_g_hybrid = agama.orbit(potential=g_pot_hybrid, time=inttime, trajsize=numsteps, ic=toCar(ic))[1]
    print('Time to integrate the orbit in agama, using galpy-hybrid potential [4]: %.4g s' % (time.time()-dt))

    ### integrate the orbit in a native agama potential approximation constructed from the galpy potential
    dt = time.time()
    a_orb_g_approx = agama.orbit(potential=g_pot_approx, time=inttime, trajsize=numsteps, ic=toCar(ic))[1]
    print('Time to integrate the orbit in agama, using galpy-approx potential [5]: %.4g s' % (time.time()-dt))

    ### using both the orbit integration routine and the native potential from agama - much faster
    dt = time.time()
    a_orb_a_native = agama.orbit(potential=a_pot_native, time=inttime, trajsize=numsteps, ic=toCar(ic))[1]
    print('Time to integrate the orbit in agama, using agama-native potential [6]: %.4g s' % (time.time()-dt))

    ### the same but with the chimera potential representing an agama-native potential
    ### (should be identical to the above, since in both cases the same underlying C++ object is used)
    dt = time.time()
    a_orb_a_hybrid = agama.orbit(potential=a_pot_hybrid, time=inttime, trajsize=numsteps, ic=toCar(ic))[1]
    print('Time to integrate the orbit in agama, using agama-hybrid potential [7]: %.4g s' % (time.time()-dt))

    ### compare the differences between the orbits computed in different ways
    ### (both the potentials and integration routines are not exactly equivalent);
    ### use only common initial segment (1/10th of the orbit) for comparison
    print('Differences between orbits: ' +
        '[1]-[2]=%g, ' % numpy.max(numpy.abs(toCar(g_orb_g_native[:len(times1)])-toCar(g_orb_g_hybrid))) +
        '[1]-[3]=%g, ' % numpy.max(numpy.abs(toCar(g_orb_g_native[:len(times1)])-toCar(g_orb_a_hybrid))) +
        '[1]-[4]=%g, ' % numpy.max(numpy.abs(toCar(g_orb_g_native)-a_orb_g_hybrid)[:len(times1)]) +
        '[1]-[5]=%g, ' % numpy.max(numpy.abs(toCar(g_orb_g_native)-a_orb_g_approx)[:len(times1)]) +
        '[1]-[6]=%g, ' % numpy.max(numpy.abs(toCar(g_orb_g_native)-a_orb_a_native)[:len(times1)]) +
        '[6]-[4]=%g, ' % numpy.max(numpy.abs(a_orb_a_native-a_orb_g_hybrid)[:len(times1)]) +
        '[6]-[7]=%g'   % numpy.max(numpy.abs(a_orb_a_native-a_orb_a_hybrid)[:len(times1)]) )  # should be zero

    ### convert the orbits to the same galpy coordinate convention
    gg_orb = g_orb_g_native  # it's already in this convention
    ga_orb = g_orb_a_hybrid
    ag_orb = toCyl(a_orb_g_hybrid)
    aa_orb = toCyl(a_orb_a_native)
    ### in galpy, this is the only tool that can estimate focal distance,
    ### but it requires the orbit to be computed first
    delta = float(galpy.actionAngle.estimateDeltaStaeckel(g_pot_hybrid, gg_orb[:,0], gg_orb[:,3]))
    print('Focal distance estimated from the entire trajectory: Delta=%.4g' % delta)

    ### plot the orbit(s) in R,z plane, along with the prolate spheroidal coordinate grid
    plt.figure(figsize=(12,8))
    plt.axes([0.06, 0.56, 0.43, 0.43])
    plotCoords(delta, 1.5)
    plt.plot(gg_orb[:,0],gg_orb[:,3], 'b', label='galpy native')  # R,z
    plt.plot(aa_orb[:,0],aa_orb[:,3], 'g', label='agama native', dashes=[4,2])
    plt.plot(ag_orb[:,0],ag_orb[:,3], 'y', label='agama using galpy potential', dashes=[1,1])
    plt.plot(ga_orb[:,0],ga_orb[:,3], 'r', label='galpy using agama potential')
    plt.xlabel(&quot;R/8kpc&quot;)
    plt.ylabel(&quot;z/8kpc&quot;)
    plt.xlim(0, 1.2)
    plt.ylim(-1,1)
    plt.legend(loc='lower left', ncol=2)

    ### create galpy action/angle finder for the given value of Delta
    ### note: using c=False in the routine below is much slower but apparently more accurate,
    ### comparable to the agama for the same value of delta
    g_actfinder = galpy.actionAngle.actionAngleStaeckel(pot=g_pot_native, delta=delta, c=True)

    ### find the actions for each point of the orbit using galpy action finder
    dt = time.time()
    g_act = g_actfinder(gg_orb[:,0],gg_orb[:,1],gg_orb[:,2],gg_orb[:,3],gg_orb[:,4],fixed_quad=True)
    print('Time to compute actions in galpy: %.4g s' % (time.time()-dt))
    print('Jr = %.6g +- %.4g, Jz = %.6g +- %.4g' %
        (numpy.mean(g_act[0]), numpy.std(g_act[0]), numpy.mean(g_act[2]), numpy.std(g_act[2])))

    ### use the agama action routine for the same value of Delta as in galpy (explicity specify focal distance):
    ### the result is almost identical but computed much faster
    dt = time.time()
    c_act = agama.actions(point=a_orb_a_hybrid, potential=a_pot_hybrid, fd=delta)
    print('Time to compute actions in agama using galpy-estimated focal distance: %.4g s' % (time.time()-dt))
    print('Jr = %.6g +- %.4g, Jz = %.6g +- %.4g' %
        (numpy.mean(c_act[:,0]), numpy.std(c_act[:,0]), numpy.mean(c_act[:,1]), numpy.std(c_act[:,1])))

    ### use the agama action finder (initialized at the beginning) that automatically determines
    ### the best value of Delta (same computational cost as the previous one)
    dt = time.time()
    a_act = a_actfinder(a_orb_a_hybrid)   # use the focal distance estimated by action finder
    print('Time to compute actions in agama using pre-initialized focal distance: %.4g s' % (time.time()-dt))
    print('Jr = %.6g +- %.4g, Jz = %.6g +- %.4g' %
        (numpy.mean(a_act[:,0]), numpy.std(a_act[:,0]), numpy.mean(a_act[:,1]), numpy.std(a_act[:,1])))

    ### use the interpolated agama action finder (initialized at the beginning) - less accurate but faster
    dt = time.time()
    i_act = i_actfinder(a_orb_a_hybrid)
    print('Time to compute actions in agama with interpolated action finder: %.4g s' % (time.time()-dt))
    print('Jr = %.6g +- %.4g, Jz = %.6g +- %.4g' %
        (numpy.mean(i_act[:,0]), numpy.std(i_act[:,0]), numpy.mean(i_act[:,1]), numpy.std(i_act[:,1])))

    ### plot Jr vs Jz
    plt.axes([0.55, 0.56, 0.43, 0.43])
    plt.plot(g_act[0],  g_act[2],   c='b', label='galpy')
    plt.plot(c_act[:,0],c_act[:,1], c='g', label=r'agama, $\Delta=%.4f$'%delta, dashes=[4,2])
    plt.plot(a_act[:,0],a_act[:,1], c='r', label=r'agama, $\Delta=$auto')
    plt.plot(i_act[:,0],i_act[:,1], c='c', label=r'agama, interpolated')
    plt.xlabel(&quot;$J_r$&quot;)
    plt.ylabel(&quot;$J_z$&quot;)
    plt.legend(loc='lower left', frameon=False)

    ### plot Jr(t) and Jz(t)
    plt.axes([0.06, 0.06, 0.92, 0.43])
    plt.plot(times, g_act[0],   c='b', label='galpy')
    plt.plot(times, g_act[2],   c='b')
    plt.plot(times, c_act[:,0], c='g', label=r'agama, $\Delta=%.4f$'%delta, dashes=[4,2])
    plt.plot(times, c_act[:,1], c='g', dashes=[4,2])
    plt.plot(times, a_act[:,0], c='r', label=r'agama, $\Delta=$auto')
    plt.plot(times, a_act[:,1], c='r')
    plt.plot(times, i_act[:,0], c='c', label=r'agama, interpolated')
    plt.plot(times, i_act[:,1], c='c')
    plt.text(0, c_act[0,0], '$J_r$', fontsize=16)
    plt.text(0, c_act[0,1], '$J_z$', fontsize=16)
    plt.xlabel(&quot;t&quot;)
    plt.ylabel(&quot;$J_r, J_z$&quot;)
    plt.legend(loc='center right', ncol=2, frameon=False)
    #plt.ylim(0.14,0.25)
    plt.xlim(0,50)
    plt.show()

compare([0.5, 0.82, 0.28, 0, 1.0, 0], 100., 1000)
</file>
    <file path="py/example_gizmo_snapshot.py">
#!/usr/bin/python
'''
This example illustrates the use of Agama to construct a smooth potential approximation
for a snapshot from the FIRE simulation (stored in the GIZMO format, similar to GADGET).
It relied on external python packages - gizmo_analysis and utilities (sic!), both hosted at
https://bitbucket.org/awetzel/

Author:  Robyn Sanderson, with contributions from Andrew Wetzel, Eugene Vasiliev
'''
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function


import agama
import numpy as np
import gizmo_analysis as ga
import utilities as ut
import sys

# base directory for all the simulations - change to the correct path, include trailing slash
# note that these files, of course, are not provided in the Agama distribution.
# the folder should contain a subfolder with the name of the simulation (e.g., 'm12i'),
# and in that subfolder there should be a file 'snapshot_times.txt', and yet another subfolder
# 'output', which contains files 'snapshot_***.*.hdf5'
sims_dir = '../../FIRE/'

# list of labels for symmetry spec
symmlabel={'a':'axi','s':'sph','t':'triax','n':'none'}

# define the physical units used in the code: the choice below corresponds to
# length scale = 1 kpc, velocity = 1 km/s, mass = 1 Msun
agama.setUnits(mass=1,length=1,velocity=1)

# tunable parameters for the potentials are:
# GridSizeR, rmin, rmax - specify the (logarithmic) grid in spherical radius
# (for Multipole) or cylindrical radius (for CylSpline); for the latter, there is a second grid in z,
# defined by GridSizeZ, zmin, zmax (by default the same as the radial grid).
# The minimum radius should be comparable to the smallest resolvable feature in the snapshot
# (e.g., the extent of the central cusp or core, or the disk scale height), but not smaller.
# The maximum radius defines the region where the potential and density approximated in full detail;
# note that for Multipole, the density is extrapolated as a power law outside this radius,
# and the potential takes into account the contribution of input particles at all radii,
# while for CylSpline the particles outside the grid are ignored, and the density is zero there.
# lmax - the order of multipole expansion;
# mmax - the order of azimuthal Fourier expansion for CylSpline (if it is axisymmetric, mmax is ignored)
# Note that the default parameters are quite sensible, but not necessarily optimal for your case.

def fitPotential(sim_name,
                 nsnap=600,
                 symmetry='a',
                 subsample_factor=1,
                 rmax_sel=600,
                 rmax_ctr=10,
                 rmax_exp=500,
                 save_coords=True):

        '''
        constructs a hybrid two-component basis expansion model of the potential for one Gizmo snapshot.
        dark matter and hot gas are represented by an expansion in spherical harmonics.
        remaining baryons (stars and cold gas) are represented by an azimuthal harmonic expansion in phi and a quintic spline in (R,z).
        (see Agama docs, sections 2.2.2 and 2.2.3 for more details).

        Arguments:
        sim_name [str]: name of simulation folder within main dir
        nsnap [int]: snapshot number
        symmetry [char]: 's' for spherical, 'a' for axisymmetric, 't' for triaxial, 'n' for none (see table 2 of Agama docs)
        subsample_factor [int]: factor by which to subsample (for speedup/testing)
        rmax_sel [float]: max radius in kpc to select particles for fitting the model
        rmax_ctr [float]: radius (kpc) defining the subset of stars which are used to define the reference frame (centering and rotation)
        rmax_exp [float]: max radial extent in kpc of the hybrid potential expansion (both components)
        save_coords [bool]: save center position, velocity, mean acceleration, and rotation matrix for principal-axis frame, to a file
        '''
        print('reading snapshot')

        #read in the snapshot
        part = ga.io.Read.read_snapshots(species=['gas', 'star', 'dark'],
                                         snapshot_values=nsnap,
                                         simulation_directory=sims_dir+sim_name,
                                         # snapshot_directory='output_accel',
                                         particle_subsample_factor=subsample_factor,
                                         assign_host_coordinates=True,
                                         assign_host_principal_axes=True)

        # start with default centering and rotation to define aperture

        dist=ut.particle.get_distances_wrt_center(part, species=['gas','star','dark'],
                rotation=part.host_rotation_tensors[0], total_distance = True)
        dist_vectors = ut.particle.get_distances_wrt_center(part, species=['gas','star','dark'],
                rotation=part.host_rotation_tensors[0])


        # compute new centering and rotation using a fixed aperture in stars

        sp = 'star'
        ctr_indices = np.where(dist[sp]&lt;rmax_ctr)[0]

        m = part[sp]['mass'][ctr_indices]
        pos = part[sp]['position'][ctr_indices]
        vel = part[sp]['velocity'][ctr_indices]
        new_ctr = np.multiply(m,pos.T).sum(axis=1)/np.sum(m)
        new_vctr = np.multiply(m,vel.T).sum(axis=1)/np.sum(m)
        new_rot = ut.particle.get_principal_axes(part,'star',part_indices=ctr_indices,
                                                 print_results=False)

        #optionally compute acceleration of center of mass frame if it was recorded 

        save_accel = ('acceleration' in part[sp].keys())
        if save_accel:
                print('saving acceleration of COM frame')
                accel = part[sp]['acceleration'][ctr_indices]
                new_actr = np.multiply(m,accel.T).sum(axis=1)/np.sum(m)

        # recompute distances in the new frame

        dist=ut.particle.get_distances_wrt_center(part,
                                                  species=['star','gas','dark'],
                                                  center_position=new_ctr,
                                                  rotation=new_rot['rotation.tensor'],
                                                  total_distance = True)
        dist_vectors = ut.particle.get_distances_wrt_center(part,
                                                            species=['star','gas','dark'],
                                                            center_position=new_ctr,
                                                            rotation=new_rot['rotation.tensor'])

        #pick out gas and stars within the region that we want to supply to the model

        m_gas_tot = part['gas']['mass'].sum()*subsample_factor

        pos_pa_gas = dist_vectors['gas'][dist['gas']&lt;rmax_sel]
        m_gas = part['gas']['mass'][dist['gas']&lt;rmax_sel]*subsample_factor
        print('{0:.3g} of {1:.3g} solar masses in gas selected'.format(m_gas.sum(),m_gas_tot))


        m_star_tot = part['star']['mass'].sum()*subsample_factor

        pos_pa_star = dist_vectors['star'][dist['star']&lt;rmax_sel]
        m_star = part['star']['mass'][dist['star']&lt;rmax_sel]*subsample_factor
        print('{0:.3g} of {1:.3g} solar masses in stars selected'.format(m_star.sum(),m_star_tot))

        #separate cold gas in disk (modeled with cylspline) from hot gas in halo (modeled with multipole)

        tsel = (np.log10(part['gas']['temperature'])&lt;4.5)
        rsel = (dist['gas']&lt;rmax_sel)

        pos_pa_gas_cold = dist_vectors['gas'][tsel&amp;rsel]
        m_gas_cold = part['gas']['mass'][tsel&amp;rsel]*subsample_factor
        print('{0:.3g} of {1:.3g} solar masses are cold gas to be modeled with cylspline'.format(m_gas_cold.sum(),m_gas.sum()))

        pos_pa_gas_hot = dist_vectors['gas'][(~tsel)&amp;rsel]
        m_gas_hot = part['gas']['mass'][(~tsel)&amp;rsel]*subsample_factor
        print('{0:.3g} of {1:.3g} solar masses are hot gas to be modeled with multipole'.format(m_gas_hot.sum(),m_gas.sum()))


        #combine components that will be fed to the cylspline part
        pos_pa_bar = np.vstack((pos_pa_star,pos_pa_gas_cold))
        m_bar = np.hstack((m_star,m_gas_cold))


        #pick out the dark matter
        m_dark_tot = part['dark']['mass'].sum()*subsample_factor

        rsel = dist['dark']&lt;rmax_sel
        pos_pa_dark=dist_vectors['dark'][rsel]
        m_dark = part['dark']['mass'][rsel]*subsample_factor
        print('{0:.3g} of {1:.3g} solar masses in dark matter selected'.format(m_dark.sum(),m_dark_tot))

        #stack with hot gas for multipole density
        pos_pa_dark = np.vstack((pos_pa_dark,pos_pa_gas_hot))
        m_dark = np.hstack((m_dark,m_gas_hot))

        if save_coords:
                #save the Hubble parameter to transform to comoving units
                hubble = part.info['hubble']
                scalefactor = part.info['scalefactor']

        del(part)

        #right now, configured to save to a new directory in the simulation directory.
        #Recommended, since it's generally useful to have around

        output_stem = sims_dir+sim_name+'/potential/{0:.0f}kpc/{1}_{2:d}'.format(rmax_ctr,sim_name,nsnap)
        try:    # create the directory if it didn't exist
                os.makedirs(os.path.dirname(output_stem))
        except OSError as e:
                if e.errno != errno.EEXIST:
                        raise

        if save_coords:
                cname = '{0}_coords.txt'.format(output_stem)
                print('Saving coordinate transformation to {0}'.format(cname))
                with open(cname,'w') as f:
                        f.write('# Hubble parameter and scale factor (to convert physical &lt;-&gt; comoving) \n')
                        f.write('{0:.18g} {1:.18g}\n'.format(hubble, scalefactor))
                        f.write('# center position (kpc comoving)\n')
                        np.savetxt(f,new_ctr)
                        f.write('# center velocity (km/s physical)\n')
                        np.savetxt(f,new_vctr)
                        if save_accel:
                                f.write('# center acceleration (km/s^2 physical)\n')
                                np.savetxt(f,new_actr)
                        f.write('# rotation to principal-axis frame\n')
                        np.savetxt(f,new_rot['rotation.tensor'])


        print('Computing multipole expansion coefficients for dark matter/hot gas component')

        p_dark=agama.Potential(type='multipole',
                               particles=(pos_pa_dark, m_dark),
                               lmax=4, symmetry=symmetry,
                               rmin=0.1, rmax=rmax_exp)


        p_dark.export('{0}.dark.{1}.coef_mul'.format(output_stem,symmlabel[symmetry]))
        print('Computing cylindrical spline coefficients for stellar/cold gas component')

        p_bar = agama.Potential(type='cylspline',
                                particles=(pos_pa_bar, m_bar),
                                mmax=4, symmetry=symmetry,
                                #gridsizer=40, gridsizez=40,
                                rmin=0.1, rmax=rmax_exp)

        p_bar.export('{0}.bar.{1}.coef_cylsp'.format(output_stem,symmlabel[symmetry]))
        print('done, enjoy your potentials!')


if __name__ == &quot;__main__&quot;:
        import os, errno
        import argparse

        parser = argparse.ArgumentParser(description=&quot;Constructs and saves a hybrid &quot;
                                         &quot;two-component basis expansion model of the potential for one Gizmo snapshot. &quot;
                                         &quot;The dark matter and hot gas are represented by an expansion in spherical harmonics. &quot;
                                         &quot;The cold gas and stars are represented by an azimuthal harmonic &quot;
                                         &quot;expansion in phi and a quintic spline in (R,z). See Agama docs, sections &quot;
                                         &quot;2.2.2 and 2.2.3 for more details.&quot;)

        parser.add_argument('--simname',help='name of simulation folder within main dir (required)', default=None)
        parser.add_argument('--nsnap', type=int, help='snapshot number', default=600)
        parser.add_argument('--symmetry', help=&quot;s' for spherical, 'a' for axisymmetric, 't' for triaxial, 'n' for none (see table 2 of Agama docs)&quot;, default='a')
        parser.add_argument('--subfactor', type=int, help='factor by which to subsample snapshot particles (for speedup/testing)', default=1)
        parser.add_argument('--rsel', type=float, help='max radius in kpc to select particles for the model (should be larger than rmaxc, rmaxm)', default=600)
        parser.add_argument('--rmaxc', type=float, help='max radius in kpc to select particles for centering the model', default=10)
        parser.add_argument('--rmaxe', type=float, help='max radial extent in kpc of the hybrid potential expansion', default=400)
        parser.add_argument('--savec', type=bool, help='save coordinate transformation to a file', default=True)


        args=parser.parse_args()

        #check that at least simname is specified
        if args.simname is None:
                print('Error: no simulation specified')
                parser.print_help()
                parser.exit()

        #check that symmetry is a valid letter
        if args.symmetry not in 'satn':
                print('Error: invalid symmetry specification')
                parser.print_help()
                parser.exit()

        #otherwise start the program
        fitPotential(args.simname,
                     nsnap=args.nsnap,
                     symmetry=args.symmetry,
                     subsample_factor=args.subfactor,
                     rmax_sel=args.rsel,
                     rmax_ctr=args.rmaxc,
                     rmax_exp=args.rmaxe,
                     save_coords=args.savec)
</file>
    <file path="py/example_lmc_mw_interaction.py">
#!/usr/bin/python
&quot;&quot;&quot;
Context: The Large Magellanic Cloud (LMC) is the most massive satellite of the Milky Way,
and it perturbs the motion of stars in the outer regions of the Galaxy due to two effects:
(1) stars that pass in its vicinity are deflected and form an overdensity behind the LMC
on its trajectory, which in turn is responsible for dynamical friction (local pertubations);
(2) the Milky Way itself is not fixed in space, but moves in response to the gravitational
pull of the LMC. Moreover, stars at large distances from the MW center experience different
amounts of perturbation from the LMC, and therefore are systematically shifted and
accelerated w.r.t. the Galactic center (global perturbations).

This script illustrates both effects in a simplified setup, where the relative motion
of the Milky Way and the LMC is approximated as if both galaxies had rigid (moving but
non-deforming) potentials, and then the orbits of test particles in the Milky Way halo
are computed in the resulting time-dependent potential of the MW-LMC system.
&quot;&quot;&quot;
import sys, agama, numpy, scipy.integrate, scipy.ndimage, scipy.special, matplotlib, matplotlib.pyplot as plt

agama.setUnits(length=1, velocity=1, mass=1)  # work in units of 1 kpc, 1 km/s, 1 Msun)

Trewind = -4.0  # initial time [Gyr] - the LMC orbit is computed back to that time
Tcurr   =  0.0  # current time
# heliocentric ICRS celestial coordinates and velocity of the LMC
# (PM from Luri+ 2021, distance from Pietrzynski+ 2019, center and velocity from van der Marel+ 2002)
ra, dec, dist, pmra, pmdec, vlos = 81.28, -69.78, 49.6, 1.858, 0.385, 262.2
# transform to Galactocentric cartesian position/velocity, using built-in routines from Agama
# (hence the manual conversion factors from degrees to radians and from mas/yr to km/s/kpc)
l, b, pml, pmb = agama.transformCelestialCoords(agama.fromICRStoGalactic,
    ra * numpy.pi/180, dec * numpy.pi/180, pmra, pmdec)
posvelLMC = agama.getGalactocentricFromGalactic(l, b, dist, pml*4.74, pmb*4.74, vlos)

# Create a simple but realistic model of the Milky Way with a bulge, a single disk,
# and a spherical dark halo
paramBulge = dict(
    type              = 'Spheroid',
    mass              = 1.2e10,
    scaleRadius       = 0.2,
    outerCutoffRadius = 1.8,
    gamma             = 0.0,
    beta              = 1.8)
paramDisk  = dict(
    type='Disk',
    mass              = 5.0e10,
    scaleRadius       = 3.0,
    scaleHeight       = -0.4)
paramHalo  = dict(
    type              = 'Spheroid',
    densityNorm       = 1.35e7,
    scaleRadius       = 14,
    outerCutoffRadius = 300,
    cutoffStrength    = 4,
    gamma             = 1,
    beta              = 3)
densMWhalo = agama.Density(paramHalo)
potMW      = agama.Potential(paramBulge, paramDisk, paramHalo)

# create a sphericalized MW potential and a corresponding isotropic halo distribution function
potMWsph   = agama.Potential(type='Multipole', potential=potMW, lmax=0, rmin=0.01, rmax=1000)
gmHalo     = agama.GalaxyModel(potMWsph,
    agama.DistributionFunction(type='quasispherical', density=densMWhalo, potential=potMWsph))

# compute the velocity dispersion in the MW halo needed for the dynamical friction
rgrid      = numpy.logspace(1, 3, 16)
xyzgrid    = numpy.column_stack([rgrid, rgrid*0, rgrid*0])
sigmafnc   = agama.Spline(rgrid, gmHalo.moments(xyzgrid, dens=False, vel=False, vel2=True)[:,0]**0.5)

# Create the LMC potential - a spherical truncated NFW profile with mass and radius
# related by the equation below, which produces approximately the same enclosed mass
# profile in the inner region, satisfying the observational constraints, as shown
# in Fig.3 of Vasiliev,Belokurov&amp;Erkal 2021.
massLMC    = 1.5e11
radiusLMC  = (massLMC/1e11)**0.6 * 8.5
bminCouLog = radiusLMC * 2.0   # minimum impact parameter in the Coulomb logarithm
potLMC     = agama.Potential(
    type              = 'spheroid',
    mass              = massLMC,
    scaleradius       = radiusLMC,
    outercutoffradius = radiusLMC*10,
    gamma             = 1,
    beta              = 3)

######## PART ONE ########
# Simulate (approximately!) the past trajectory of the MW+LMC system under mutual gravity.
# Here, we integrate in time a 12-dimensional ODE system for positions &amp; velocities of
# both galaxies in the external inertial reference frame. The acceleration of each galaxy
# is computed by taking the gradient of the rigid (non-deforming) potential of the other
# galaxy at the location of the first galaxy's center, and then assuming that the entire
# first galaxy experiences the same acceleration and continues to move as a rigid body.
# The same procedure then is applied in reverse. Moreover, we add a dynamical friction
# acceleration to the LMC, but not to the Milky Way; it is computed using the standard
# Chandrasekhar's formula, but with a spatially-varying value of Coulomb logarithm,
# which has been calibrated against full N-body simulations.
# This simplified model is certainly not physically correct, e.g. manifestly violates
# Newton's third law, but still captures the main features of the actual interaction.
print(&quot;Computing the past orbits of the Milky Way and the LMC&quot;)
def difeq(vars, t):
    x0    = vars[0:3]          # MW position
    v0    = vars[3:6]          # MW velocity
    x1    = vars[6:9]          # LMC position
    v1    = vars[9:12]         # LMC velocity
    dx    = x1-x0              # relative offset
    dv    = v1-v0              # relative velocity
    dist  = sum(dx**2)**0.5    # distance between the galaxies
    vmag  = sum(dv**2)**0.5    # magnitude of relative velocity
    f0    = potLMC.force(-dx)  # force from LMC acting on the MW center
    f1    = potMW .force( dx)  # force from MW acting on the LMC
    rho   = potMW.density(dx)  # actual MW density at this point
    sigma = sigmafnc(dist)     # approximate MW velocity dispersion at this point
    # distance-dependent Coulomb logarithm
    # (an approximation that best matches the results of N-body simulations)
    couLog= max(0, numpy.log(dist / bminCouLog)**0.5)
    X     = vmag / (sigma * 2**.5)
    drag  = -(4*numpy.pi * rho * dv / vmag *
        (scipy.special.erf(X) - 2/numpy.pi**.5 * X * numpy.exp(-X*X)) *
        massLMC * agama.G**2 / vmag**2 * couLog)   # dynamical friction force
    return numpy.hstack((v0, f0, v1, f1 + drag))

Tstep   = 1./64
tgrid   = numpy.linspace(Trewind, Tcurr, round((Tcurr-Trewind)/Tstep)+1)
ic      = numpy.hstack((numpy.zeros(6), posvelLMC))
sol     = scipy.integrate.odeint(difeq, ic, tgrid[::-1])[::-1]

# After obtaining the solution for trajectories of both galaxies,
# we transform it into a more convenient form, namely, into the non-inertial
# reference frame centered at the Milky Way center at all times.
# In this frame, the total time-dependent gravitational potential consists of
# three terms. First is the rigid potential of the Milky Way itself.
# Because the latter moves on a curvilinear trajectory, we need to add
# a corresponding spatially uniform acceleration field. Finally, the potential
# of the LMC is also rigid but moves in space.

# LMC trajectory in the MW-centric (non-inertial) reference frame
# (7 columns: time, 3 position and 3 velocity components)
trajLMC = numpy.column_stack([tgrid, sol[:,6:12] - sol[:,0:6]])
# MW trajectory in the inertial frame
trajMWx = agama.Spline(tgrid, sol[:,0], der=sol[:,3])
trajMWy = agama.Spline(tgrid, sol[:,1], der=sol[:,4])
trajMWz = agama.Spline(tgrid, sol[:,2], der=sol[:,5])
# MW centre acceleration is minus the second derivative of its trajectory in the inertial frame
accMW   = numpy.column_stack([tgrid, -trajMWx(tgrid, 2), -trajMWy(tgrid, 2), -trajMWz(tgrid, 2)])
potacc  = agama.Potential(type='UniformAcceleration', file=accMW)
potLMCm = agama.Potential(potential=potLMC, center=trajLMC)  # potential of the moving LMC

# finally, the total time-dependent potential in the non-inertial MW-centric reference frame
potTotal= agama.Potential(potMW, potLMCm, potacc)

######## PART TWO ########
# Compute the perturbations caused by the moving LMC and the accelerating
# Milky Way on the orbits of test particles in the Milky Way halo.
# We create a large sample of stars initially in equilibrium with
# the isolated Milky Way potential, then integrate their orbits
# in the time-dependent potential of two interacting galaxies,
# and plot the changes in density and mean velocity in several radial bins.

if len(sys.argv)&gt;1:
    Nstars = int(float(sys.argv[1]))
else:
    Nstars = 100000

# create the initial conditions for the halo objects (for simplicity,
# using the density profile of the DM halo rather than a separate stellar halo)
ic = gmHalo.sample(Nstars)[0]

# integrate the orbits of these objects in the time-dependent total potential
# and record the &quot;final conditions&quot; (present-day position&amp;velocity)
print(&quot;Integrating the trajectories of %i stars in the Milky Way halo &quot;
    &quot;in the time-dependent potential of the LMC + MW&quot; % len(ic))
if Nstars &lt; 1e6:
    print(&quot;To increase the resolution and reduce the Poisson noise in maps, run the script &quot;
        &quot;with a larger number of orbits, e.g. 1e6 (provide the number in the command line)&quot;)

fc = numpy.vstack(agama.orbit(potential=potTotal, ic=ic, time=Tcurr-Trewind,
    timestart=Trewind, trajsize=1)[:,1])

# present-day positions and Solar reflex-corrected velocities of these stars
# in the heliocentric system (for an observer at rest w.r.t. the Galactic center)
l,b,d,ml,mb,vl = agama.getGalacticFromGalactocentric(*fc.T, galcen_v_sun=[0,0,0])
ml *= d; mb *= d

# the background density of stars in the unperturbed halo could be taken from &quot;ic&quot;,
# but to reduce the Poisson noise, we create a higher-resolution sample of stars
oversampling_factor = 10
ic_hr = densMWhalo.sample(Nstars * oversampling_factor)[0]
# convert the positions to the heliocentric system
l0,b0,d0 = agama.getGalacticFromGalactocentric(*ic_hr.T)

# LMC trajectory in the heliocentric system
lLMC, bLMC, dLMC = agama.getGalacticFromGalactocentric(*trajLMC[:,1:4].T)

def projectMollweide(lon, lat):
    &quot;&quot;&quot;
    Convert the longitude/latitude expressed in radians into coordinates in the ellipse
    with semimajor axes 2x1, typical for showing all-sky maps of some quantity
    &quot;&quot;&quot;
    ang = numpy.array(lat)
    bla = numpy.pi/2 * numpy.sin(lat)
    # solve a nonlinear equation for ang by Newton's method, carefully designing the first approximation
    w = (1 - abs(ang) * 2/numpy.pi)**(2./3)
    ang = (1 - w * (1 + (1-w) * (-0.09 - 0.086*w) )) * numpy.sign(ang) * numpy.pi/2
    for it in range(3):
        ang -= 0.5 * (ang + 0.5*numpy.sin(2*ang) - bla) / numpy.cos(ang)**2
    X = lon * 2/numpy.pi * numpy.cos(ang)
    Y = numpy.sin(ang)
    return X, Y

X,Y   = projectMollweide(l, b)
X0,Y0 = projectMollweide(l0,b0)
Xl,Yl = projectMollweide(lLMC,bLMC)
# show perturbation maps as 2d histograms in X,Y
gridX, gridY = numpy.linspace(-2,2,81), numpy.linspace(-1,1,41)
centX, centY = (gridX[1:]+gridX[:-1])/2, (gridY[1:]+gridY[:-1])/2
cntrX = numpy.repeat(centX, len(centY)).reshape(len(centX), len(centY))
cntrY = numpy.tile  (centY, len(centX)).reshape(len(centX), len(centY))
def smooth(hist):
    # Gaussian smoothing of a region inside the ellipse
    smoothing = (Nstars/1e7)**-0.25
    hist[hist==0] = numpy.mean(hist)  # fill the outside region with the mean value
    hist = scipy.ndimage.gaussian_filter(hist, smoothing)
    hist[ (cntrX/2.0)**2 + cntrY**2 &gt; 1.0 ] = numpy.nan
    return hist

def showmap(ax, qty):
    ax.set_axis_off()
    ax.imshow(qty.T, extent=[-2,2,-1.01,0.99], aspect='auto', interpolation='nearest', origin='lower',
        cmap='bluered', vmin=-1, vmax=1)
    ax.add_artist(matplotlib.patches.Ellipse((0,0), 4, 2, fill=False, color='k', lw=0.5, clip_on=False))
    ax.set_xlim(2, -2)
    ax.set_ylim(-1, 1)
    ax.plot(Xl, Yl, color='g', dashes=[2,1.5], lw=0.25)
    ax.plot(Xl[dlf], Yl[dlf], color='g', lw=0.75)
    ax.plot(Xl[-1 ], Yl[-1 ], 'o', mew=0, ms=1.5, color='g')

plt.rc('axes', linewidth=0.5)
plt.rc('font', size=6)
plt.rc('ytick.major', size=1)
plt.figure(figsize=(6.4,3.2), dpi=200)
distbins = [0, 30, 60, 100, 150]
for i in range(4):
    dmin = distbins[i]
    dmax = distbins[i+1]
    filt0= (d0  &gt;=dmin) * (d0  &lt;=dmax)
    filt = (d   &gt;=dmin) * (d   &lt;=dmax)
    dlf  = (dLMC&gt;=dmin) * (dLMC&lt;=dmax)
    print('%g &lt; D [kpc] &lt; %g: %i stars' % (dmin, dmax, numpy.sum(filt)))
    his0 = smooth(numpy.histogram2d(X0[filt0], Y0[filt0], bins=(gridX,gridY))[0]) / oversampling_factor
    his  = smooth(numpy.histogram2d(X[filt], Y[filt], bins=(gridX,gridY))[0])
    hml  = smooth(numpy.histogram2d(X[filt], Y[filt], bins=(gridX,gridY), weights=ml[filt])[0]) / his
    hmb  = smooth(numpy.histogram2d(X[filt], Y[filt], bins=(gridX,gridY), weights=mb[filt])[0]) / his
    hvl  = smooth(numpy.histogram2d(X[filt], Y[filt], bins=(gridX,gridY), weights=vl[filt])[0]) / his
    showmap(plt.axes([0.005 + i*0.22, 0.73, 0.20, 0.20]), his/his0-1)  # over/underdensity map
    showmap(plt.axes([0.005 + i*0.22, 0.49, 0.20, 0.20]), hml/80.0)    # mean velocity in the &quot;l&quot; direction
    showmap(plt.axes([0.005 + i*0.22, 0.25, 0.20, 0.20]), hmb/80.0)    # mean velocity in the &quot;b&quot; direction
    showmap(plt.axes([0.005 + i*0.22, 0.01, 0.20, 0.20]), hvl/80.0)    # mean line-of-sight velocity
    plt.text(0.115 + i*0.22, 0.99, '%g &lt; D [kpc] &lt; %g' % (dmin, dmax), ha='center', va='top',
        transform=plt.gcf().transFigure, fontsize=7)

def showcolorbar(ax, label, vmin, vmax):
    ax.imshow(numpy.linspace(0,1,256).reshape(-1,1), extent=[0,1,vmin,vmax], aspect='auto', interpolation='nearest',
        origin='lower', cmap='bluered', vmin=0, vmax=1)
    ax.set_xticks([])
    ax.yaxis.tick_right()
    ax.set_ylabel(label, labelpad=-40, fontsize=8)

showcolorbar(plt.axes([0.89, 0.73, 0.02, 0.20]), r'$\rho / \rho_0 - 1$', -1, 1)
showcolorbar(plt.axes([0.89, 0.49, 0.02, 0.20]), r'$D\times \mu_l \;\sf[km/s]$', -80, 80)
showcolorbar(plt.axes([0.89, 0.25, 0.02, 0.20]), r'$D\times \mu_b \;\sf[km/s]$', -80, 80)
showcolorbar(plt.axes([0.89, 0.01, 0.02, 0.20]), r'$v_\mathsf{los} \;\sf[km/s]$', -80, 80)
#plt.savefig('example_lmc_mw_interaction.pdf')
plt.show()
</file>
    <file path="py/example_mw_bar_potential.py">
#!/usr/bin/python
'''
This script defines an analytic approximation for the barred Milky Way model from Portail et al.(2017)
and constructs a corresponding CylSpline potential, which can be used to integrate orbits, etc.
The density is represented by four components: an X-shaped inner bar, two instances of long bars,
and an axisymmetric disk. In addition, there is a 'central mass concentration' (a triaxial disk)
and a flattened axisymmetric dark halo, which is represented by a separate Multipole potential.
This potential model is a good fit for the central region of the Galaxy (within ~5kpc),
but is not very realistic further out.
A better variant of the entire Milky Way potential is provided by example_mw_potential_hunter24.py
The left panel shows the circular-velocity curve (in the axisymmetrized potential),
and the right panel shows examples of a few orbits in this potential.

Reference: Sormani et al. 2022 (MNRAS Letters/514/L5).

Authors: Mattia Sormani, Eugene Vasiliev
'''
import agama, numpy, matplotlib.pyplot as plt

# Nearly identical to the built-in Disk density profile, but with a slightly different
# vertical profile containing an additional parameter 'verticalSersicIndex'
def makeDisk(**params):
    surfaceDensity      = params['surfaceDensity']
    scaleRadius         = params['scaleRadius']
    scaleHeight         = params['scaleHeight']
    innerCutoffRadius   = params['innerCutoffRadius']
    sersicIndex         = params['sersicIndex']
    verticalSersicIndex = params['verticalSersicIndex']
    def density(xyz):
        R = (xyz[:,0]**2 + xyz[:,1]**2)**0.5
        return (surfaceDensity / (4*scaleHeight) *
            numpy.exp( - (R/scaleRadius)**sersicIndex - innerCutoffRadius/(R+1e-100)) /
            numpy.cosh( (abs(xyz[:,2]) / scaleHeight)**verticalSersicIndex ) )
    return agama.Density(density, symmetry='a')

# Modification of equation 9 of Coleman et al. 2020 (https://arxiv.org/abs/1911.04714)
def makeXBar(**params):
    densityNorm = params['densityNorm']
    x0   = params['x0']
    y0   = params['y0']
    z0   = params['z0']
    xc   = params['xc']
    yc   = params['yc']
    c    = params['c']
    alpha= params['alpha']
    cpar = params['cpar']
    cperp= params['cperp']
    m    = params['m']
    n    = params['n']
    outerCutoffRadius = params['outerCutoffRadius']
    def density(xyz):
        r  = numpy.sum(xyz**2, axis=1)**0.5
        a  = ( ( (abs(xyz[:,0]) / x0)**cperp + (abs(xyz[:,1]) / y0)**cperp )**(cpar/cperp) +
            (abs(xyz[:,2]) / z0)**cpar )**(1/cpar)
        ap = ( ((xyz[:,0] + c * xyz[:,2]) / xc)**2 + (xyz[:,1] / yc)**2 )**(0.5)
        am = ( ((xyz[:,0] - c * xyz[:,2]) / xc)**2 + (xyz[:,1] / yc)**2 )**(0.5)
        return (densityNorm / numpy.cosh(a**m) * numpy.exp( -(r/outerCutoffRadius)**2) *
            (1 + alpha * (numpy.exp(-ap**n) + numpy.exp(-am**n) ) ) )
    return density

# Modification of equation 9 of Wegg et al. 2015 (https://arxiv.org/pdf/1504.01401.pdf)
def makeLongBar(**params):
    densityNorm = params['densityNorm']
    x0   = params['x0']
    y0   = params['y0']
    cpar = params['cpar']
    cperp= params['cperp']
    scaleHeight = params['scaleHeight']
    innerCutoffRadius   = params['innerCutoffRadius']
    outerCutoffRadius   = params['outerCutoffRadius']
    innerCutoffStrength = params['innerCutoffStrength']
    outerCutoffStrength = params['outerCutoffStrength']
    def density(xyz):
        R = (xyz[:,0]**2 + xyz[:,1]**2)**0.5
        a = ( (abs(xyz[:,0]) / x0)**cperp + (abs(xyz[:,1]) / y0)**cperp )**(1/cperp)
        return densityNorm / numpy.cosh(xyz[:,2] / scaleHeight)**2 * numpy.exp(-a**cpar
            -(R/outerCutoffRadius)**outerCutoffStrength - (innerCutoffRadius/R)**innerCutoffStrength)
    return density

# additional central mass concentration as described in sec.7.3 of Portail et al.(2017)
def makeCMC(mass, scaleRadius, scaleHeight, axisRatioY):
    norm = mass / (4 * numpy.pi * scaleRadius**2 * scaleHeight * axisRatioY)
    def density(xyz):
        return norm * numpy.exp(-(xyz[:,0]**2 + (xyz[:,1]/axisRatioY)**2)**0.5 / scaleRadius
            - abs(xyz[:,2]) / scaleHeight)
    return agama.Density(density, symmetry='a')

# create the bar density profile with 3 component
def makeBarDensity():
    params = numpy.array(
      # short/thick bar
      [ 3.16273226e+09, 4.90209137e-01, 3.92017253e-01, 2.29482096e-01,
        1.99110223e+00, 2.23179266e+00, 8.73227940e-01, 4.36983774e+00,
        6.25670015e-01, 1.34152138e+00, 1.94025114e+00, 7.50504078e-01,
        4.68875471e-01] +
      # long bar 1
      [ 4.95381575e+08, 5.36363324e+00, 9.58522229e-01, 6.10542494e-01,
        9.69645220e-01, 3.05125124e+00, 3.19043585e+00, 5.58255674e-01,
        1.67310332e+01, 3.19575493e+00] +
      # long bar 2
      [ 1.74304936e+13, 4.77961423e-01, 2.66853061e-01, 2.51516920e-01,
        1.87882599e+00, 9.80136710e-01, 2.20415408e+00, 7.60708626e+00,
       -2.72907665e+01, 1.62966434e+00]
    )
    ind=0
    densityXBar = makeXBar(
         densityNorm=params[ind+0],
         x0=params[ind+1],
         y0=params[ind+2],
         z0=params[ind+3],
         cpar=params[ind+4],
         cperp=params[ind+5],
         m=params[ind+6],
         outerCutoffRadius=params[ind+7],
         alpha=params[ind+8],
         c=params[ind+9],
         n=params[ind+10],
         xc=params[ind+11],
         yc=params[ind+12])
    ind+=13
    densityLongBar1 = makeLongBar(
        densityNorm=params[ind+0],
        x0=params[ind+1],
        y0=params[ind+2],
        scaleHeight=params[ind+3],
        cperp=params[ind+4],
        cpar=params[ind+5],
        outerCutoffRadius=params[ind+6],
        innerCutoffRadius=params[ind+7],
        outerCutoffStrength=params[ind+8],
        innerCutoffStrength=params[ind+9] )
    ind+=10
    densityLongBar2 = makeLongBar(
        densityNorm=params[ind+0],
        x0=params[ind+1],
        y0=params[ind+2],
        scaleHeight=params[ind+3],
        cperp=params[ind+4],
        cpar=params[ind+5],
        outerCutoffRadius=params[ind+6],
        innerCutoffRadius=params[ind+7],
        outerCutoffStrength=params[ind+8],
        innerCutoffStrength=params[ind+9] )
    ind+=10
    assert len(params)==ind, 'invalid number of parameters'
    return agama.Density(lambda x: densityXBar(x) + densityLongBar1(x) + densityLongBar2(x), symmetry='t')


# create the potential of the entire model:
# 3-component bar density as defined above, plus disk, central mass concentration, and dark halo
def makePotentialModel():
    # combined 4 components and the CMC represented by a single triaxial CylSpline potential
    mmax = 12  # order of azimuthal Fourier expansion (higher order means better accuracy,
    # but values greater than 12 *significantly* slow down the computation!)
    params_disk = [ 1.03063359e+09, 4.75409497e+00, 4.68804907e+00, 1.51100601e-01,
        1.53608780e+00, 7.15915848e-01 ]
    densityDisk = makeDisk(
        surfaceDensity=params_disk[0],
        scaleRadius=params_disk[1],
        innerCutoffRadius=params_disk[2],
        scaleHeight=params_disk[3],
        sersicIndex=params_disk[4],
        verticalSersicIndex=params_disk[5])

    pot_bary = agama.Potential(type='CylSpline',
        density=agama.Density(makeBarDensity(), densityDisk, makeCMC(0.2e10, 0.25, 0.05, 0.5)),
        mmax=mmax, gridsizeR=25, gridsizez=25, Rmin=0.1, Rmax=40, zmin=0.05, zmax=20)
    # flattened axisymmetric dark halo with the Einasto profile
    pot_dark = agama.Potential(type='Multipole',
        density='Spheroid', axisratioz=0.8, gamma=0, beta=0,
        outerCutoffRadius=1.84, cutoffStrength=0.74, densityNorm=0.0263e10,
        gridsizer=26, rmin=0.01, rmax=1000, lmax=8)
    return agama.Potential(pot_bary, pot_dark)


if __name__ == '__main__':
    agama.setUnits(length=1, mass=1, velocity=1)  # 1 kpc, 1 Msun, 1 km/s
    pot = makePotentialModel()
    pot.export('Portail17.ini')
    print('Created MW potential: total mass in stars=%.3g Msun, halo=%.3g Msun' %
        (pot[0].totalMass(), pot[1].totalMass()))
    # create an axisymmetrized version of the potential for plotting the true circular-velocity curve
    pot_axi = agama.Potential(
        agama.Potential(type='CylSpline', potential=pot[0],
            mmax=0, gridsizeR=25, gridsizez=25, Rmin=0.1, Rmax=40, zmin=0.05, zmax=20),
        pot[1])

    r=numpy.linspace(0,10,101)
    xyz=numpy.column_stack((r,r*0,r*0))
    ax=plt.subplots(1, 2, figsize=(12,6), dpi=100)[1]
    ax[0].plot(r, (-r*pot_axi[0].force(xyz)[:,0])**0.5, 'c', label='stars')
    ax[0].plot(r, (-r*pot_axi[1].force(xyz)[:,0])**0.5, 'y', label='halo')
    ax[0].plot(r, (-r*pot_axi   .force(xyz)[:,0])**0.5, 'r', label='total')
    ax[0].legend(loc='lower right', frameon=False)
    ax[0].set_xlabel('radius [kpc]')
    ax[0].set_ylabel('circular velocity [km/s]')

    # integrate and show a few orbits
    numorbits=10
    numpy.random.seed(42)
    ic=numpy.random.normal(size=(numorbits,6)) * numpy.array([2.0, 0.0, 0.4, 50., 40., 30.])
    ic[:,0] += -6.
    ic[:,4] += 220
    bar_angle = -25.0 * numpy.pi/180  # orientation of the bar w.r.t. the Sun
    Omega = -39.0  # km/s/kpc - the value is negative since the potential rotates clockwise
    orbits = agama.orbit(potential=pot, ic=ic, time=10., trajsize=1000, Omega=Omega)[:,1]
    sina, cosa = numpy.sin(bar_angle), numpy.cos(bar_angle)
    rmax = 10.0   # plotting range
    cmap = plt.get_cmap('mist')
    for i,o in enumerate(orbits):
        ax[1].plot(o[:,0]*cosa-o[:,1]*sina, o[:,0]*sina+o[:,1]*cosa, color=cmap(i*1.0/numorbits), lw=0.5)
    ax[1].plot(-8.2,0.0, 'ko', ms=5)  # Solar position
    ax[1].text(-8.0,0.0, 'Sun')
    ax[1].set_xlabel('x [kpc]')
    ax[1].set_ylabel('y [kpc]')
    ax[1].set_xlim(-rmax, rmax)
    ax[1].set_ylim(-rmax, rmax)

    # overplot the surface density contours
    print('Computing surface density')
    gridr  = numpy.linspace(-rmax, rmax, 101)  # 1d grid
    gridxy = numpy.column_stack((numpy.repeat(gridr, len(gridr)), numpy.tile(gridr, len(gridr))))  # 2d grid
    Sigma  = pot[0].projectedDensity(gridxy, gamma=-bar_angle)  # surface density for a stellar component rotated by bar_angle
    logSigma = 2.5 * numpy.log10(Sigma / numpy.max(Sigma))      # log-scaled to magnitudes per unit square
    # thick lines spaced by one magnitude, thin lines lie halfway between thick ones
    ax[1].contour(gridr, gridr, logSigma.reshape(len(gridr), len(gridr)).T,
        levels=numpy.linspace(-8,0,17), colors='k', zorder=5, linewidths=[2,1], linestyles='solid')

    plt.tight_layout()
    plt.show()
</file>
    <file path="py/example_mw_nsd.py">
#!/usr/bin/python
'''
Construct a self-consistent DF-based model of the Milky Way nuclear stellar disk (NSD)
with an additional non-self-consistent component representing the nuclear star cluster (NSC).
This model is fitted to the current observational constraints, as detailed in
Sormani et al. 2022 (MNRAS/512/1857).
Authors: Mattia Sormani, Jason Sanders, Eugene Vasiliev
Date: Feb 2022
'''

import numpy, agama, matplotlib.pyplot as plt

def plotVcirc(model, iteration):
    rhos   = (model.components[0].density, model.components[1].density)
    pots   = (  # recompute potentials of both components separately, using a multipole Poisson solver
        agama.Potential(type='Multipole', lmax=6,  density=rhos[0], rmin=1e-4, rmax=0.1),
        agama.Potential(type='Multipole', lmax=12, density=rhos[1], rmin=1e-3, rmax=1.0))
    r      = numpy.linspace(0.0, 1.0, 1001)
    xyz    = numpy.column_stack((r, r*0, r*0))
    vcomp2 = numpy.column_stack([-pot.force(xyz)[:,0]*r for pot in pots])
    vtot2  = numpy.sum(vcomp2, axis=1)
    #print('NSC total mass=%g'%rhos[0].totalMass())
    print('NSD total mass=%g'%rhos[1].totalMass())
    # plot the circular-velocity curves for both NSC and NSD separately, and their sum
    plt.figure(figsize=(6,4))
    ax = plt.axes([0.15, 0.15, 0.8, 0.8])
    ax.plot(r, vtot2**0.5, color='k', label='total')
    ax.plot(r, vcomp2[:,0]**0.5, '--', color='k', label='NSC')
    ax.plot(r, vcomp2[:,1]**0.5, ':',  color='k', label='NSD')
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 140)
    ax.set_xlabel(r'$R\, {\rm [kpc]}$', fontsize=16)
    ax.set_ylabel(r'$v_{\rm circ}\, {\rm [km/s]}$', fontsize=16)
    ax.grid()
    ax.legend()
    plt.savefig('nsd_vcirc_iter%i.pdf' % iteration)
    plt.close()

def plotModel(model, df):
    print('Creating density and kinematic plots...')
    gridx  = numpy.linspace(0, 0.70, 141)
    gridz  = numpy.linspace(0, 0.25, 51)
    gridxz = numpy.column_stack((numpy.tile(gridx, len(gridz)), numpy.repeat(gridz, len(gridx))))
    gridxyz= numpy.column_stack((numpy.tile(gridx, len(gridz)), numpy.zeros(len(gridx)*len(gridz)), numpy.repeat(gridz, len(gridx))))
    nsc = model.components[0].density
    nsd = model.components[1].density
    rho_nsd = nsd.density(gridxyz).reshape(len(gridz), len(gridx))
    Sig_nsd = nsd.projectedDensity(gridxz, beta=numpy.pi/2).reshape(len(gridz), len(gridx))
    plt.figure(figsize=(15,10), dpi=75)
    ax = numpy.array(
        [plt.axes([0.035, 0.81-0.195*i, 0.38, 0.18]) for i in range(5)] +
        [plt.axes([0.425, 0.81-0.195*i, 0.38, 0.18]) for i in range(5)]).reshape(2,5).T
    ax[0,0].contour(gridx, gridz, numpy.log10(rho_nsd), levels=numpy.log10(numpy.max(rho_nsd))+numpy.linspace(-6,-0,16), cmap='Blues')
    ax[0,1].contour(gridx, gridz, numpy.log10(Sig_nsd), levels=numpy.log10(numpy.max(Sig_nsd))+numpy.linspace(-6,-0,16), cmap='Blues')
    # compute moments on a coarser grid
    gridx = agama.nonuniformGrid(20, 0.02, 0.70)
    gridz = agama.nonuniformGrid(10, 0.02, 0.25)
    gridxz = numpy.column_stack((numpy.tile(gridx, len(gridz)), numpy.repeat(gridz, len(gridx))))
    gridxyz= numpy.column_stack((numpy.tile(gridx, len(gridz)), numpy.zeros(len(gridx)*len(gridz)), numpy.repeat(gridz, len(gridx))))
    gm = agama.GalaxyModel(model.potential, df)
    gridv = numpy.linspace(0, 100, 11)
    # intrinsic moments
    vel, vel2 = gm.moments(gridxyz, dens=False, vel=True, vel2=True, beta=numpy.pi/2)
    plt.clabel(ax[1,0].contour(gridx, gridz, -vel[:,2].reshape(len(gridz), len(gridx)), levels=gridv, cmap='Blues'), fmt='%.0f')
    plt.clabel(ax[2,0].contour(gridx, gridz, numpy.sqrt(vel2[:,2]-vel[:,2]**2).reshape(len(gridz), len(gridx)), levels=gridv, cmap='Blues'), fmt='%.0f')
    plt.clabel(ax[3,0].contour(gridx, gridz, numpy.sqrt(vel2[:,0]-vel[:,0]**2).reshape(len(gridz), len(gridx)), levels=gridv, cmap='Blues'), fmt='%.0f')
    plt.clabel(ax[4,0].contour(gridx, gridz, numpy.sqrt(vel2[:,1]-vel[:,1]**2).reshape(len(gridz), len(gridx)), levels=gridv, cmap='Blues'), fmt='%.0f')
    # projected moments
    vel, vel2 = gm.moments(gridxz, dens=False, vel=True, vel2=True, beta=numpy.pi/2)
    plt.clabel(ax[1,1].contour(gridx, gridz, -vel[:,2].reshape(len(gridz), len(gridx)), levels=gridv, cmap='Blues'), fmt='%.0f')
    plt.clabel(ax[2,1].contour(gridx, gridz, numpy.sqrt(vel2[:,2]-vel[:,2]**2).reshape(len(gridz), len(gridx)), levels=gridv, cmap='Blues'), fmt='%.0f')
    plt.clabel(ax[3,1].contour(gridx, gridz, numpy.sqrt(vel2[:,0]-vel[:,0]**2).reshape(len(gridz), len(gridx)), levels=gridv, cmap='Blues'), fmt='%.0f')
    plt.clabel(ax[4,1].contour(gridx, gridz, numpy.sqrt(vel2[:,1]-vel[:,1]**2).reshape(len(gridz), len(gridx)), levels=gridv, cmap='Blues'), fmt='%.0f')
    labels = ['density', 'v_los', 'sigma_los', 'sigma_R', 'sigma_z']
    colors = ['c', 'm', 'b', 'r', 'g']
    # fiducial fields for computing projected velocity distributions
    points = [ [0.05, 0.01], [0.15, 0.01], [0.15, 0.10], [0.30, 0.01] ]
    for i in range(5):
        ax[i,0].set_ylabel('z [kpc]', labelpad=4)
        ax[i,1].set_yticklabels([])
        ax[i,0].text(0.5, 0.98, 'intrinsic '+labels[i], ha='center', va='top', transform=ax[i,0].transAxes, color=colors[i])
        ax[i,1].text(0.5, 0.98, 'projected '+labels[i], ha='center', va='top', transform=ax[i,1].transAxes, color=colors[i])
        if i&lt;4:
            ax[i,0].set_xticklabels([])
            ax[i,1].set_xticklabels([])
        else:
            ax[i,0].set_xlabel('R [kpc]', labelpad=2)
            ax[i,1].set_xlabel('R [kpc]', labelpad=2)
        ax[i,0].set_xlim(min(gridx), max(gridx))
        ax[i,1].set_xlim(min(gridx), max(gridx))
        ax[i,0].set_ylim(min(gridz), max(gridz))
        ax[i,1].set_ylim(min(gridz), max(gridz))
        for k,point in enumerate(points):
            ax[i,1].text(point[0], point[1], chr(k+65), ha='center', va='center', color='olive')
    gridv = numpy.linspace(-250, 250, 26)   # coarse grid for computing the velocity distribution
    gridV = numpy.linspace(-250, 250, 101)  # fine grid for plotting a smoother spline-interpolated VDF
    vdfx, vdfz, vdfd = gm.vdf(points, gridv=gridv, beta=numpy.pi/2)
    for i in range(4):
        ax=plt.axes([0.845, 0.75-0.24*i, 0.15, 0.225])
        ax.plot(gridV, vdfd[i](-gridV), 'b', label='f(v_los)')
        ax.plot(gridV, vdfx[i](-gridV), 'r', label='f(v_R)')
        ax.plot(gridV, vdfz[i](-gridV), 'g', label='f(v_z)')
        ax.set_yscale('log')
        ax.text(0.02, 0.98, 'field %s' % chr(i+65), ha='left', va='top', transform=ax.transAxes, color='olive')
        ax.set_xlim(min(gridv), max(gridv))
        ax.set_ylim(1e-5, 3e-2)
        if i&lt;3:
            ax.set_xticklabels([])
        else:
            ax.set_xlabel('V [km/s]')
        if i==0:
            ax.legend(loc='lower center', frameon=False)
            ax.text(1.0, 1.05, 'projected velocity distributions in fields', ha='right', va='center', transform=ax.transAxes)
        ax.set_ylabel('f(V)', labelpad=3)
    plt.savefig('nsd_model.pdf')
    plt.show()


if __name__ == '__main__':

    agama.setUnits(length=1, velocity=1, mass=1e10)   # 1 kpc, 1 km/s, 1e10 Msun

    # initialize the SelfConsistentModel object (only the potential expansion parameters)
    model = agama.SelfConsistentModel(
        RminCyl        = 0.005,
        RmaxCyl        = 1.0,
        sizeRadialCyl  = 25,
        zminCyl        = 0.005,
        zmaxCyl        = 1.0,
        sizeVerticalCyl= 25,
        RminSph        = 0.0001,
        RmaxSph        = 0.1,
        sizeRadialSph  = 25,
        lmaxAngularSph = 8
    )

    # construct a two component model: NSD + NSC
    # NSD -&gt; generated self-consistently
    # NSC -&gt; kept fixed as an external potential

    # NSC best-fitting model from Chatzopoulos et al. 2015 (see Equation 28 here: https://arxiv.org/pdf/2007.06577.pdf)
    density_NSC_init = agama.Density(type='Dehnen',mass=6.1e-3,gamma=0.71,scaleRadius=5.9e-3,axisRatioZ=0.73)

    # NSD model 3 from Sormani et al. 2020 (see Equation 24 here: https://arxiv.org/pdf/2007.06577.pdf)
    d1 = agama.Density(type='Spheroid',DensityNorm=0.9*222.885,gamma=0,beta=0,axisRatioZ=0.37,outerCutoffRadius=0.0050617,cutoffStrength=0.7194)
    d2 = agama.Density(type='Spheroid',DensityNorm=0.9*169.975,gamma=0,beta=0,axisRatioZ=0.37,outerCutoffRadius=0.0246,cutoffStrength=0.7933)
    density_NSD_init = agama.Density(d1,d2)

    # add both NSC and NSD components as static density profiles for the moment:
    # assign NSC and SMBH to the Multipole potential, and NSD to the CylSpline
    model.components.append(agama.Component(density=density_NSC_init, disklike=False))
    model.components.append(agama.Component(density=density_NSD_init, disklike=True))

    # compute the initial guess for the potential
    model.iterate()
    plotVcirc(model, 0)

    # introduce DF for the NSD component
    mass     = 0.097
    Rdisk    = 0.075
    Hdisk    = 0.025
    sigmar0  = 75.0
    Rsigmar  = 1.0
    sigmamin = 2.0
    Jmin     = 10.0
    dfNSD = agama.DistributionFunction(potential=model.potential, type='QuasiIsothermal',
        mass=mass, Rdisk=Rdisk, Hdisk=Hdisk, sigmar0=sigmar0, Rsigmar=Rsigmar, sigmamin=sigmamin, Jmin=Jmin)

    # replace the static density of the NSD by a DF-based component
    model.components[1] = agama.Component(df=dfNSD, disklike=True,
        RminCyl=0.005, RmaxCyl=0.75, sizeRadialCyl=20, zminCyl=0.005, zmaxCyl=0.25, sizeVerticalCyl=15)

    # iterate to make NSD DF &amp; potential self-consistent
    for iteration in range(1,5):
        print('Starting iteration #%d' % iteration)
        model.iterate()
        plotVcirc(model, iteration)

    # plot density and kinematic structure of the final model
    plotModel(model, dfNSD)
</file>
    <file path="py/example_mw_potential_hunter24.py">
#!/usr/bin/python
&quot;&quot;&quot;
This script uses the analytic approximation for the bar model from Portail et al.(2017),
in combination with several other mass components (central black hole, nuclear star cluster,
nuclear stellar disk, thin and thick stellar disks, gas disks, dark halo, and spiral arms)
to create a realistic Milky Way potential satisfying present-day observational constraints.
The bar model is taken from `example_mw_bar_potential.py', but other components are different;
this variant rectifies some of the weaknesses of the original bar model that was not fitted
to the region outside the central 5 kpc.
The left panel shows the circular-velocity curve (in the axisymmetrized potential),
and the right panel shows examples of a few orbits in this potential.

References: Sormani et al. 2022 (MNRAS Letters/514/L5); Hunter et al. 2024 (arXiv:2403.18000)

Authors: Mattia Sormani, Glen Hunter, Eugene Vasiliev
&quot;&quot;&quot;
import agama, numpy, matplotlib.pyplot as plt, scipy.special
from example_mw_bar_potential import makeBarDensity

agama.setUnits(length=1, mass=1, velocity=1)  # 1 kpc, 1 Msun, 1 km/s
filename_full     = 'MWPotentialHunter24_full.ini'
filename_axi      = 'MWPotentialHunter24_axi.ini'
filename_spiral   = 'MWPotentialHunter24_spiral.ini'
filename_rotating = 'MWPotentialHunter24_rotating.ini'
filename_rotspiral= 'MWPotentialHunter24_rotspiral.ini'
Omega_bar         = -37.5
Omega_spiral      = -22.5
angle_bar         = -25.0 * numpy.pi/180

def makePotentialModel():
    &quot;&quot;&quot;
    Create the potential of the entire Milky Way model:
    3-component bar density as defined in a separate file (example_mw_bar_potential.py),
    central structures (SgrA*, NSC and NSD), two stellar disks (thin and thick),
    two gas disks (same as in McMillan 2017), dark halo, and optionally four spiral arms.
    Even though the model has many ingredients, the total potential consists of
    only two components (three if spiral arms are used): all spherical or axisymmetric
    structures (SgrA*, NSC, NSD, and dark halo) are bunched together into a single Multipole
    potential, and all remaining baryonic components (bar, thin/thick stellar disks, and
    two gas disks) are represented by a single triaxial CylSpline potential.
    The spiral arms are represented by a separate bisymmetric CylSpline potential,
    since (1) they are optional, (2) their pattern speed differs from that of the bar.
    The resulting potentials are stored in several files:
    MWPotentialHunter2024_full.ini - the combination of all components except spiral arms,
        i.e., axisymmetric Multipole and triaxial CylSpline, with the bar oriented along
        the x axis, non-rotating.
    MWPotentialHunter2024_axi.ini - same components, but using axisymmetrized version of
        the CylSpline, suitable for plotting the circular-velocity curve.
    MWPotentialHunter2024_spiral.ini - a separate CylSpline potential for spiral arms,
        oriented to match their location relative to the bar, non-rotating.
    MWPotentialHunter2024_rotating.ini - all components except spirals,
        with added clockwise rotation with the angular speed Omega_bar = -37.5 km/s/kpc
        and oriented such that at t=0 the bar major axis is at -25 degrees from the x axis.
    MWPotentialHunter2024_rotspiral.ini - same but with added spirals
        rotating clockwise with the angular speed Omega_spiral = -22.5 km/s/kpc.
    &quot;&quot;&quot;

    # Analytic Plummer potential for SgrA*
    # (NB: scale radius is arbitrarily set to 1 pc, much larger than the Schwarzschild radius!)
    params_BH = dict(type='Plummer', mass=4.1e6, scaleRadius=1e-3)

    # Axisymmetric flattened spheroidal potential for the nuclear star cluster (Chatzopoulos+ 2015)
    params_NSC = dict(type='Spheroid', mass=6.1e7, gamma=0.71, beta=4, alpha=1,
        axisRatioZ=0.73, scaleRadius=0.0059, outerCutoffRadius=0.1)

    # two-component axisymmetric flatten spheroidal potential for the nuclear stellar disk (Sormani+ 2020)
    params_NSD = [
        dict(type='Spheroid', densityNorm=2.00583e12, gamma=0, beta=0, alpha=1,
            axisRatioZ=0.37, outerCutoffRadius=0.00506, cutoffStrength=0.72),
        dict(type='Spheroid',densityNorm=1.53e12, gamma=0, beta=0, alpha=1,
            axisRatioZ=0.37, outerCutoffRadius=0.0246, cutoffStrength=0.79) ]

    # analytic bar density (Sormani+ 2022)
    dens_bar = makeBarDensity()

    # Stellar disk (thin/thick) with a central hole where the bar replaces it)
    params_disk = [
        dict(type='Disk', surfaceDensity=1.332e9, scaleRadius=2.0, scaleHeight=0.3,
            innerCutoffRadius=2.7, sersicIndex=1),  # thin stellar disk
        dict(type='Disk', surfaceDensity=8.97e8, scaleRadius=2.8, scaleHeight=0.9,
            innerCutoffRadius=2.7, sersicIndex=1) ] # thick stellar disk

    params_gas = [
        dict(type='Disk', surfaceDensity=5.81e7, scaleRadius=7, scaleHeight=-0.085,
            innerCutoffRadius=4, sersicIndex=1),   # HI gas disk
        dict(type='Disk', surfaceDensity=2.68e9, scaleRadius=1.5, scaleHeight=-0.045,
            innerCutoffRadius=12, sersicIndex=1) ] # molecular gas disk

    # Einasto Dark matter potential with rho_{-2} = 2.216e7 Msun/kpc^3 and r_{-2} = 16.42 kpc
    params_dark = dict(type='Spheroid', densitynorm=2.774e11, gamma=0, beta=0, alpha=1,
        outerCutoffRadius=8.682e-6, cutoffStrength = 0.1704)

    # all spheroidal components put into a single axisymmetric Multipole potential
    pot_mul = agama.Potential(type='Multipole',
        density=agama.Density(params_dark, params_BH, params_NSC, *params_NSD),
        lmax=12, gridSizeR=36, rmin=1e-4, rmax=1000)

    # all remaining components (except spirals) are represented by a CylSpline potential
    # in two variants: axisymmetric (suitable for plotting the circular velocity profile)
    # and triaxial (for all other purposes)
    params_cylspline = dict(type='CylSpline',
        density=agama.Density(dens_bar, *(params_disk + params_gas)),
        gridSizeR=30, gridSizez=32, Rmin=0.1, Rmax=200, zmin=0.05, zmax=200)
    pot_cyl_axi  = agama.Potential(mmax=0, **params_cylspline)
    pot_cyl_full = agama.Potential(mmax=8, **params_cylspline)

    # spiral arms go into a separate CylSpline potential, which has zero amplitude in the m=0 term,
    # so does not contribute to the axisymmetrized version of the total potential
    density_disk = agama.Density(*params_disk)   # density of the stellar disk
    m   = 2                     # number of spiral arms
    i   = 12.5 * numpy.pi/180   # pitch angle of the logarithmic spiral
    Ra  = 9.64                  # fiducial radius [kpc]
    sig = 5.0                   # width of the spiral [kpc]
    # two sets of m=2 spirals with different phase angles (not equivalent to a single m=4 spiral)
    phi1= 139.5 * numpy.pi/180  # phase angle of the first set of spiral arms
    phi2= 69.75 * numpy.pi/180  # phase angle of the second set of spiral arms
    def densfnc(pos):
        R   = (pos[:,0]**2 + pos[:,1]**2)**0.5
        phi = numpy.arctan2(pos[:,1], pos[:,0])
        F   = (m/numpy.tan(i)) * numpy.log(numpy.maximum(R, 1e-12) / Ra)
        S   = (-2 * scipy.special.i0e(-(R/sig)**2) +
            numpy.exp(-(R/sig)**2 * (1 - numpy.cos(m * (phi+phi1) - F))) +
            numpy.exp(-(R/sig)**2 * (1 - numpy.cos(m * (phi+phi2) - F))) )
        # the minimum of S for the entire range of phi and R is around -0.33 for each of the two spiral components;
        # make sure that the total amplitude of the spiral is no larger than -1
        amp = numpy.minimum(0.36 * (R/8.179)**2, 1.5)
        return amp * S * density_disk.density(pos)
    pot_spiral = agama.Potential(type='CylSpline', density=densfnc,
        Rmin=0.2, Rmax=40, gridSizeR=80, zmin=0.1, zmax=10, gridSizeZ=20, mmax=8, symmetry='b')

    # now export these potentials into several files
    agama.Potential(pot_mul, pot_cyl_full).export(filename_full)
    agama.Potential(pot_mul, pot_cyl_axi ).export(filename_axi)
    pot_spiral.export(filename_spiral)

    # the remaining two files with rotation are created &quot;manually&quot;, since the Potential.export() method
    # currently cannot store the information about potential modifiers (including rotation)
    with open(filename_rotating, 'w') as f:
        f.write('''# Milky Way potential from Hunter+ 2024 with added rotation
[Potential]
file=%s
rotation=[[0,%.2f],[1,%.2f]]
''' % (filename_full, angle_bar, angle_bar + Omega_bar))
    with open(filename_rotspiral, 'w') as f:
        f.write('''# Milky Way potential from Hunter+ 2024 with added rotation and spiral arms
[Potential main]
file=%s
rotation=[[0,%.2f],[1,%.2f]]

[Potential spiral]
file=%s
rotation=[[0,%.2f],[1,%.2f]]
''' % (filename_full, angle_bar, angle_bar + Omega_bar, filename_spiral, angle_bar, angle_bar + Omega_spiral))

try:
    pot_axi = agama.Potential(filename_axi)
except RuntimeError:  # file does not exist - create on the first run
    makePotentialModel()
    pot_axi = agama.Potential(filename_axi)
pot_rotspiral = agama.Potential(filename_rotspiral)
# for plotting the surface density, use only the cylspline component of the full potential plus the spirals
pot_plot = agama.Potential(
    agama.Potential(filename_full)[1],
    agama.Potential(filename_spiral) )

r=agama.nonuniformGrid(100, 0.001, 500)
xyz=numpy.column_stack((r,r*0,r*0))
ax=plt.subplots(1, 2, figsize=(12,6), dpi=100)[1]
ax[0].plot(r, (-r*pot_axi[0].force(xyz)[:,0])**0.5, 'y', label='spheroidal components (BH, NSC, NSD and halo)')
ax[0].plot(r, (-r*pot_axi[1].force(xyz)[:,0])**0.5, 'c', label='disky components (bar, stellar and gas disks)')
ax[0].plot(r, (-r*pot_axi   .force(xyz)[:,0])**0.5, 'r', label='total')
ax[0].legend(loc='lower right', frameon=False, fontsize=12)
ax[0].set_xlabel('radius [kpc]')
ax[0].set_ylabel('circular velocity [km/s]')
ax[0].set_xlim(0,10)

# integrate and show a few orbits
numorbits=8
numpy.random.seed(42)
ic=numpy.random.normal(size=(numorbits,6)) * numpy.array([2.0, 0.0, 0.4, 50., 40., 30.])
ic[:,0] += -6.
ic[:,4] += 220
#angle_bar = -25.0 * numpy.pi/180  # orientation of the bar w.r.t. the Sun
#Omega = -39.0  # km/s/kpc - the value is negative since the potential rotates clockwise
times, orbits = agama.orbit(potential=pot_rotspiral, ic=ic, time=10., trajsize=1001).T
rmax = 10.0   # plotting range
cmap = plt.get_cmap('mist')
for i in range(numorbits):
    sina, cosa = numpy.sin(times[i] * Omega_bar), numpy.cos(times[i] * Omega_bar)
    ax[1].plot(orbits[i][:,0]*cosa+orbits[i][:,1]*sina, -orbits[i][:,0]*sina+orbits[i][:,1]*cosa,
        color=cmap(i*1.0/numorbits), lw=0.5)
ax[1].plot(-8.2,0.0, 'ko', ms=5)  # Solar position
ax[1].text(-8.0,0.0, 'Sun')
ax[1].set_xlabel('x [kpc]')
ax[1].set_ylabel('y [kpc]')
ax[1].set_xlim(-rmax, rmax)
ax[1].set_ylim(-rmax, rmax)

# overplot the surface density contours
print('Computing surface density of bar+disk')
gridr  = numpy.linspace(-rmax, rmax, 101)  # 1d grid
gridxy = numpy.column_stack((numpy.repeat(gridr, len(gridr)), numpy.tile(gridr, len(gridr))))  # 2d grid
Sigma  = pot_plot.projectedDensity(gridxy, gamma=-angle_bar)  # surface density for a stellar component rotated by angle_bar
logSigma = 2.5 * numpy.log10(Sigma / numpy.max(Sigma))        # log-scaled to magnitudes per unit square
# thick lines spaced by one magnitude, thin lines lie halfway between thick ones
ax[1].contour(gridr, gridr, logSigma.reshape(len(gridr), len(gridr)).T,
    levels=numpy.linspace(-8,0,17), colors='k', zorder=5, linewidths=[2,1], linestyles='solid')

plt.tight_layout()
plt.show()
</file>
    <file path="py/example_nbody_simulation_arepo.param">
%----  Relevant files
InitCondFile                            IC.snap
OutputDir                               output
SnapshotFileBase                        snapshot
OutputListFilename                      none
ResubmitOn                              0
ResubmitCommand                         none

%---- File formats
ICFormat                                2
SnapFormat                              2

%---- CPU-time limits in seconds
TimeLimitCPU                            1800
CpuTimeBetRestartFile                   7200

%----- Memory alloction
MaxMemSize                              2000

%---- Characteristics of run
TimeBegin                               0.0    % Begin of the simulation
TimeMax                                 0.25   % End of the simulation

%---- Basic code options that set the type of simulation
ComovingIntegrationOn                   0
PeriodicBoundariesOn                    0
CoolingOn                               0
StarformationOn                         0

%---- Cosmological parameters (unused)
Omega0                                  0.0
OmegaLambda                             0.0
OmegaBaryon                             0.0
HubbleParam                             1.0
BoxSize                                 0

%---- Output frequency and output parameters
OutputListOn                            0
TimeBetSnapshot                         0.001953125
TimeOfFirstSnapshot                     0
TimeBetStatistics                       0.03125
NumFilesPerSnapshot                     1
NumFilesWrittenInParallel               1

%---- Accuracy of time integration
TypeOfTimestepCriterion                 0
ErrTolIntAccuracy                       0.1
CourantFac                              0.15
MaxSizeTimestep                         0.001953125
MinSizeTimestep                         0

%---- Tree algorithm, force accuracy, domain update frequency
TypeOfOpeningCriterion                  1
ErrTolTheta                             0.5
ErrTolForceAcc                          0.005
MultipleDomains                         8
TopNodeFactor                           2.5
ActivePartFracForNewDomainDecomp        0.01
 
%---- Initial density estimate
DesNumNgb                               64
MaxNumNgbDeviation                      4

%---- System of units
UnitLength_in_cm                        3.085678e21   %  1.0 kpc/h
UnitMass_in_g                           1.989e33      %  1 solar mass
UnitVelocity_in_cm_per_s                1e5           %  1 km/sec
GravityConstantInternal                 0             %  determine automatically from the above units

%---- Gravitational softening lengths
SofteningComovingType0                  0
SofteningComovingType1                  0.001
SofteningComovingType2                  0
SofteningComovingType3                  0
SofteningComovingType4                  0
SofteningComovingType5                  0

SofteningMaxPhysType0                   0
SofteningMaxPhysType1                   0.001
SofteningMaxPhysType2                   0
SofteningMaxPhysType3                   0
SofteningMaxPhysType4                   0
SofteningMaxPhysType5                   0

SofteningTypeOfPartType0                0
SofteningTypeOfPartType1                1
SofteningTypeOfPartType2                1
SofteningTypeOfPartType3                1
SofteningTypeOfPartType4                1
SofteningTypeOfPartType5                1

GasSoftFactor                           2.5

%----- Mesh regularization options
CellShapingSpeed                        0.5
CellShapingFactor                       1.0

%---- Treatment of empty space and temperature limits
InitGasTemp                             0
MinGasTemp                              0
MinimumDensityOnStartUp                 0
LimitUBelowThisDensity                  0
LimitUBelowCertainDensityToThisValue    0
MinEgySpec                              0
</file>
    <file path="py/example_nbody_simulation_arepo.patch">
diff -u -r -N arepo-master/Makefile arepo-agama/Makefile
--- arepo-master/Makefile	2024-03-20 11:05:32.000000000 +0000
+++ arepo-agama/Makefile	2024-03-20 11:27:03.000000000 +0000
@@ -320,6 +320,9 @@
 
 LIBS = $(GMP_LIB) $(MATH_LIB) $(MPICH_LIB) $(HDF5_LIB) $(GSL_LIB) $(FFTW_LIB) $(HWLOC_LIB)
 
+ifeq (EXTERNALGRAVITY_AGAMA, $(findstring EXTERNALGRAVITY_AGAMA, $(CONFIGVARS)))
+endif
+
 FOPTIONS = $(OPTIMIZE)
 FFLAGS = $(FOPTIONS)
 
diff -u -r -N arepo-master/Template-Config.sh arepo-agama/Template-Config.sh
--- arepo-master/Template-Config.sh	2023-04-29 14:33:30.000000000 +0100
+++ arepo-agama/Template-Config.sh	2024-03-20 11:23:30.000000000 +0000
@@ -89,6 +89,9 @@
 #EXTERNALGRAVITY               # master switch for external potential
 #EXTERNALGY=0.0                # constant external gravity in y direction
 
+#--------------------------------------- External potential provided by the Agama package
+#EXTERNALGRAVITY_AGAMA         # external potential provided by the Agama package and described by parameters in agama_potential.ini
+
 #--------------------------------------- Static NFW Potential
 #STATICNFW                     # static gravitational Navarro-Frenk-White (NFW) potential
 #NFW_C=12                      # concentration parameter of NFW potential
diff -u -r -N arepo-master/documentation/source/config-options.md arepo-agama/documentation/source/config-options.md
--- arepo-master/documentation/source/config-options.md	2023-04-29 14:33:30.000000000 +0100
+++ arepo-agama/documentation/source/config-options.md	2024-03-20 11:24:40.000000000 +0000
@@ -610,6 +610,13 @@
 
 Constant external gravity in the y-direction
 
+-------
+
+**EXTERNALGRAVITY_AGAMA**
+
+Activates an external potential provided by the Agama package,
+with parameters given in the file agama_potential.ini
+
 -----
 
 NFW Potential
diff -u -r -N arepo-master/src/gravity/grav_external.c arepo-agama/src/gravity/grav_external.c
--- arepo-master/src/gravity/grav_external.c	2023-04-29 14:33:30.000000000 +0100
+++ arepo-agama/src/gravity/grav_external.c	2024-03-20 11:20:59.000000000 +0000
@@ -47,6 +47,11 @@
 
 #include &quot;../domain/domain.h&quot;
 
+#ifdef EXTERNALGRAVITY_AGAMA
+void* agama_potential = NULL;
+extern double agama_evalPotential(const void* potential, const double pos[3], double time, double deriv[3], double deriv2[6]);
+#endif
+
 #ifdef EXTERNALGRAVITY
 static void gravity_external_get_force(double pos[3], int type, MyIDType ID, double acc[3], double *pot, int *flag_set);
 
@@ -71,14 +76,20 @@
       if(i &lt; 0)
         continue;
 
-      double *pos;
+      double pos[3];
 
 #ifdef CELL_CENTER_GRAVITY
-      if(P[i].Type == 0)
-        pos = SphP[i].Center;
-      else
+      if(P[i].Type == 0) {
+        pos[0] = SphP[i].Center[0];
+        pos[1] = SphP[i].Center[1];
+        pos[2] = SphP[i].Center[2];
+      } else
 #endif /* #ifdef CELL_CENTER_GRAVITY */
-        pos = P[i].Pos;
+      {
+        pos[0] = P[i].Pos[0];
+        pos[1] = P[i].Pos[1];
+        pos[2] = P[i].Pos[2];
+      }
 
       double acc[3], pot;
       int flag_set = 0;
@@ -158,6 +169,16 @@
   *pot = -(EXTERNALGY)*pos[1];
 #endif /* #ifdef EXTERNALGY */
 
+#ifdef EXTERNALGRAVITY_AGAMA
+  {
+    double deriv[3];
+    *pot += agama_evalPotential(agama_potential, pos, All.Time, deriv, NULL);
+    acc[0] -= deriv[0];
+    acc[1] -= deriv[1];
+    acc[2] -= deriv[2];
+  }
+#endif
+
 #ifdef STATICISO
   {
     double r, m;
diff -u -r -N arepo-master/src/init/begrun.c arepo-agama/src/init/begrun.c
--- arepo-master/src/init/begrun.c	2023-04-29 14:33:30.000000000 +0100
+++ arepo-agama/src/init/begrun.c	2024-03-20 11:21:15.000000000 +0000
@@ -58,6 +58,12 @@
 herr_t my_hdf5_error_handler(void *unused);
 #endif
 
+#ifdef EXTERNALGRAVITY_AGAMA
+extern void* agama_potential;
+extern const char* agama_getError();
+extern void* agama_createPotential(const char* params);
+#endif
+
 static void delete_end_file(void);
 
 /*! \brief Prints a welcome message.
@@ -192,6 +198,17 @@
   All.FlushLast = CPUThisRun;
 #endif /* #ifdef REDUCE_FLUSH */
 
+#ifdef EXTERNALGRAVITY_AGAMA
+  char param[100] = &quot;file=agama_potential.ini G=&quot;;
+  snprintf(param + strlen(param), 99 - strlen(param), &quot;%.16g&quot;, All.G);
+  agama_potential = agama_createPotential(param);
+  if(!agama_potential) {
+    mpi_printf(&quot;BEGRUN: Cannot initialize Agama potential, halting.\n%s\n&quot;, agama_getError());
+    exit(1);
+  }
+  mpi_printf(&quot;BEGRUN: Initialized Agama potential with %s.\n&quot;, param);
+#endif
+
   init_scalars();
 
   init_gradients();
</file>
    <file path="py/example_nbody_simulation_gadget4.param">
%----  Relevant files
InitCondFile                            IC.snap
OutputDir                               output
SnapshotFileBase                        snapshot
OutputListFilename                      none

%---- File formats
ICFormat                                2
SnapFormat                              2

%---- CPU-time limits in seconds
TimeLimitCPU                            1800
CpuTimeBetRestartFile                   7200

%----- Memory alloction
MaxMemSize                              2000

%---- Characteristics of run
TimeBegin                               0.0    % Begin of the simulation
TimeMax                                 0.25   % End of the simulation

%---- Basic code options that set the type of simulation
ComovingIntegrationOn                   0

%---- Cosmological parameters (unused)
Omega0                                  0.0
OmegaLambda                             0.0
OmegaBaryon                             0.0
HubbleParam                             1.0
Hubble                                  0
BoxSize                                 0

%---- Output frequency and output parameters
OutputListOn                            0
TimeBetSnapshot                         0.001953125
TimeOfFirstSnapshot                     0
TimeBetStatistics                       0.03125
NumFilesPerSnapshot                     1
MaxFilesWithConcurrentIO                1

%---- Accuracy of time integration
ErrTolIntAccuracy                       0.1
CourantFac                              0.15
MaxSizeTimestep                         0.001953125
MinSizeTimestep                         0

%---- Tree algorithm, force accuracy, domain update frequency
TypeOfOpeningCriterion                  1
ErrTolTheta                             0.5
ErrTolThetaMax                          0.9
ErrTolForceAcc                          0.005
TopNodeFactor                           2.5
ActivePartFracForNewDomainDecomp        0.01
 
%---- Initial density estimate
DesNumNgb                               64
MaxNumNgbDeviation                      4

%---- System of units
UnitLength_in_cm                        3.085678e21   %  1.0 kpc/h
UnitMass_in_g                           1.989e33      %  1 solar mass
UnitVelocity_in_cm_per_s                1e5           %  1 km/sec
GravityConstantInternal                 0             %  determine automatically from the above units

%---- Gravitational softening lengths
SofteningComovingClass0                 0
SofteningComovingClass1                 0.001
SofteningComovingClass2                 0
SofteningComovingClass3                 0
SofteningComovingClass4                 0
SofteningComovingClass5                 0

SofteningMaxPhysClass0                  0
SofteningMaxPhysClass1                  0.001
SofteningMaxPhysClass2                  0
SofteningMaxPhysClass3                  0
SofteningMaxPhysClass4                  0
SofteningMaxPhysClass5                  0

SofteningClassOfPartType0               0
SofteningClassOfPartType1               1
SofteningClassOfPartType2               1
SofteningClassOfPartType3               1
SofteningClassOfPartType4               1
SofteningClassOfPartType5               1

%----- SPH
ArtBulkViscConst                        1.0
InitGasTemp                             0
MinEgySpec                              0
</file>
    <file path="py/example_nbody_simulation_gadget4.patch">
diff -u -r -N gadget4-master/Makefile gadget4-agama/Makefile
--- gadget4-master/Makefile	2024-03-19 18:08:53.000000000 +0000
+++ gadget4-agama/Makefile	2024-03-19 18:15:17.000000000 +0000
@@ -446,6 +446,8 @@
 
 LIBS = $(MATH_LIBS) $(HDF5_LIBS) $(GSL_LIBS) $(FFTW_LIBS) $(HWLOC_LIBS) $(VTUNE_LIBS) $(TEST_LIBS) $(MAPS_LIBS) $(SHMEM_LIBS)
 
+ifeq (EXTERNALGRAVITY_AGAMA, $(findstring EXTERNALGRAVITY_AGAMA, $(CONFIGVARS)))
+endif
 
 SUBDIRS := $(addprefix $(BUILD_DIR)/,$(SUBDIRS))
 OBJS := $(addprefix $(BUILD_DIR)/,$(OBJS)) $(BUILD_DIR)/compile_time_info.o $(BUILD_DIR)/compile_time_info_hdf5.o $(BUILD_DIR)/version.o
diff -u -r -N gadget4-master/Template-Config.sh gadget4-agama/Template-Config.sh
--- gadget4-master/Template-Config.sh	2024-03-19 18:06:29.000000000 +0000
+++ gadget4-agama/Template-Config.sh	2024-03-19 18:16:24.000000000 +0000
@@ -33,6 +33,7 @@
 #ALLOW_DIRECT_SUMMATION                       # allows calculation of direct summation gravity force if only a tiny number of particles as active 
 #EXTERNALGRAVITY                              # switches on inclusion of external gravitational potential
 #EXTERNALGRAVITY_STATICHQ                     # example for a simple external potential due to a Hernquist halo
+#EXTERNALGRAVITY_AGAMA                        # external potential provided by the Agama package and described by parameters in agama_potential.ini
 
 #--------------------------------------- TreePM Options
 
diff -u -r -N gadget4-master/documentation/04_config-options.md gadget4-agama/documentation/04_config-options.md
--- gadget4-master/documentation/04_config-options.md	2024-01-21 12:29:33.000000000 +0000
+++ gadget4-agama/documentation/04_config-options.md	2024-03-19 18:20:34.000000000 +0000
@@ -369,6 +369,13 @@
 
 -------
 
+**EXTERNALGRAVITY_AGAMA**
+
+Activates an external potential provided by the Agama package,
+with parameters given in the file agama_potential.ini
+
+-------
+
 
 TreePM Options                                             {#treepm}
 ==============
diff -u -r -N gadget4-master/src/gravity/grav_external.cc gadget4-agama/src/gravity/grav_external.cc
--- gadget4-master/src/gravity/grav_external.cc	2024-01-21 12:29:33.000000000 +0000
+++ gadget4-agama/src/gravity/grav_external.cc	2024-03-20 09:08:00.000000000 +0000
@@ -33,6 +33,13 @@
 #include &quot;../system/system.h&quot;
 #include &quot;../time_integration/timestep.h&quot;
 
+#ifdef EXTERNALGRAVITY_AGAMA
+void* agama_potential = NULL;
+extern &quot;C&quot; {
+double agama_evalPotential(const void* potential, const double pos[3], double time, double deriv[3], double deriv2[6]);
+}
+#endif
+
 void sim::gravity_external(void)
 {
 #ifdef PERIODIC
@@ -70,6 +77,21 @@
 #endif
       }
 #endif
+
+#ifdef EXTERNALGRAVITY_AGAMA
+      {
+        vector&lt;double&gt; pos;
+        Sp.nearest_image_intpos_to_pos(Sp.P[target].IntPos, intpos_center, pos.da);
+        double deriv[3];
+#if defined(EVALPOTENTIAL) || defined(OUTPUT_POTENTIAL)
+        Sp.P[target].ExtPotential +=
+#endif
+        agama_evalPotential(agama_potential, &amp;pos.da[0], All.Time, deriv, NULL);
+        Sp.P[target].GravAccel.da[0] -= deriv[0];
+        Sp.P[target].GravAccel.da[1] -= deriv[1];
+        Sp.P[target].GravAccel.da[2] -= deriv[2];
+      }
+#endif
     }
 }
 
diff -u -r -N gadget4-master/src/main/begrun.cc gadget4-agama/src/main/begrun.cc
--- gadget4-master/src/main/begrun.cc	2024-01-21 12:29:33.000000000 +0000
+++ gadget4-agama/src/main/begrun.cc	2024-03-20 09:08:47.000000000 +0000
@@ -50,6 +50,14 @@
 #include &quot;../time_integration/driftfac.h&quot;
 #include &quot;../time_integration/timestep.h&quot;
 
+#ifdef EXTERNALGRAVITY_AGAMA
+extern void* agama_potential;
+extern &quot;C&quot; {
+const char* agama_getError();
+void* agama_createPotential(const char* params);
+}
+#endif
+
 /*!
  *  This file contains various functions to initialize a simulation run. In
  *  particular, the parameter file is read in and parsed and global variables
@@ -267,6 +275,17 @@
     }
 #endif
 
+#ifdef EXTERNALGRAVITY_AGAMA
+  char param[100] = &quot;file=agama_potential.ini G=&quot;;
+  snprintf(param + strlen(param), 99 - strlen(param), &quot;%.16g&quot;, All.G);
+  agama_potential = agama_createPotential(param);
+  if(!agama_potential) {
+    mpi_printf(&quot;BEGRUN: Cannot initialize Agama potential, halting.\n%s\n&quot;, agama_getError());
+    exit(1);
+  }
+  mpi_printf(&quot;BEGRUN: Initialized Agama potential with %s.\n&quot;, param);
+#endif
+
   Logs.open_logfiles();
 
   All.TimeLastRestartFile = Logs.CPUThisRun;
</file>
    <file path="py/example_nbody_simulation.py">
#!/usr/bin/python
&quot;&quot;&quot;
This example demonstrates the use of Agama as a source of external gravitational potential
in several N-body simulation codes: GyrfalcON (from NEMO), Gadget4, Arepo.
The first of these codes uses the agama.so shared library directly as a plug-in, whereas
the other two need some patches and recompilation; this script attempts to do this automatically.
In additional, a &quot;restricted N-body simulation&quot; method that uses the built-in tools from Agama
can be used as a faster (but more approximate) alternative: it evolves the collection of orbits
in the moving potential of the cluster on a prescribed trajectory in the host galaxy, updating
this cluster potential periodically to account for the mass loss due to tidal stripping.
This method is also illustrated by the script &quot;example_tidal_stream.py&quot;.
The host galaxy potential mimics the Milky Way with a rotating bar, and is created separately
using the script &quot;example_mw_potential_hunter24.py&quot;. The cluster is placed on an orbit within
the bar region, which leads to the stripping of ~1/3 of its mass by the end of the simulation
(which takes a few minutes).
&quot;&quot;&quot;
import sys, agama, numpy

agama.setUnits(length=1, velocity=1, mass=1)  # length = 1 kpc, velocity = 1 km/s, mass = 1 Msun

# create an isolated star cluster
c_pot = agama.Potential(type='plummer', scaleRadius=0.01, mass=1e6)
c_df  = agama.DistributionFunction(type='quasispherical', potential=c_pot)
c_gm  = agama.GalaxyModel(c_pot, c_df)
N     = 10000
xv, m = c_gm.sample(N)
# shift it to some initial point in the Galaxy
c_center = numpy.hstack([2.0, 0, 0, 0, -100, 50])
xv   += c_center
sim_time = 0.25  # total simulation time in units of kpc/(km/s) = 0.98 Gyr

potfile = 'MWPotentialHunter24_rotating.ini'
try:
    g_pot = agama.Potential(potfile)
except RuntimeError:
    print('You need to create the barred Milky Way potential by running the script &quot;example_mw_potential_hunter24.py&quot;')
    exit(1)
print('''Initial conditions for a cluster in the galaxy are created, what to do next?
  1 - show the orbit of the cluster center as a test particle
  2 - run the simulation of a disrupting cluster using the Agama-only &quot;restricted N-body&quot; approach
  3 - run the simulation using the GyrfalcON code (from existing NEMO installation)
  4 - run the simulation using the Gadget4 code (downloading and compiling if necessary)
  5 - run the simulation using the Arepo code (downloading and compiling if necessary)
  any other key - exit''')

def runSingleOrbit():
    import matplotlib.pyplot as plt
    o = agama.orbit(potential=g_pot, ic=c_center, time=sim_time, trajsize=500)[1]
    plt.figure(figsize=(10,10), dpi=75)
    plt.plot(o[:,0], o[:,1], 'k')
    plt.xlim(-2.5, 2.5)
    plt.ylim(-2.5, 2.5)
    plt.show()


def runRestrictedNbody():
    import matplotlib.pyplot as plt
    plt.ion()
    plt.figure(figsize=(10,10), dpi=75)
    ax = plt.axes([0.08, 0.08, 0.9, 0.9])
    num_intervals = 32
    num_subint = 16
    interval = sim_time / num_intervals
    time_center, orbit_center = agama.orbit(potential=g_pot, ic=c_center, time=sim_time,
        trajsize=num_intervals * num_subint + 1)
    cpot = c_pot
    snap = xv.copy()
    print('Playing animation as the simulation progresses...')
    for i in range(num_intervals+1):
        # determine which particles remain bound to the satellite
        c_bound = c_pot.potential(snap[:,0:3] - orbit_center[i*num_subint, 0:3]) + 0.5 * numpy.sum((snap[:,3:6] - orbit_center[i*num_subint, 3:6])**2, axis=1) &lt; 0
        time = i * interval
        ax.cla()
        ax.scatter(snap[:,0], snap[:,1], c=c_bound, cmap='bwr_r', vmin=0, vmax=1, s=2, linewidths=0)
        ax.plot(orbit_center[0:i*num_subint, 0], orbit_center[0:i*num_subint, 1], color='k')
        ax.text(0.01, 0.99, 'time=%.4f, bound fraction=%.3f' % (time, numpy.sum(c_bound)*1./N), ha='left', va='top', transform=ax.transAxes)
        grid = numpy.linspace(-2.5, 2.5, 101)
        xyz = numpy.column_stack([numpy.repeat(grid,len(grid)), numpy.tile(grid,len(grid)), numpy.zeros(len(grid)**2)])
        den = g_pot.density(xyz, t=time).reshape(len(grid), len(grid)).T
        ax.contour(grid, grid, numpy.log10(den), levels=numpy.linspace(8.1, 12.1, 17), cmap='earth_r', zorder=2)
        ax.set_xlim(min(grid), max(grid))
        ax.set_ylim(min(grid), max(grid))
        plt.draw()
        plt.pause(0.01)
        if i == num_intervals: continue
        # evolve the cluster for some time:
        # initialize the time-dependent total potential (host + moving sat) on this time interval
        t_pot = agama.Potential(g_pot,
                agama.Potential(potential=cpot, center=numpy.column_stack((time_center, orbit_center))))
        # compute the trajectories of all particles moving in the combined potential of the host galaxy and the moving satellite
        snap = numpy.vstack(agama.orbit(ic=snap, potential=t_pot, time=interval, timestart=time, trajsize=1, accuracy=1e-5, verbose=False)[:,1])
        # update the potential of the satellite (using a spherical monopole approximation)
        cpot = agama.Potential(type='multipole', particles=(snap[:,0:3] - orbit_center[(i+1)*num_subint, 0:3], m), symmetry='s')
    filename = 'example_nbody_simulation_last.nemo'
    agama.writeSnapshot(filename, (snap,m), 'nemo')
    print('Saved the final snapshot to %s' % filename)
    plt.ioff()
    plt.show()


def runGyrfalcon():
    import os, subprocess
    path = 'gyrfalcon'
    if not os.path.isdir(path):
        os.mkdir(path)
    os.chdir(path)
    infile = 'IC.nemo'
    print('*** Writing the initial conditions into %s' % infile)
    agama.writeSnapshot(infile, (xv, m), 'nemo')
    outfile = 'output.nemo'
    endfile = 'output_last.nemo'
    if os.path.isfile(outfile):
        os.remove(outfile)
    if os.path.isfile(endfile):
        os.remove(endfile)
    runstr = ('gyrfalcON %s %s eps=0.001 kmax=14 Nlev=3 fea=0.5 step=0.001953125 tstop=0.25 logstep=32 '
        'Grav=%g accname=agama accpars=0,%g accfile=%s') % (infile, outfile, agama.G, agama.G, '../'+potfile)
    print('*** Launching the simulation (end time: %g):\n%s' % (sim_time, runstr))
    sub = subprocess.check_call(runstr, shell=True)
    if os.path.isfile(outfile):
        print('*** Done! You may play the simulation movie using &quot;glnemo %s/%s&quot;' % (path,outfile))
        # extract and show the last snapshot
        subprocess.check_call('s2s %s %s times=%g' % (outfile, endfile, sim_time), shell=True)
        showSnapshot(endfile)
    else:
        print('No output files produced, try running the above command manually to see the error messages')


def runArepoOrGadget(code):
    import os, platform, subprocess, zipfile, shutil, multiprocessing
    if sys.version_info.major == 2:
        from urllib import urlretrieve
    else:
        from urllib.request import urlretrieve
    path = code
    if os.path.isdir(path):
        print('*** Using the existing installation of %s' % code)
    else:
        print('*** Downloading %s' % code)
        filename = code + '.zip'
        # download a specific version of the codes, which is known to work;
        # one may use the same approach with the latest version or a private branch, but the patch might need to be adjusted
        if code == 'arepo':
            url = 'https://gitlab.mpcdf.mpg.de/vrs/arepo/-/archive/73d6bc4821daece021f02c0ae5da834c1d05b3c7/arepo-73d6bc4821daece021f02c0ae5da834c1d05b3c7.zip'
        elif code == 'gadget4':
            url = 'https://gitlab.mpcdf.mpg.de/vrs/gadget4/-/archive/1e171a4a679d30ac1e6accabe8a76a037ccbacac/gadget4-1e171a4a679d30ac1e6accabe8a76a037ccbacac.zip'
        urlretrieve(url, filename)
        if not os.path.isfile(filename):
            raise RuntimeError('Cannot find downloaded file %s' % filename)
        with zipfile.ZipFile(filename, 'r') as f:  # unpack the archive, manually setting the file attributes
            for info in f.infolist():
                extr = f.extract(info)
                attr = info.external_attr &gt;&gt; 16
                if attr:
                    os.chmod(extr, attr)
        os.remove(filename)  # remove the downloaded archive
        folder = url[url.rfind('/')+1:-4]
        os.rename(folder, path)  # simplify the folder name, removing the tag id

    # apply the patch file if necessary
    with open(path + '/Template-Config.sh', 'r') as f:
        lines = ''.join(f.readlines())
        if 'AGAMA' in lines:
            print('*** Code is already patched')
        else:
            print('*** Patching %s' % code)
            subprocess.check_call('patch -r -u -N -d %s -p 1 &lt; example_nbody_simulation_%s.patch' % (path, code), shell=True)
            # This is only half of the job; now we need to add the full path to agama.a and all other flags
            # necessary for linking it with executable files, which are taken from Makefile.local
            agama_root = os.path.abspath('../')
            if not (os.path.isfile(agama_root+'/Makefile.local') and os.path.isfile(agama_root+'/agama.a')):
                raise RuntimeError('Cannot find Makefile.local and agama.a in %s, exiting...' % agama_root)
            allflags = []
            # collect relevant linking flags from agama's Makefile.local
            with open(agama_root+'/Makefile.local', 'r') as mf:
                for line in mf.readlines():
                    if (line.startswith('LINK_FLAGS_ALL') or line.startswith('LINK_FLAGS_LIB_AND_EXE_STATIC') or
                            # for arepo, which is a C (not C++) program, need to add another set of flags...
                            code=='arepo' and line.startswith('LINK_FLAGS_EXE_STATIC_NONCPP')):
                        flags = line[line.find('=')+1:].strip().split(' ')
                        for i in range(len(flags)):
                            if flags[i].startswith('extras/'):
                                # replace relative paths to libraries in extras/... by absolute paths
                                flags[i] = agama_root + '/' + flags[i]
                            if flags[i].startswith('-Lextras/'):
                                flags[i] = '-L' + agama_root + '/' + flags[i][2:]
                        allflags += flags
            # now add these flags along with the full path to agama.a to the makefile of arepo/gadget
            with open(path + '/Makefile', 'r') as mf:
                lines = mf.readlines()
                for i in range(len(lines)):
                    if lines[i].startswith('ifeq (EXTERNALGRAVITY_AGAMA'):
                        lines = lines[:i+1] + ['LIBS += %s/agama.a ' % agama_root + ' '.join(allflags) + '\n'] + lines[i+1:]
                        break
            with open(path + '/Makefile', 'w') as mf:
                mf.write(''.join(lines))

    # compile
    os.chdir(path)
    executable = code[0].upper() + code[1:]
    if not os.path.isfile(executable):
        if not os.path.isfile('Makefile.systype'):
            with open('Makefile.systype', 'w') as f:
                if platform.uname()[0]=='Darwin':
                    systype = 'Darwin'
                else:
                    systype = 'Generic-gcc' if code == 'gadget4' else 'Ubuntu'
                f.write('SYSTYPE=&quot;%s&quot;\n' % systype)
        # macros written into Config.sh before compilation
        macros = ['SELFGRAVITY', 'EXTERNALGRAVITY', 'EXTERNALGRAVITY_AGAMA']
        if code == 'gadget4':
            macros += ['GADGET2_HEADER']
        elif code == 'arepo':
            macros += ['GRAVITY_NOT_PERIODIC']
        with open('Config.sh', 'w') as f:
            f.write('\n'.join(macros)+'\n')
        print('*** I am going to compile the executable %s/%s, ' % (path, executable) +
            'please adjust the files Config.sh, Makefile, Makefile.systype in the %s directory as needed.\n' % path +
            'In particular, make sure that GSL and HDF5 libraries are available, if necessary, '
            'adding -I/path_to_gsl_or_hdf5_include to CFLAGS and -L/path_to_gsl_or_hdf5_lib to LIBS.\n'
            'Press any key when ready...')
        input()
        # initiate compilation
        subprocess.check_call('make', shell=True)

    # final preparations
    infile = 'IC.snap'
    print('*** Writing the initial conditions into %s' % infile)
    agama.writeSnapshot(infile, (xv, m), 'gadget')

    with open('agama_potential.ini', 'w') as f:
        f.write('[Potential]\nfile=../%s\n' % potfile)

    shutil.copyfile('../example_nbody_simulation_%s.param' % code, 'param.txt')

    numproc = max(1, min(8, multiprocessing.cpu_count()))  # determine the number of processor cores for running MPI

    runstr = 'mpirun -np %i ./%s param.txt' % (numproc, executable)
    print('*** Launching the simulation (end time: %g):\n%s' % (sim_time, runstr))
    subprocess.check_call(runstr + ' | grep Time:', shell=True)

    # create a list of output files for easy loading into GLNemo
    if os.path.isdir('output'):
        outputfiles = sorted(['output/'+name for name in os.listdir('output') if name.startswith('snapshot')])
    else:
        outputfiles = []
    if outputfiles:
        with open('output_files.txt', 'w') as f:
            f.write('\n'.join(outputfiles) + '\n')
        print('*** Done! You may play the simulation movie using &quot;glnemo %s/output_files.txt&quot;' % path)
        showSnapshot(outputfiles[-1])
    else:
        print('No output files produced, try running the above command manually to see the error messages')


def showSnapshot(filename):
    import matplotlib.pyplot as plt
    pos = agama.readSnapshot(filename)[0]
    plt.figure(figsize=(10,10), dpi=75)
    plt.axes([0.08, 0.08, 0.9, 0.9])
    plt.scatter(pos[:,0], pos[:,1], c='b', s=2, linewidths=0)
    grid = numpy.linspace(-2.5, 2.5, 101)
    xyz = numpy.column_stack([numpy.repeat(grid,len(grid)), numpy.tile(grid,len(grid)), numpy.zeros(len(grid)**2)])
    den = g_pot.density(xyz, t=sim_time).reshape(len(grid), len(grid)).T
    plt.contour(grid, grid, numpy.log10(den), levels=numpy.linspace(8.1, 12.1, 17), cmap='earth_r', zorder=2)
    plt.xlim(min(grid), max(grid))
    plt.ylim(min(grid), max(grid))
    plt.show()

if sys.version_info.major == 2:
    input = raw_input
if len(sys.argv)&gt;1:
    choice = sys.argv[1]
    print(choice+'\n')
else:
    choice = input()
if choice == '1': runSingleOrbit()
if choice == '2': runRestrictedNbody()
if choice == '3': runGyrfalcon()
if choice == '4': runArepoOrGadget('gadget4')
if choice == '5': runArepoOrGadget('arepo')
</file>
    <file path="py/example_poincare.py">
#!/usr/bin/python
'''
This interactive example shows the meridional plane {x,z} (left panel) and the Poincare
surface of section {x,v_x} for an axisymmetric potential, where x is either cylindrical
radius R when L_z&gt;0 or the x coordinate otherwise, and points on the SoS are placed
when passing through the z=0 plane with v_z&gt;0.
Upon right-clicking at any point inside the zero-velocity curve on the surface of section,
a new orbit starting from these initial conditions is added to the plot.
The parameters of the potential, energy and L_z are specified at the beginning of the script.
'''
import agama, numpy, scipy.optimize, matplotlib, matplotlib.pyplot as plt
plt.rc('axes', linewidth=0.5)
plt.rc('font', size=8)
# consider motion in the x-z plane of an axisymmetric potential
# (with Lz=0 for motion in a flattened 2d potential, or Lz&gt;0 for the motion in the meridional plane)
#pot  = agama.Potential(type='spheroid', gamma=1.5, q=0.5)
pot  = agama.Potential(type='disk', scaleheight=0.1)
rmax = 2.0
E    = pot.potential(rmax,0,0)
Lzmax= 2*numpy.pi * pot.Rcirc(E=E)**2 / pot.Tcirc(E)
Lz   = 0.1 * Lzmax

def init_axes(arg=None):
    axorb.cla()
    axpss.cla()
    axorb.set_xlim(0 if Lz&gt;0 else -rmax, rmax)
    axorb.set_aspect('equal')
    axpss.set_xlim(axorb.get_xlim())
    axorb.set_xlabel('$x$', fontsize=12)
    axorb.set_ylabel('$z$', fontsize=12)
    axpss.set_xlabel('$x$', fontsize=12)
    axpss.set_ylabel('$p_x$', fontsize=12)
    # plot boundaries of orbit plane and surface of section
    Rp,Ra= pot.Rperiapo(E, Lz)
    xmin = -Ra if Lz==0 else Rp
    xmax = Ra
    grid = numpy.linspace(0, 1, 100)
    grid = grid * grid * (3-2*grid) * (xmax-xmin) + xmin
    vval = numpy.maximum(0, 2*E - 2*pot.potential(numpy.column_stack((grid,grid*0,grid*0))) - (Lz/grid)**2)**0.5
    zval = numpy.hstack([0,
        numpy.array([ scipy.optimize.brentq(lambda z: pot.potential(xx,0,z) - E + 0.5*(Lz/xx)**2, 0, xmax) for xx in grid[1:-1]]),
        0])
    axorb.plot(numpy.hstack((grid[:-1], grid[::-1])), numpy.hstack((zval[:-1], -zval[::-1])), color='k', lw=0.5)
    axpss.plot(numpy.hstack((grid[:-1], grid[::-1])), numpy.hstack((vval[:-1], -vval[::-1])), color='k', lw=0.5)
    axorb.text(0.5, 1.01, 'orbit plane',        ha='center', va='bottom', transform=axorb.transAxes, fontsize=10)
    axpss.text(0.5, 1.01, 'surface of section', ha='center', va='bottom', transform=axpss.transAxes, fontsize=10)
    plt.draw()

def run_orbit(ic):
    color = numpy.random.random(size=3)*0.8
    # create an orbit represented by a spline interpolator
    orbit = agama.orbit(ic=ic, potential=pot, time=100*pot.Tcirc(ic), dtype=object)
    # get all crossing points with z=0
    timecross = orbit.z.roots()
    # select those at which vz&gt;=0
    timecross = timecross[orbit.z(timecross, der=1) &gt;= 0]
    # get recorded trajectory sampled at every timestep...
    traj = orbit(orbit)
    # ...and at all crossing times
    trajcross = orbit(timecross)
    if Lz==0:
        axorb.plot(traj[:,0], traj[:,2], color=color, lw=0.5, alpha=0.5)
        axpss.plot(trajcross[:,0], trajcross[:,3], 'o', color=color, mew=0, ms=1.5)
    else:
        # orbit in the R,z plane, and SoS in the R, v_R plane
        axorb.plot((traj[:,0]**2 + traj[:,1]**2)**0.5, traj[:,2], color=color, lw=0.5, alpha=0.5)
        R = (trajcross[:,0]**2 + trajcross[:,1]**2)**0.5
        vR= (trajcross[:,0]*trajcross[:,3] + trajcross[:,1]*trajcross[:,4]) / R
        axpss.plot(R, vR, 'o', color=color, mew=0, ms=1.5)

def add_point(event):
    if event.inaxes is not axpss or event.button != 3: return
    x, vx = event.xdata, event.ydata
    vz2 = 2 * (E - pot.potential(x,0,0)) - (Lz/x)**2 - vx**2
    if vz2&gt;0:
        run_orbit([x, 0, 0, vx, Lz/x, vz2**0.5])
        plt.draw()

fig   = plt.figure(figsize=(6,3), dpi=200)
axorb = plt.axes([0.08,0.14,0.4,0.8])
axpss = plt.axes([0.58,0.14,0.4,0.8])
button_clear = matplotlib.widgets.Button(plt.axes([0.90,0.88,0.08,0.06]), 'clear')
fig.canvas.mpl_connect('button_press_event', add_point)
button_clear.on_clicked(init_axes)
init_axes()
print('Right-click on the Surface of Section to start an orbit')
plt.show()
</file>
    <file path="py/example_schwarzschild_flattened_rotating.py">
#!/usr/bin/python
&quot;&quot;&quot;
This example illustrates the use of Schwarzschild method to construct a flattened rotating system.
The density profile follows the Sersic law with axis ratio z/x=0.6,
and there is a central black hole of mass 0.1 (the total stellar mass is 1).
The script constructs the orbit library, assigns the weights to the orbits,
then generates an N-body model representing the system (except the central black hole),
and plots various diagnostic information:
1) distribution of orbit weights as a function of mean radius and eccentricity of orbits --
one can check that there are no orbits with extremely high weight (this usually indicates
that the size of the orbit library needs to be increased),
2) kinematic profiles - mean rotation velocity and three components of velocity dispersion tensor
as functions of radius. Currently there is no way to constrain kinematics explicitly at the stage
of the optimization problem (solution for the orbit weights), but one can adjust it implicitly
by modifying the parameters of the initial condition generator - here we use the axisymmetric
anisotropic Jeans equations, and the two parameters (anisotropy and rotation fraction) can be tuned.
&quot;&quot;&quot;
import agama, numpy

# stellar potential
potstars = agama.Potential(type='Sersic', sersicIndex=4, axisRatioZ=0.6, scaleRadius=1, mass=1)

# central black hole (slightly softened)
potbh = agama.Potential(type='Plummer', scaleRadius=1e-4, mass=0.1)

# total potential
pot = agama.Potential(potstars, potbh)

# discretized density profile is recorded on a grid of radial points and spherical harmonics up to lmax
gridr = agama.nonuniformGrid(50, 0.02, 20.0)   # !! make sure that the grid covers the range of interest !!
target = agama.Target(type='DensitySphHarm', gridr=gridr, lmax=8, mmax=0)

# discretized density profile to be used as the density constraint
rhs = target(potstars)
#print(&quot;Density constraint values&quot;)
#for i in range(len(gridr)): print(&quot;%s: mass= %g&quot; % (target[i], rhs[i]))

# construct initial conditions for the orbit library:
# use the anisotropic Jeans eqs to set the (approximate) shape of the velocity ellipsoid and the mean v_phi;
beta  = 0.0   # velocity anisotropy in R/z plane: &gt;0 - sigma_R&gt;sigma_z, &lt;0 - reverse.
kappa = 0.8   # sets the amount of rotation v_phi vs. dispersion sigma_phi; 1 is rather fast rotation, 0 - no rot.
initcond,_ = potstars.sample(10000, potential=pot, beta=beta, kappa=kappa)

# integration time is 100 orbital periods
inttimes = 100*pot.Tcirc(initcond)

# integrate all orbits, storing the recorded density data and trajectories represented by interpolator objects
data, trajs = agama.orbit(potential=pot, ic=initcond, time=inttimes, dtype=object, targets=target)

# assemble the matrix equation which contains two blocks:
# total mass, discretized density

# a single value for the total mass constraint, each orbit contributes 1 to it
mass = potstars.totalMass()
data0= numpy.ones((len(initcond), 1))

# solve the matrix equation for orbit weights
weights = agama.solveOpt(matrix=(data0.T, data.T), rhs=([mass], rhs),
    rpenl=([numpy.inf], numpy.ones(len(rhs))*numpy.inf),
    xpenq=numpy.ones(len(initcond)) )

#numpy.savetxt('orbits', numpy.column_stack((initcond, weights, inttimes))[numpy.argsort(inttimes)], '%g')

# export an N-body model
nbody=100000
status,result = agama.sampleOrbitLibrary(nbody, trajs, weights)
if not status:
    # this may occur if there was not enough recorded trajectory points for some high-weight orbits:
    # in this case their indices and the required numbers of points are returned in the result tuple.
    # This cannot happen if orbits are represented by interpolator objects rather than pre-recorded arrays.
    indices,trajsizes = result
    print(&quot;reintegrating %i orbits; max # of sampling points is %i&quot; % (len(indices), max(trajsizes)))
    trajs[indices] = agama.orbit(potential=pot, ic=initcond[indices], time=inttimes[indices], \
        trajsize=trajsizes)
    status,result = agama.sampleOrbitLibrary(nbody,trajs[:,1],weights)
    if not status: print(&quot;Failed to produce output N-body model&quot;)
agama.writeSnapshot(&quot;flattened_rotating_model.nemo&quot;, result,'n')


# various diagnostic plots
import matplotlib.pyplot as plt
ax=plt.subplots(1,2,figsize=(12,6))[1]

# plot orbit weights as a function of mean radius and eccentricity (shown in color)
rperi, rapo = pot.Rperiapo(initcond).T
ravg = (rapo+rperi)/2
ecc  = (rapo-rperi)/(rapo+rperi)
meanw= numpy.median(weights)
plt.colorbar(
    ax[0].scatter(ravg, weights, c=ecc, s=20*numpy.log(1+weights/meanw),
    marker='.', linewidths=0, cmap='mist', vmin=0, vmax=1),
    ax=ax[0], orientation='vertical', label='eccentricity')
ax[0].set_xscale('log')
ax[0].set_yscale('log')
ax[0].set_ylim(meanw*0.1, numpy.amax(weights)*1.2)
ax[0].set_xlim(min(ravg)*0.8, max(ravg)*1.2)
ax[0].set_xlabel('mean radius')
ax[0].set_ylabel('orbit weight')

# plot particle kinematics
xv = result[0]
R  = (xv[:,0]**2+xv[:,1]**2)**0.5
vR = (xv[:,0]*xv[:,3]+xv[:,1]*xv[:,4]) / R
vt = (xv[:,0]*xv[:,4]-xv[:,1]*xv[:,3]) / R
vz =  xv[:,5]
Rmin, Rmax = numpy.percentile(R, [1, 99])
gridR  = numpy.logspace(numpy.log10(Rmin), numpy.log10(Rmax), 25)
centrR = (gridR[1:]*gridR[:-1])**0.5
norm   = numpy.histogram(R, bins=gridR)[0]
meanvt = numpy.histogram(R, bins=gridR, weights=vt)[0] / norm
sigmaR =(numpy.histogram(R, bins=gridR, weights=vR**2)[0] / norm)**0.5
sigmat =(numpy.histogram(R, bins=gridR, weights=vt**2)[0] / norm - meanvt**2)**0.5
sigmaz =(numpy.histogram(R, bins=gridR, weights=vz**2)[0] / norm)**0.5
ax[1].plot(centrR, sigmaR, label='sigma_R')
ax[1].plot(centrR, sigmat, label='sigma_phi')
ax[1].plot(centrR, sigmaz, label='sigma_z')
ax[1].plot(centrR, meanvt, label='v_phi', dashes=[3,2])
ax[1].set_xscale('log')
ax[1].set_xlim(min(gridR), max(gridR))
ax[1].set_xlabel('radius')
ax[1].set_ylabel('velocity mean/dispersion')
ax[1].legend(loc='upper right', frameon=False)
plt.tight_layout()
plt.show()
</file>
    <file path="py/example_schwarzschild_triaxial.py">
#!/usr/bin/python
&quot;&quot;&quot;
This example illustrates the use of Schwarzschild method to construct a triaxial Dehnen model.
&quot;&quot;&quot;
import agama, numpy

# Hernquist density profile
den = agama.Density(type='Spheroid', axisRatioY=0.8, axisRatioZ=0.6, scaleRadius=1, mass=1, gamma=1, beta=4)

# potential corresponding to this density
pot = agama.Potential(type='Multipole', lmax=8, mmax=6, density=den)

# target1 is discretized density profile
target1 = agama.Target(type='DensityClassicLinear', gridr=agama.nonuniformGrid(25, 0.1, 20.0), \
    axisratioy=0.8, axisratioz=0.6, stripsPerPane=2)

# target2 is discretized kinematic constraint (we will enforce velocity isotropy)
target2 = agama.Target(type='KinemShell', gridR=agama.nonuniformGrid(15, 0.2, 10.0), degree=1)

# construct initial conditions for the orbit library
initcond,weightprior = den.sample(5000, potential=pot)

# integration time is 50 orbital periods
inttimes = 50*pot.Tcirc(initcond)
# integrate all orbits, storing the recorded data corresponding to each target
# in the data1 and data2 arrays, and the trajectories - in trajs
# (by specifying dtype=object, orbits are represented by instances of agama.Orbit
# providing interpolated trajectories recorded at each timestep of the ODE integrator)
data1, data2, trajs = agama.orbit(potential=pot, ic=initcond, time=inttimes, \
    dtype=object, targets=[target1,target2])

# assemble the matrix equation which contains three blocks:
# total mass, discretized density, and velocity anisotropy

# a single value for the total mass constraint, each orbit contributes 1 to it
mass = den.totalMass()
data0= numpy.ones((len(initcond), 1))

# discretized density profile to be used as the density constraint
rhs1 = target1(den)

# data2 is kinematic data: for each orbit (row) it contains
# Ngrid values of rho sigma_r^2, then the same number of values of rho sigma_t^2;
# we combine them into a single array of Ngrid values that enforce isotropy (sigma_t^2 - 2 sigma_r^2 = 0)
Ngrid = len(target2) // 2
datak = 2*data2[:,:Ngrid] - data2[:,Ngrid:]
rhs2  = numpy.zeros(Ngrid)

# solve the matrix equation for orbit weights
weights = agama.solveOpt(matrix=(data0.T, data1.T, datak.T), rhs=([mass], rhs1, rhs2), \
    rpenl=([numpy.inf], numpy.ones_like(rhs1), numpy.ones_like(rhs2)), \
    xpenq=numpy.ones(len(initcond))*0.1 )

# check if all constraints were satisfied
delta1 = data1.T.dot(weights) - rhs1
for i,d in enumerate(delta1):
    if abs(d)&gt;1e-8:
        print(&quot;DensityConstraint %i not satisfied: %s, val=%.4g, rel.err=%.4g&quot; % \
        (i, target1[i], rhs1[i], d / rhs1[i]))
delta2 = datak.T.dot(weights)
for i,d in enumerate(delta2):
    if abs(d)&gt;1e-8:  print(&quot;KinemConstraint %i not satisfied: %.4g&quot; % (i, d))

# export an N-body model
nbody=100000
status,result = agama.sampleOrbitLibrary(nbody, trajs, weights)
if not status:
    # this may occur if there was not enough recorded trajectory points for some high-weight orbits:
    # in this case their indices and the required numbers of points are returned in the result tuple.
    # This cannot happen if orbits are represented by interpolator objects rather than pre-recorded arrays.
    indices,trajsizes = result
    print(&quot;reintegrating %i orbits; max # of sampling points is %i&quot; % (len(indices), max(trajsizes)))
    trajs[indices] = agama.orbit(potential=pot, ic=initcond[indices], time=inttimes[indices], \
        trajsize=trajsizes)
    status,result = agama.sampleOrbitLibrary(nbody, trajs, weights)
    if not status: print(&quot;Failed to produce output N-body model&quot;)
agama.writeSnapshot(&quot;schwarzschild_model_nbody.txt&quot;, result, 'text')   # one could also use numpy.savetxt

# also store the entire Schwarzschild model in a numpy binary archive
numpy.savez_compressed(&quot;schwarzschild_model_data&quot;, ic=initcond, inttime=inttimes, weight=weights, \
    data1=data1, data2=data2, cons1=rhs1)

# store the orbit initial conditions and weights in a text file
numpy.savetxt(&quot;schwarzschild_model_orbits&quot;, \
    numpy.column_stack((initcond, weights, weightprior, inttimes)), \
    header='x y z vx vy vz weight prior inttime')
</file>
    <file path="py/example_self_consistent_model_flattened.py">
#!/usr/bin/python
&quot;&quot;&quot;
Create a simple single-component flattened self-consistent model
determined by its distribution function in terms of actions.
We use the DoublePowerLaw DF approximately corresponding to the Sersic
model, with parameters found by the program example_doublepowerlaw.exe
(fitting the DF to a spherical Sersic profile with n=2) and then
adjusted manually to create some flattening and rotation.
&quot;&quot;&quot;
import agama, numpy, matplotlib.pyplot as plt

# the distribution function defining the model
dfparams = dict(
    type     = 'DoublePowerLaw',
    J0       = 1.0,
    slopeIn  = 1.5,
    slopeOut = 1.5,
    steepness= 1.0,
    coefJrIn = 1.0,
    coefJzIn = 1.5,
    coefJrOut= 1.0,
    coefJzOut= 1.6,
    Jcutoff  = 0.54,
    cutoffstrength=1.5,
    rotFrac  = 1.0,  # make a rotating model (just for fun)
    Jphi0    = 0.05, # size of non-(or weakly-)rotating core
    mass     = 1.0)

# compute the mass and rescale norm to get the total mass = 1
#dfparams['norm'] /= agama.DistributionFunction(**dfparams).totalMass()
df = agama.DistributionFunction(**dfparams)

# initial guess for the density profile
dens = agama.Density(type='sersic', mass=1, scaleRadius=0.65, sersicindex=2)

# define the self-consistent model consisting of a single component
gridparams = dict(rminSph=0.01, rmaxSph=10., sizeRadialSph=25, lmaxAngularSph=8)
comp = agama.Component(df=df, density=dens, disklike=False, **gridparams)
scm = agama.SelfConsistentModel(**gridparams)
scm.components=[comp]

# prepare visualization
r = numpy.logspace(-2.,1.)
xyz = numpy.vstack((r,r*0,r*0)).T
ax = plt.subplots(1, 3, figsize=(15,5))[1]
ax[0].plot(r, dens.density(xyz), label='Init density', color='lightgray', lw=3, dashes=[2,2])

# perform several iterations of self-consistent modelling procedure
for i in range(5):
    scm.iterate()
    print('Iteration %i, Phi(0)=%g, Mass=%g' %
        (i, scm.potential.potential(0,0,0), scm.potential.totalMass()))
    # for a fair comparison, show the spherically-averaged density profile
    sphDensity = agama.Density(type='DensitySphericalHarmonic', density=comp.density, lmax=0)
    ax[0].plot(r, sphDensity.density(xyz), label='Iteration #'+str(i))

ax[0].legend(loc='lower left', frameon=False)
ax[0].set_xlabel('r')
ax[0].set_ylabel(r'$\rho$')
ax[0].set_xscale('log')
ax[0].set_yscale('log')
ax[0].set_ylim(1e-5, 2e2)
ax[0].set_xlim(min(r), max(r))

# save the final density/potential profile and create an N-body snapshot
print('Creating N-body model')
comp.density.export('flattened_sersic_density.ini')
scm.potential.export('flattened_sersic_potential.ini')
gm = agama.GalaxyModel(scm.potential, df)
xv, m = gm.sample(1000000)
agama.writeSnapshot('flattened_sersic_nbody.nemo', (xv, m), 'nemo')

# show the axis ratio
print('Determining shape')
r = numpy.logspace(-2, 1, 16)
xyz = numpy.column_stack((r, r*0, r*0))
axes = comp.density.principalAxes(r)[0]
ax[1].plot(r, axes[:,2]/axes[:,0])
ax[1].set_xlabel('r')
ax[1].set_ylabel(r'$z/R$')
ax[1].set_xscale('log')
ax[1].set_ylim(0, 1)
ax[1].set_xlim(min(r), max(r))

print('Computing kinematic profiles')
rho, meanv, vel2 = gm.moments(xyz, dens=True, vel=True, vel2=True)
vcirc = (-r * scm.potential.force(xyz)[:,0])**0.5
ax[2].plot(r, vcirc, label=r'$v_{\sf circ}$')
ax[2].plot(r, meanv[:,1], label=r'$\overline{v_\phi}$')
ax[2].plot(r,  vel2[:,0]**0.5, label=r'$\sigma_R$')
ax[2].plot(r, (vel2[:,1]-meanv[:,1]**2)**0.5, label=r'$\sigma_\phi$')
ax[2].plot(r,  vel2[:,2]**0.5, label=r'$\sigma_z$')
ax[2].set_xlabel('r')
ax[2].set_ylabel('velocity')
ax[2].set_xscale('log')
ax[2].set_xlim(min(r), max(r))
ax[2].legend(loc='upper left', frameon=False)

plt.tight_layout()
plt.show()
</file>
    <file path="py/example_self_consistent_model_mw.py">
#!/usr/bin/python
&quot;&quot;&quot;
This example demonstrates the machinery for constructing multicomponent self-consistent models
specified by distribution functions (DFs) in terms of actions.
We create a Milky Way model with four disk, bulge, stellar and dark halo components
defined by their DFs, and a static density profile of gas disk.
The thin disk is split into 3 age groups, and there is a separate thick disk.
Then we perform several iterations of recomputing the density profiles of components from
their DFs and recomputing the total potential.
Finally, we create N-body representations of all mass components:
dark matter halo, stars (bulge, several disks and stellar halo combined), and gas disk,
and compute various diagnostic quantities written into text files.
The DFs for the disky and spheroidal components used here differ from the built-in DF types, and
are defined in the first part of the file; their parameters are contained in a separate INI file.
The DF parameters are optimized to fit Gaia DR2 data, as described in Binney&amp;Vasiliev 2023.
These new DFs are implemented as Python functions, and for this reason the script is less
computationally efficient than the pure C++ equivalent program example_self_consistent_model_mw.cpp;
there are several reasons for this:
(a) Overheads from transferring the control between the C++ computational core and the Python
callback functions. This is partly mitigated by the fact that these functions are called
in a vectorized way, with several input points at once (~few dozen for the main part of the script,
where the integrals of DFs over velocity space are carried out, and much more for the last part,
where the DFs are sampled into an N-body snapshot).
(b) The mathematical computations are slower in Python, although again this is mostly mitigated
by performing them in a vectorized way on NumPy arrays with many elements at once.
(c) The computation of density from DF is OpenMP-parallelized in the C++ core, but because of GIL,
the user-defined functions can be entered only from one thread at a time. Most of the computational
time is spent on calculating the actions, which happens inside the C++ core and is fully parallelized,
and the evaluation of DF is usually sub-dominant, but may become a bottleneck when too many threads
are used; for this reason, we limit their number to 4. A special free-threading version of Python
(starting from 3.13) does not have GIL and benefits from OpenMP parallelization in principle, 
but not necessarily in practice.
In addition, the results (potential, density, velocity profiles) of the C++ and Python programs
slightly differ due to unavoidable differences in floating-point operations implemented in two
languages, which are greatly amplified in the course of iterations (but stay at the level 10^-3).
&quot;&quot;&quot;
import agama, numpy, sys, os, time, warnings
try:
    from ConfigParser import RawConfigParser  # python 2
except ImportError:
    from configparser import RawConfigParser  # python 3

# user-defined modifications of spheroidal (DoublePowerLaw) and disky (Exponential) DFs
def createNewDoublePowerLawDF(**params):
    def df(J):
        modJphi = abs(J[:,2])
        L = J[:,1] + modJphi
        c = L / (L + J[:,0])
        jt = (1.5 * J[:,0] + L) / L0
        jta = jt**alpha
        xi = jta / (1+jta)
        rat = (1-xi) * Fin + xi * Fout
        a = 0.5 * (rat+1)
        b = 0.5 * (rat-1)
        cL = numpy.where(L&gt;0, J[:,1] * (a + b * modJphi / L) + modJphi, 0)
        fac = numpy.exp(beta * numpy.sin(numpy.pi/2 * c))
        hJ = J[:,0] / fac + 0.5 * (1 + c * xi) * fac * cL
        gJ = hJ
        result = norm / (2*numpy.pi * J0)**3 * (1 + J0/hJ)**slopeIn * (1 + gJ/J0)**(-slopeOut)
        if Jcutoff &gt; 0:
            result *= numpy.exp(-(gJ / Jcutoff)**cutoffStrength)
        if Jcore &gt; 0:
            result *= (1 + Jcore/hJ * (Jcore/hJ - zeta))**(-0.5*slopeIn)
        if rotFrac != 0:
            result *= 1 + rotFrac * numpy.tanh(J[:,2] / Jphi0)
        return result
    J0, L0, slopeIn, slopeOut, rotFrac, Jphi0, alpha, beta, Fin, Fout, Jcutoff, cutoffStrength, Jcore = (
        float(params[name]) for name in 
        ('J0', 'L0', 'slopeIn', 'slopeOut', 'rotFrac', 'Jphi0', 'alpha', 'beta',
        'Fin', 'Fout', 'Jcutoff', 'cutoffStrength', 'Jcore'))
    if Jcore &gt; 0:
        import scipy.optimize, scipy.integrate
        def rootFnc(zeta):
            def integrand(t):
                hJ = Jcore * t*t*(3-2*t) / (1-t)**2 / (1+2*t)
                dhJdt = Jcore * 6*t / (1-t)**3 / (1+2*t)**2
                return (hJ**2 * dhJdt * (1 + J0/hJ)**slopeIn * (1+hJ/J0)**(-slopeOut) *
                    ((1 + Jcore/hJ * (Jcore/hJ-zeta))**(-0.5*slopeIn) - 1))
            return scipy.integrate.fixed_quad(integrand, 0.0, 1.0, n=20)[0]
        zeta = scipy.optimize.brentq(rootFnc, 0.0, 2.0)
    norm = 1.0
    norm = float(params['mass']) / agama.DistributionFunction(df).totalMass()
    print(&quot;Created a %s DF with mass %s&quot; % (params['type'], params['mass']))
    return df

def createNewExponentialDF(**params):
    def df(J):
        Jp = numpy.maximum(0, J[:,2])
        Jvel = Jp + addJvel
        Jden = Jp + addJden
        xr = (Jvel / Jphi0)**pr / Jr0
        xz = (Jvel / Jphi0)**pz / Jz0
        fr = xr * numpy.exp(-xr * J[:,0])
        fz = xz * numpy.exp(-xz * J[:,1])
        fp = norm / Jphi0**2 * abs(J[:,2]) * numpy.exp(-Jden / Jphi0)
        return numpy.where(J[:,2] &gt; 0, fr * fz * fp, 0)
    Jr0, Jz0, Jphi0, pr, pz, addJden, addJvel = (float(params[name]) for name in
    ('Jr0', 'Jz0', 'Jphi0', 'pr', 'pz', 'addJden', 'addJvel'))
    norm = 1.0
    norm = float(params['mass']) / agama.DistributionFunction(df).totalMass()
    print(&quot;Created a %s DF with mass %s&quot; % (params['type'], params['mass']))
    return df

# common header for output files, listing the DF components in order of adding them to the total DF
header= &quot;bulge\tthin,young\tthin,middle\tthin,old\tthick\tstellarhalo&quot;

# print velocity dispersion, in-plane and surface density profiles of each stellar component to a file
def writeRadialProfile(model):
    print(&quot;Writing radial density and velocity profiles&quot;)
    radii = numpy.hstack(([1./8, 1./4], numpy.linspace(0.5, 16, 32), numpy.linspace(18, 30, 7)))
    xy    = numpy.column_stack((radii, radii*0))
    xyz   = numpy.column_stack((radii, radii*0, radii*0))
    # in-plane density and velocity moments, separately for each DF component
    z0dens, meanv, meanv2 = model.moments(xyz, dens=True, vel=True, vel2=True, separate=True)
    # projected density for each DF component
    Sigma = model.moments(xy, dens=True, vel=False, vel2=False, separate=True)
    numpy.savetxt(&quot;mwmodel_surface_density.txt&quot;, numpy.column_stack((radii, Sigma * 1e-6)),
        fmt=&quot;%.6g&quot;, delimiter=&quot;\t&quot;, header=&quot;radius\t&quot;+header+&quot;[Msun/pc^2]&quot;)
    numpy.savetxt(&quot;mwmodel_volume_density.txt&quot;, numpy.column_stack((radii, z0dens * 1e-9)),
        fmt=&quot;%.6g&quot;, delimiter=&quot;\t&quot;, header=&quot;radius\t&quot;+header+&quot;[Msun/pc^3]&quot;)
    numpy.savetxt(&quot;mwmodel_sigmaR.txt&quot;, numpy.column_stack((radii, meanv2[:,:,0]**0.5)),
        fmt=&quot;%.6g&quot;, delimiter=&quot;\t&quot;, header=&quot;radius\t&quot;+header+&quot;[km/s]&quot;)
    numpy.savetxt(&quot;mwmodel_sigmaz.txt&quot;, numpy.column_stack((radii, meanv2[:,:,2]**0.5)),
        fmt=&quot;%.6g&quot;, delimiter=&quot;\t&quot;, header=&quot;radius\t&quot;+header+&quot;[km/s]&quot;)
    numpy.savetxt(&quot;mwmodel_sigmaphi.txt&quot;, numpy.column_stack((radii, (meanv2[:,:,1]-meanv[:,:,1]**2)**0.5)),
        fmt=&quot;%.6g&quot;, delimiter=&quot;\t&quot;, header=&quot;radius\t&quot;+header+&quot;[km/s]&quot;)
    numpy.savetxt(&quot;mwmodel_meanvphi.txt&quot;, numpy.column_stack((radii, meanv[:,:,1])),
        fmt=&quot;%.6g&quot;, delimiter=&quot;\t&quot;, header=&quot;radius\t&quot;+header+&quot;[km/s]&quot;)

# print vertical density profile for several sub-components of the stellar DF
def writeVerticalDensityProfile(model):
    print(&quot;Writing vertical density profile&quot;)
    height = numpy.hstack((numpy.linspace(0, 0.5, 11), numpy.linspace(0.75, 5.0, 18)))
    xyz   = numpy.column_stack((height*0 + solarRadius, height*0, height))
    dens  = model.moments(xyz, dens=True, vel=False, vel2=False, separate=True) * 1e-9
    numpy.savetxt(&quot;mwmodel_vertical_density.txt&quot;, numpy.column_stack((height, dens)),
        fmt=&quot;%.6g&quot;, delimiter=&quot;\t&quot;, header=&quot;radius\t&quot;+header+&quot;[Msun/pc^3]&quot;)

# print velocity distributions at the given point to a file
def writeVelocityDistributions(model):
    points = [[solarRadius-2, 0, 0], [solarRadius, 0, 0], [solarRadius+2, 0, 0], [solarRadius, 0, 2]]
    print(&quot;Writing velocity distributions&quot;)
    # create grids in velocity space for computing the spline representation of VDF
    v_max = 400.0    # km/s
    gridv = agama.symmetricGrid(75, 6.0, v_max)
    # compute the distributions (represented as cubic splines)
    result = model.vdf(points, gridv=gridv, separate=True, dens=True)  # three sets of VDFs and density
    rho = result[-1]
    # output f(v) at a different grid of velocity values
    gridv = numpy.linspace(-v_max, v_max, int(v_max+1))
    for ip,point in enumerate(points):
        for iv in range(3):
            numpy.savetxt(&quot;mwmodel_vdf_R%g_z%g_v%s.txt&quot; % (point[0], point[2], [&quot;R&quot;,&quot;phi&quot;,&quot;z&quot;][iv]),
                numpy.column_stack([gridv] +
                [rho[ip][ic] * result[iv][ip][ic](gridv) * 1e-9 for ic in range(len(result[iv][ip]))]),
                fmt=&quot;%.6g&quot;, delimiter=&quot;\t&quot;, header=&quot;v\t&quot;+header+&quot;[Msun/pc^3/(km/s)]&quot;)

# display some information after each iteration
def printoutInfo(model):
    compStars = model.components[0].density
    compDark  = model.components[1].density
    pt0 = (solarRadius, 0, 0)
    pt1 = (solarRadius, 0, 1)
    print(&quot;Disk total mass=%g Msun, rho(Rsolar,z=0)=%g, rho(Rsolar,z=1kpc)=%g Msun/pc^3&quot; % \
        (compStars.totalMass(), compStars.density(pt0)*1e-9, compStars.density(pt1)*1e-9))
    print(&quot;Halo total mass=%g Msun, rho(Rsolar,z=0)=%g, rho(Rsolar,z=1kpc)=%g Msun/pc^3&quot; % \
        (compDark .totalMass(), compDark .density(pt0)*1e-9, compDark .density(pt1)*1e-9))
    print(&quot;Potential at origin=-(%g km/s)^2, total mass=%g Msun&quot; % \
        ((-model.potential.potential(0,0,0))**0.5, model.potential.totalMass()))
    compStars.export(&quot;mwmodel_density_stars.ini&quot;)
    compDark .export(&quot;mwmodel_density_dark.ini&quot;)
    model.potential.export(&quot;mwmodel_potential.ini&quot;)
    # write out the rotation curve (separately for each component, and the total one)
    radii = numpy.logspace(-2., 2., 81)
    xyz   = numpy.column_stack((radii, radii*0, radii*0))
    vcomp = numpy.column_stack([(-pot.force(xyz)[:,0] * radii)**0.5 for pot in model.potential])
    vtot  = numpy.sum(vcomp**2, axis=1)**0.5
    numpy.savetxt(&quot;mwmodel_rotcurve.txt&quot;,
        numpy.column_stack((radii, vtot, vcomp)), fmt=&quot;%.6g&quot;, delimiter=&quot;\t&quot;,
        header=&quot;radius[Kpc]\tv_circ,total[km/s]\tdarkmatter\tstars+gas&quot;)


if __name__ == &quot;__main__&quot;:
    # read parameters from the INI file
    iniFileName = os.path.dirname(os.path.realpath(sys.argv[0])) + &quot;/../data/SCM_MW.ini&quot;
    ini = RawConfigParser()
    ini.optionxform=str  # do not convert key to lowercase
    ini.read(iniFileName)
    iniPotenGasDisk  = dict(ini.items(&quot;Potential gas disk&quot;))
    iniDFyoungDisk   = dict(ini.items(&quot;DF young disk&quot;))
    iniDFmiddleDisk  = dict(ini.items(&quot;DF middle disk&quot;))
    iniDFoldDisk     = dict(ini.items(&quot;DF old disk&quot;))
    iniDFhighADisk   = dict(ini.items(&quot;DF highA disk&quot;))
    iniDFStellarHalo = dict(ini.items(&quot;DF stellar halo&quot;))
    iniDFDarkHalo    = dict(ini.items(&quot;DF dark halo&quot;))
    iniDFBulge       = dict(ini.items(&quot;DF bulge&quot;))
    iniSCMDisk       = dict(ini.items(&quot;SelfConsistentModel disk&quot;))
    iniSCMHalo       = dict(ini.items(&quot;SelfConsistentModel halo&quot;))
    iniSCM           = dict(ini.items(&quot;SelfConsistentModel&quot;))
    solarRadius      = ini.getfloat(&quot;Data&quot;, &quot;SolarRadius&quot;)

    # define external unit system describing the data (including the parameters in INI file)
    agama.setUnits(length=1, velocity=1, mass=1)   # in Kpc, km/s, Msun

    # initialize the SelfConsistentModel object (only the potential expansion parameters)
    model = agama.SelfConsistentModel(**iniSCM)

    # create the initial potential from all sections of the INI file starting with &quot;[Potential...&quot;
    model.potential = agama.Potential(iniFileName)

    print(&quot;\033[1;37mInitializing\033[0m&quot;)
    warnings.filterwarnings(&quot;ignore&quot;, category=RuntimeWarning)  # suppress division by zero warning
    time0 = time.time()
    # the initialization is costly because of computing the DF normalization (integral over all J);
    # the equivalent operation with C++-native DF types is almost instantaneous
    dfDarkHalo    = createNewDoublePowerLawDF(**iniDFDarkHalo)
    dfBulge       = createNewDoublePowerLawDF(**iniDFBulge)
    dfYoungDisk   = createNewExponentialDF(**iniDFyoungDisk)
    dfMiddleDisk  = createNewExponentialDF(**iniDFmiddleDisk)
    dfOldDisk     = createNewExponentialDF(**iniDFoldDisk)
    dfHighADisk   = createNewExponentialDF(**iniDFhighADisk)
    dfStellarHalo = createNewDoublePowerLawDF(**iniDFStellarHalo)
    # composite DF of all stellar components
    dfStellar     = agama.DistributionFunction(
        dfBulge, dfYoungDisk, dfMiddleDisk, dfOldDisk, dfHighADisk, dfStellarHalo)
    time1 = time.time()
    print(&quot;%g seconds to initialize DFs&quot; % (time1-time0))

    # replace the disk, halo and bulge SCM components with the DF-based ones
    model.components = [
        agama.Component(df=dfStellar,  disklike=True,  **iniSCMDisk),
        agama.Component(df=dfDarkHalo, disklike=False, **iniSCMHalo),
        agama.Component(density=agama.Density(**iniPotenGasDisk), disklike=True)
    ]

    # Limit the number of OpenMP threads to at most 4, because the user-defined DF functions prevent
    # effective parallelization due to Python GIL (although the action computation is still parallelized,
    # so the overall procedure benefits from having a few, but not too many, threads).
    # This is not necessary for free-threading Python 3.13+, which has no GIL.
    numThreads = (0  if hasattr(sys, &quot;_is_gil_enabled&quot;) and not sys._is_gil_enabled()
        else min(agama.setNumThreads(0).prevNumThreads, 4))
    with agama.setNumThreads(numThreads):
        # do a few iterations to obtain the self-consistent density profile for the entire system
        for iteration in range(1,5):
            print(&quot;\033[1;37mStarting iteration #%d\033[0m&quot; % iteration)
            model.iterate()
            printoutInfo(model)
    time2 = time.time()
    print(&quot;%g seconds to build the model&quot; % (time2-time1))

    # output various profiles (only for stellar components)
    print(&quot;\033[1;37mComputing diagnostics\033[0m&quot;)
    modelStars = agama.GalaxyModel(model.potential, dfStellar, model.af)
    # again limit the number of OpenMP threads to avoid congestion
    with agama.setNumThreads(numThreads):
        writeRadialProfile(modelStars)
        writeVerticalDensityProfile(modelStars)
        writeVelocityDistributions(modelStars)
    time3 = time.time()
    print(&quot;%g seconds to compute diagnostics&quot; % (time3-time2))

    # export model to an N-body snapshot;
    # here we do not need to limit the number of threads, since the sampling procedure
    # is much more vectorized than integration (which is at the heart of all previous steps),
    # and the overhead of calling the user-defined Python function is relatively lower.
    print(&quot;\033[1;37mCreating an N-body representation of the model\033[0m&quot;)
    format = &quot;nemo&quot;  # could use 'text', 'nemo' or 'gadget' here
    agama.writeSnapshot(&quot;mwmodel_dm_final.nbody&quot;,
        agama.GalaxyModel(potential=model.potential, df=dfDarkHalo, af=model.af).sample(750000),
        format)
    agama.writeSnapshot(&quot;model_stars_final.nbody&quot;,
        modelStars.sample(200000),
        format)
    # we didn't use an action-based DF for the gas disk, leaving it as a static component;
    # to create an N-body representation, we sample the density profile and assign velocities
    # from the axisymmetric Jeans equation with equal velocity dispersions in R,z,phi
    agama.writeSnapshot(&quot;model_gas_final.nbody&quot;,
        model.components[2].density.sample(50000, potential=model.potential, beta=0, kappa=1),
        format)
    print(&quot;%g seconds to create an N-body snapshot&quot; % (time.time()-time3))
</file>
    <file path="py/example_self_consistent_model_simple.py">
#!/usr/bin/python

&quot;&quot;&quot;
Create a simple single-component spherical self-consistent model
determined by its distribution function in terms of actions.
We use the true DF of the Plummer model, expressed in terms of actions,
and start iterations from a deliberately wrong initial guess;
nevertheless, after 10 iterations we converge to the true solution within 1%;
each iteration approximately halves the error.
&quot;&quot;&quot;
import agama, numpy, matplotlib.pyplot as plt

# the distribution function defining the model
truepot = agama.Potential(type='Plummer')
df = agama.DistributionFunction(type='QuasiSpherical', potential=truepot, density=truepot)

# initial guess for the density profile - deliberately a wrong one
dens = agama.Density(type='Dehnen', mass=0.1, scaleRadius=0.5)

# define the self-consistent model consisting of a single component
params = dict(rminSph=0.001, rmaxSph=1000., sizeRadialSph=40, lmaxAngularSph=0)
comp = agama.Component(df=df, density=dens, disklike=False, **params)
scm = agama.SelfConsistentModel(**params)
scm.components=[comp]

# prepare visualization
r=numpy.logspace(-2.,2.)
xyz=numpy.vstack((r,r*0,r*0)).T
plt.plot(r, dens.density(xyz), label='Init density')
plt.plot(r, truepot.density(xyz), label='True density', c='k')[0].set_dashes([4,4])

# perform several iterations of self-consistent modelling procedure
for i in range(10):
    scm.iterate()
    print('Iteration %i, Phi(0)=%g, Mass=%g' % \
        (i, scm.potential.potential(0,0,0), scm.potential.totalMass()))
    plt.plot(r, scm.potential.density(xyz), label='Iteration #'+str(i))

# save the final density/potential profile
scm.potential.export(&quot;simple_scm.ini&quot;)

# show the results
plt.legend(loc='lower left')
plt.xlabel(&quot;r&quot;)
plt.ylabel(r'$\rho$')
plt.xscale('log')
plt.yscale('log')
plt.ylim(1e-5, 1)
plt.xlim(0.02, 20)
plt.show()
</file>
    <file path="py/example_self_consistent_model.py">
#!/usr/bin/python
&quot;&quot;&quot;
This example demonstrates the machinery for constructing multicomponent self-consistent models
specified by distribution functions (DFs) in terms of actions.
We create a four-component galaxy with disk, bulge and halo components defined by their DFs,
and a static density profile of gas disk.
Then we perform several iterations of recomputing the density profiles of components from their DFs
and recomputing the total potential.
Finally, we create N-body representations of all mass components: dark matter halo,
stars (bulge, thin and thick disks and stellar halo combined), and gas disk.
A modification of this script that creates a self-consistent three-component model
(disk, bulge and halo) is given in example_self_consistent_model3.py
This example is the Python counterpart of tests/example_self_consistent_model.cpp
&quot;&quot;&quot;
import agama, numpy, sys, os
try:
    from ConfigParser import RawConfigParser  # python 2
except ImportError:
    from configparser import RawConfigParser  # python 3

# write out the rotation curve (separately for each component, and the total one)
def writeRotationCurve(filename, potentials):
    radii = numpy.logspace(-2., 2., 81)
    xyz   = numpy.column_stack((radii, radii*0, radii*0))
    vcomp = numpy.column_stack([(-potential.force(xyz)[:,0] * radii)**0.5 for potential in potentials])
    vtot  = numpy.sum(vcomp**2, axis=1)**0.5
    numpy.savetxt(filename, numpy.column_stack((radii, vtot, vcomp)), fmt=&quot;%.6g&quot;, delimiter=&quot;\t&quot;, \
        header=&quot;radius[Kpc]\tv_circ,total[km/s]\tdisk\tbulge\thalo&quot;)

# print surface density profiles to a file
def writeSurfaceDensityProfile(filename, model):
    print(&quot;Writing surface density profile&quot;)
    radii = numpy.hstack(([1./8, 1./4], numpy.linspace(0.5, 16, 32), numpy.linspace(18, 30, 7)))
    xy    = numpy.column_stack((radii, radii*0))
    Sigma = model.moments(xy, dens=True, vel=False, vel2=False, separate=True) * 1e-6  # convert from Msun/Kpc^2 to Msun/pc^2
    numpy.savetxt(filename, numpy.column_stack((radii, Sigma)), fmt=&quot;%.6g&quot;, delimiter=&quot;\t&quot;, \
        header=&quot;Radius[Kpc]\tThinDisk\tThickDisk\tStellarHalo:SurfaceDensity[Msun/pc^2]&quot;)

# print vertical density profile for several sub-components of the stellar DF
def writeVerticalDensityProfile(filename, model):
    print(&quot;Writing vertical density profile&quot;)
    height = numpy.hstack((numpy.linspace(0, 1.5, 13), numpy.linspace(2, 8, 13)))
    xyz   = numpy.column_stack((height*0 + solarRadius, height*0, height))
    dens  = model.moments(xyz, dens=True, vel=False, vel2=False, separate=True) * 1e-9  # convert from Msun/Kpc^3 to Msun/pc^3
    numpy.savetxt(filename, numpy.column_stack((height, dens)), fmt=&quot;%.6g&quot;, delimiter=&quot;\t&quot;, \
        header=&quot;z[Kpc]\tThinDisk\tThickDisk\tStellarHalo:Density[Msun/pc^3]&quot;)

# print velocity dispersion profiles in the equatorial plane as functions of radius to a file
def writeVelocityDispersionProfile(filename, model):
    print(&quot;Writing velocity dispersion profile&quot;)
    radii = numpy.hstack(([1./8, 1./4], numpy.linspace(0.5, 16, 32), numpy.linspace(18, 30, 7)))
    xyz   = numpy.column_stack((radii, radii*0, radii*0))
    vel, vel2 = model.moments(xyz, dens=False, vel=True, vel2=True, separate=True)
    vel2[:,:,1] -= vel[:,:,1]**2
    numpy.savetxt(filename, numpy.column_stack((radii, numpy.dstack((vel2[:,:,0:3]**0.5, vel[:,:,1:2])).reshape(len(radii),-1))),
        fmt=&quot;%.6g&quot;, delimiter=&quot;\t&quot;, header=&quot;Radius[Kpc]\t&quot;
        &quot;ThinDisk:sigma_r\tsigma_phi\tsigma_z\tv_phi\t&quot;
        &quot;ThickDisk:sigma_r\tsigma_phi\tsigma_z\tv_phi\t&quot;
        &quot;StellarHalo:sigma_r\tsigma_phi\tsigma_z\tv_phi[km/s]&quot;)

# print velocity distributions at the given point to a file
def writeVelocityDistributions(filename, model):
    point = (solarRadius, 0, 0.1)
    print(&quot;Writing velocity distributions at (x=%g, z=%g)&quot; % (point[0], point[2]))
    # create grids in velocity space for computing the spline representation of VDF
    v_max = 360.0    # km/s
    gridv = numpy.linspace(-v_max, v_max, 75) # use the same grid for all dimensions
    # compute the distributions (represented as cubic splines)
    splvx, splvy, splvz = model.vdf(point, gridv=gridv)
    # output f(v) at a different grid of velocity values
    gridv = numpy.linspace(-v_max, v_max, 201)
    numpy.savetxt(filename, numpy.column_stack((gridv, splvx(gridv), splvy(gridv), splvz(gridv))),
        fmt=&quot;%.6g&quot;, delimiter=&quot;\t&quot;, header=&quot;V\tf(V_x)\tf(V_y)\tf(V_z) [1/(km/s)]&quot;)

# display some information after each iteration
def printoutInfo(model, iteration):
    densDisk = model.components[0].density
    densBulge= model.components[1].density
    densHalo = model.components[2].density
    pt0 = (solarRadius, 0, 0)
    pt1 = (solarRadius, 0, 1)
    print(&quot;Disk total mass=%g Msun, rho(Rsolar,z=0)=%g, rho(Rsolar,z=1kpc)=%g Msun/pc^3&quot; % \
        (densDisk.totalMass(), densDisk.density(pt0)*1e-9, densDisk.density(pt1)*1e-9))  # per pc^3, not kpc^3
    print(&quot;Halo total mass=%g Msun, rho(Rsolar,z=0)=%g, rho(Rsolar,z=1kpc)=%g Msun/pc^3&quot; % \
        (densHalo.totalMass(), densHalo.density(pt0)*1e-9, densHalo.density(pt1)*1e-9))
    print(&quot;Potential at origin=-(%g km/s)^2, total mass=%g Msun&quot; % \
        ((-model.potential.potential(0,0,0))**0.5, model.potential.totalMass()))
    densDisk.export (&quot;dens_disk_&quot; +iteration);
    densBulge.export(&quot;dens_bulge_&quot;+iteration);
    densHalo.export (&quot;dens_halo_&quot; +iteration);
    model.potential.export(&quot;potential_&quot;+iteration);
    writeRotationCurve(&quot;rotcurve_&quot;+iteration, (model.potential[1],  # disk potential (CylSpline)
        agama.Potential(type='Multipole', lmax=6, density=densBulge),        # -&quot;- bulge
        agama.Potential(type='Multipole', lmax=6, density=densHalo) ) )      # -&quot;- halo


if __name__ == &quot;__main__&quot;:
    # read parameters from the INI file
    iniFileName = os.path.dirname(os.path.realpath(sys.argv[0])) + &quot;/../data/SCM.ini&quot;
    ini = RawConfigParser()
    ini.optionxform=str  # do not convert key to lowercase
    ini.read(iniFileName)
    iniPotenThinDisk = dict(ini.items(&quot;Potential thin disk&quot;))
    iniPotenThickDisk= dict(ini.items(&quot;Potential thick disk&quot;))
    iniPotenGasDisk  = dict(ini.items(&quot;Potential gas disk&quot;))
    iniPotenBulge    = dict(ini.items(&quot;Potential bulge&quot;))
    iniPotenDarkHalo = dict(ini.items(&quot;Potential dark halo&quot;))
    iniDFThinDisk    = dict(ini.items(&quot;DF thin disk&quot;))
    iniDFThickDisk   = dict(ini.items(&quot;DF thick disk&quot;))
    iniDFStellarHalo = dict(ini.items(&quot;DF stellar halo&quot;))
    iniDFDarkHalo    = dict(ini.items(&quot;DF dark halo&quot;))
    iniDFBulge       = dict(ini.items(&quot;DF bulge&quot;))
    iniSCMHalo       = dict(ini.items(&quot;SelfConsistentModel halo&quot;))
    iniSCMBulge      = dict(ini.items(&quot;SelfConsistentModel bulge&quot;))
    iniSCMDisk       = dict(ini.items(&quot;SelfConsistentModel disk&quot;))
    iniSCM           = dict(ini.items(&quot;SelfConsistentModel&quot;))
    solarRadius      = ini.getfloat(&quot;Data&quot;, &quot;SolarRadius&quot;)

    # define external unit system describing the data (including the parameters in INI file)
    agama.setUnits(length=1, velocity=1, mass=1)   # in Kpc, km/s, Msun

    # initialize the SelfConsistentModel object (only the potential expansion parameters)
    model = agama.SelfConsistentModel(**iniSCM)

    # create initial ('guessed') density profiles of all components
    densityBulge       = agama.Density(**iniPotenBulge)
    densityDarkHalo    = agama.Density(**iniPotenDarkHalo)
    densityThinDisk    = agama.Density(**iniPotenThinDisk)
    densityThickDisk   = agama.Density(**iniPotenThickDisk)
    densityGasDisk     = agama.Density(**iniPotenGasDisk)
    densityStellarDisk = agama.Density(densityThinDisk, densityThickDisk)  # composite

    # add components to SCM - at first, all of them are static density profiles
    model.components.append(agama.Component(density=densityStellarDisk, disklike=True))
    model.components.append(agama.Component(density=densityBulge,       disklike=False))
    model.components.append(agama.Component(density=densityDarkHalo,    disklike=False))
    model.components.append(agama.Component(density=densityGasDisk,     disklike=True))

    # compute the initial potential
    model.iterate()
    printoutInfo(model, &quot;init&quot;)

    print(&quot;\033[1;33m**** STARTING MODELLING ****\033[0m\nInitial masses of density components: &quot; \
        &quot;Mdisk=%g Msun, Mbulge=%g Msun, Mhalo=%g Msun, Mgas=%g Msun&quot; % \
        (densityStellarDisk.totalMass(), densityBulge.totalMass(), \
        densityDarkHalo.totalMass(), densityGasDisk.totalMass()))

    # create the dark halo DF
    dfHalo        = agama.DistributionFunction(**iniDFDarkHalo)
    # same for the bulge
    dfBulge       = agama.DistributionFunction(**iniDFBulge)
    # same for the stellar components (thin/thick disks and stellar halo)
    dfThinDisk    = agama.DistributionFunction(potential=model.potential, **iniDFThinDisk)
    dfThickDisk   = agama.DistributionFunction(potential=model.potential, **iniDFThickDisk)
    dfStellarHalo = agama.DistributionFunction(**iniDFStellarHalo)
    # composite DF of all stellar components except the bulge
    dfStellar     = agama.DistributionFunction(dfThinDisk, dfThickDisk, dfStellarHalo)
    # composite DF of all stellar components including the bulge
    dfStellarAll  = agama.DistributionFunction(dfThinDisk, dfThickDisk, dfStellarHalo, dfBulge)

    # replace the disk, halo and bulge SCM components with the DF-based ones
    model.components[0] = agama.Component(df=dfStellar, disklike=True, **iniSCMDisk)
    model.components[1] = agama.Component(df=dfBulge, disklike=False, **iniSCMBulge)
    model.components[2] = agama.Component(df=dfHalo,  disklike=False, **iniSCMHalo)

    # we can compute the masses even though we don't know the density profile yet
    print(&quot;Masses of DF components: &quot; \
        &quot;Mdisk=%g Msun (Mthin=%g, Mthick=%g, Mstel.halo=%g); Mbulge=%g Msun; Mdarkhalo=%g Msun&quot; % \
        (dfStellar.totalMass(), dfThinDisk.totalMass(), dfThickDisk.totalMass(), \
        dfStellarHalo.totalMass(), dfBulge.totalMass(), dfHalo.totalMass()))

    # do a few more iterations to obtain the self-consistent density profile for the entire system
    for iteration in range(1,6):
        print(&quot;\033[1;37mStarting iteration #%d\033[0m&quot; % iteration)
        model.iterate()
        printoutInfo(model, &quot;iter&quot;+str(iteration))

    # output various profiles (only for stellar components)
    print(&quot;\033[1;33mComputing density profiles and velocity distribution\033[0m&quot;)
    modelStars = agama.GalaxyModel(model.potential, dfStellar, model.af)
    writeSurfaceDensityProfile    (&quot;model_stars_final.surfdens&quot;, modelStars)
    writeVerticalDensityProfile   (&quot;model_stars_final.vertical&quot;, modelStars)
    writeVelocityDispersionProfile(&quot;model_stars_final.veldisp&quot;,  modelStars)
    writeVelocityDistributions    (&quot;model_stars_final.veldist&quot;,  modelStars)

    # export model to an N-body snapshot
    print(&quot;\033[1;33mCreating an N-body representation of the model\033[0m&quot;)
    format = 'text'  # could use 'text', 'nemo' or 'gadget' here

    # first create a representation of density profiles without velocities
    # (just for demonstration), by drawing samples from the density distribution
    print(&quot;Writing N-body sampled density profile for the dark matter halo&quot;)
    agama.writeSnapshot(&quot;dens_dm_final&quot;, model.components[2].density.sample(800000), format)
    print(&quot;Writing N-body sampled density profile for the stellar bulge, disk and halo&quot;)
    # recall that component[0] contains stellar disks and stellar halo, and component[1] - bulge
    densStars = agama.Density(model.components[0].density, model.components[1].density)
    agama.writeSnapshot(&quot;dens_stars_final&quot;, densStars.sample(200000), format)

    # now create genuinely self-consistent models of all components,
    # by drawing positions and velocities from the DF in the given (self-consistent) potential
    print(&quot;Writing a complete DF-based N-body model for the dark matter halo&quot;)
    agama.writeSnapshot(&quot;model_dm_final&quot;, \
        agama.GalaxyModel(potential=model.potential, df=dfHalo, af=model.af).sample(800000), format)
    print(&quot;Writing a complete DF-based N-body model for the stellar bulge, disk and halo&quot;)
    agama.writeSnapshot(&quot;model_stars_final&quot;, \
        agama.GalaxyModel(potential=model.potential, df=dfStellarAll, af=model.af).sample(200000), format)
    # we didn't use an action-based DF for the gas disk, leaving it as a static component;
    # to create an N-body representation, we sample the density profile and assign velocities
    # from the axisymmetric Jeans equation with equal velocity dispersions in R,z,phi
    print(&quot;Writing an N-body model for the gas disk&quot;)
    agama.writeSnapshot(&quot;model_gas_final&quot;, \
        model.components[3].density.sample(24000, potential=model.potential, beta=0, kappa=1), format)
</file>
    <file path="py/example_self_consistent_model3.py">
#!/usr/bin/python
&quot;&quot;&quot;
Example of construction of a three-component disk-bulge-halo equilibrium model of a galaxy.
The approach is explained in example_self_consistent_model.py;
this example differs in that it has a somewhat simpler structure (only a single stellar disk
component, no stellar halo or gas disk) and adds a central supermassive black hole.
Another modification is that the halo and the bulge are represented by 'quasi-isotropic' DF:
it is a spherical isotropic DF that is constructed using the Eddington inversion formula
for the given density profile in the spherically-symmetric approximation of the total potential.
This DF is then expressed in terms of actions and embedded into the 'real', non-spherical
potential, giving rise to a somewhat different density profile; however, it is close enough
to the input one. Then a few more iterations are needed to converge towards a self-consistent
model.
&quot;&quot;&quot;

import agama, numpy, os, sys, matplotlib.pyplot as plt
try:
    from ConfigParser import RawConfigParser  # python 2
except ImportError:
    from configparser import RawConfigParser  # python 3

# write out the circular velocity curve for the entire model and per component
def writeRotationCurve(filename, potentials, names):
    radii = numpy.logspace(-3.0, 2.0, 101)
    xyz   = numpy.column_stack((radii, radii*0, radii*0))
    vcomp2= numpy.column_stack([-potential.force(xyz)[:,0] * radii for potential in potentials])
    vtot2 = numpy.sum(vcomp2, axis=1)
    numpy.savetxt(filename, numpy.column_stack((radii, vtot2**0.5, vcomp2**0.5)),
        fmt=&quot;%.6g&quot;, header=&quot;radius\tVcTotal\t&quot;+&quot;\t&quot;.join(names))

# print some diagnostic information after each iteration
def printoutInfo(model, iteration):
    densDisk = model.components[0].density
    densBulge= model.components[1].density
    densHalo = model.components[2].density
    pt0 = (2.0, 0, 0)
    pt1 = (2.0, 0, 0.25)
    pt2 = (0.0, 0, 2.0)
    print(&quot;Disk  total mass=%g, rho(R=2,z=0)=%g, rho(R=2,z=0.25)=%g&quot; %
        (densDisk.totalMass(), densDisk.density(pt0), densDisk.density(pt1)))
    print(&quot;Bulge total mass=%g, rho(R=0.5,z=0)=%g&quot; %
        (densBulge.totalMass(), densBulge.density(0.4, 0, 0)))
    print(&quot;Halo  total mass=%g, rho(R=2,z=0)=%g, rho(R=0,z=2)=%g&quot; %
        (densHalo.totalMass(), densHalo.density(pt0), densHalo.density(pt2)))
    # report only the potential of stars+halo, excluding the potential of the central BH (0th component)
    pot0 = model.potential.potential(0,0,0) - model.potential[0].potential(0,0,0)
    print(&quot;Potential at origin=-(%g)^2, total mass=%g&quot; % ((-pot0)**0.5, model.potential.totalMass()))
    densDisk. export(&quot;dens_disk_&quot; +iteration)
    densBulge.export(&quot;dens_bulge_&quot;+iteration)
    densHalo. export(&quot;dens_halo_&quot; +iteration)
    model.potential.export(&quot;potential_&quot;+iteration)
    # separate the contributions of bulge and halo, which are normally combined
    # into the Multipole potential of all spheroidal components
    writeRotationCurve(&quot;rotcurve_&quot;+iteration, (
        model.potential[0], # potential of the BH
        model.potential[2], # potential of the disk
        agama.Potential(type='Multipole', lmax=6, density=densBulge),  # -&quot;- bulge
        agama.Potential(type='Multipole', lmax=6, density=densHalo) ), # -&quot;- halo
        ('BH', 'Disk', 'Bulge', 'Halo') )

if __name__ == &quot;__main__&quot;:
    # read parameters from the INI file
    iniFileName = os.path.dirname(os.path.realpath(sys.argv[0])) + &quot;/../data/SCM3.ini&quot;
    ini = RawConfigParser()
    #ini.optionxform=str  # do not convert key to lowercase
    ini.read(iniFileName)
    iniPotenHalo  = dict(ini.items(&quot;Potential halo&quot;))
    iniPotenBulge = dict(ini.items(&quot;Potential bulge&quot;))
    iniPotenDisk  = dict(ini.items(&quot;Potential disk&quot;))
    iniPotenBH    = dict(ini.items(&quot;Potential BH&quot;))
    iniDFDisk     = dict(ini.items(&quot;DF disk&quot;))
    iniSCMHalo    = dict(ini.items(&quot;SelfConsistentModel halo&quot;))
    iniSCMBulge   = dict(ini.items(&quot;SelfConsistentModel bulge&quot;))
    iniSCMDisk    = dict(ini.items(&quot;SelfConsistentModel disk&quot;))
    iniSCM        = dict(ini.items(&quot;SelfConsistentModel&quot;))

    # initialize the SelfConsistentModel object (only the potential expansion parameters)
    model = agama.SelfConsistentModel(**iniSCM)

    # create initial density profiles of all components
    densityDisk  = agama.Density(**iniPotenDisk)
    densityBulge = agama.Density(**iniPotenBulge)
    densityHalo  = agama.Density(**iniPotenHalo)
    potentialBH  = agama.Potential(**iniPotenBH)

    # add components to SCM - at first, all of them are static density profiles
    model.components.append(agama.Component(density=densityDisk,  disklike=True))
    model.components.append(agama.Component(density=densityBulge, disklike=False))
    model.components.append(agama.Component(density=densityHalo,  disklike=False))
    model.components.append(agama.Component(potential=potentialBH))

    # compute the initial potential
    model.iterate()
    printoutInfo(model,'init')

    # construct the DF of the disk component, using the initial (non-spherical) potential
    dfDisk  = agama.DistributionFunction(potential=model.potential, **iniDFDisk)
    # initialize the DFs of spheroidal components using the Eddington inversion formula
    # for their respective density profiles in the initial potential
    dfBulge = agama.DistributionFunction(type='QuasiSpherical', potential=model.potential, density=densityBulge)
    dfHalo  = agama.DistributionFunction(type='QuasiSpherical', potential=model.potential, density=densityHalo)

    print(&quot;\033[1;33m**** STARTING ITERATIVE MODELLING ****\033[0m\nMasses (computed from DF): &quot;
        &quot;Mdisk=%g, Mbulge=%g, Mhalo=%g&quot; % (dfDisk.totalMass(), dfBulge.totalMass(), dfHalo.totalMass()))

    # replace the initially static SCM components with the DF-based ones
    model.components[0] = agama.Component(df=dfDisk,  disklike=True,  **iniSCMDisk)
    model.components[1] = agama.Component(df=dfBulge, disklike=False, **iniSCMBulge)
    model.components[2] = agama.Component(df=dfHalo,  disklike=False, **iniSCMHalo)

    # do a few more iterations to obtain the self-consistent density profile for both disks
    for iteration in range(1,5):
        print(&quot;\033[1;37mStarting iteration #%d\033[0m&quot; % iteration)
        model.iterate()
        printoutInfo(model, 'iter%d'%iteration)

    # export model to an N-body snapshot
    print(&quot;\033[1;33mCreating an N-body representation of the model\033[0m&quot;)
    format = 'text'  # one could also use 'nemo' or 'gadget' here

    # first create a representation of density profiles without velocities
    # (just for demonstration), by drawing samples from the density distribution
    print(&quot;Sampling disk density&quot;)
    agama.writeSnapshot(&quot;dens_disk_final&quot;,  model.components[0].density.sample(160000), format)
    print(&quot;Sampling bulge density&quot;)
    agama.writeSnapshot(&quot;dens_bulge_final&quot;, model.components[1].density.sample(40000), format)
    print(&quot;Sampling halo density&quot;)
    agama.writeSnapshot(&quot;dens_halo_final&quot;,  model.components[2].density.sample(800000), format)

    # now create genuinely self-consistent models of both components,
    # by drawing positions and velocities from the DF in the given (self-consistent) potential
    print(&quot;Sampling disk DF&quot;)
    agama.writeSnapshot(&quot;model_disk_final&quot;,
        agama.GalaxyModel(potential=model.potential, df=dfDisk,  af=model.af).sample(1600000), format)
    print(&quot;Sampling bulge DF&quot;)
    agama.writeSnapshot(&quot;model_bulge_final&quot;,
        agama.GalaxyModel(potential=model.potential, df=dfBulge, af=model.af).sample(400000), format)
    print(&quot;Sampling halo DF&quot;)
    # note: use a 10x larger particle mass for halo than for bulge/disk
    agama.writeSnapshot(&quot;model_halo_final&quot;,
        agama.GalaxyModel(potential=model.potential, df=dfHalo,  af=model.af).sample(3000000), format)

    # the remaining part computes and plots various diagnostics
    print(&quot;\033[1;33mComputing disk density and velocity profiles\033[0m&quot;)
    ax=plt.subplots(2, 3, figsize=(16,10))[1].reshape(-1)
    # take only the disk component
    modelDisk = agama.GalaxyModel(potential=model.potential, df=dfDisk, af=model.af)
    # radial grid for computing various quantities in the disk plane
    Sigma0 = float(iniPotenDisk[&quot;surfacedensity&quot;])
    Rdisk  = float(iniPotenDisk[&quot;scaleradius&quot;])
    Hdisk  =-float(iniPotenDisk[&quot;scaleheight&quot;])
    sigmar0= float(iniDFDisk[&quot;sigmar0&quot;])
    rsigmar= float(iniDFDisk[&quot;rsigmar&quot;])
    R   = agama.nonuniformGrid(60, 0.01*Rdisk, 10.0*Rdisk)
    xyz = numpy.column_stack((R, R*0, R*0))
    print(&quot;Computing surface density&quot;)
    Sigma = modelDisk.moments(xyz[:,0:2], vel2=False)  # projected density moment
    print(&quot;Computing 3d density and velocity dispersion&quot;)
    rho,vel,sigma = modelDisk.moments(xyz, dens=True, vel=True, vel2=True)
    acc,der = model.potential.eval(xyz, acc=True, der=True)
    kappa = numpy.sqrt(-der[:,0] - 3*acc[:,0]/R)
    ToomreQ = sigma[:,0]**0.5 * kappa / 3.36 / Sigma / agama.G
    numpy.savetxt(&quot;disk_plane&quot;,
        numpy.column_stack((R, Sigma, rho, sigma[:,0]**0.5, (sigma[:,1]-vel[:,1]**2)**0.5,
        sigma[:,2]**0.5, vel[:,1], ToomreQ)),
        header=&quot;R Sigma rho(R,z=0) sigma_R sigma_phi sigma_z v_phi ToomreQ&quot;, fmt=&quot;%.6g&quot;)
    ax[0].plot(R, Sigma / (Sigma0 * numpy.exp(-R/Rdisk)), 'r-', label=r'$\Sigma$')
    ax[0].plot(R, rho   / (Sigma0 * numpy.exp(-R/Rdisk) * 0.25/Hdisk), 'g-', label=r'$\rho_{z=0}$')
    ax[0].plot(R, sigma[:,0]**0.5 / (sigmar0 * numpy.exp(-R/rsigmar)), 'b-', label=r'$\sigma_r$')
    ax[0].set_xscale(&quot;log&quot;)
    ax[0].set_xlabel(&quot;R&quot;)
    ax[0].set_ylim(0,2)
    ax[0].legend(loc='lower right', frameon=False)
    # vertical grid for density
    print(&quot;Computing vertical density profiles&quot;)
    z = numpy.linspace(0, 6*Hdisk, 31)
    R = numpy.array([0.05, 0.5, 1.0, 3.0]) * Rdisk
    xyz = numpy.column_stack((numpy.tile(R, len(z)), numpy.zeros(len(R)*len(z)), numpy.repeat(z, len(R))))
    rho = modelDisk.moments(xyz, vel2=False).reshape(len(z), len(R))
    numpy.savetxt(&quot;vertical_density&quot;, numpy.column_stack((z, rho)), fmt=&quot;%.6g&quot;,
        header=&quot;z\\R:\t&quot; + &quot;\t&quot;.join([&quot;%.4g&quot; % r for r in R]))
    colors=['r','g','b','m']
    for i,r in enumerate(R):
        ax[1].plot(z, rho[:,i], '-', c=colors[i], label='R='+str(r))
        rho_init = Sigma0 * numpy.exp(-r/Rdisk) / Hdisk / (numpy.exp(-z/2/Hdisk) + numpy.exp(z/2/Hdisk))**2
        ax[1].plot(z, rho_init, ':', c=colors[i])
    ax[1].set_xlabel('z')
    ax[1].set_ylabel(r'$\rho$')
    ax[1].set_yscale('log')
    ax[1].legend(loc='lower left', frameon=False)
    # grid for computing velocity distributions
    print(&quot;Computing velocity distributions&quot;)
    z = numpy.array([0, 2*Hdisk])
    xyz = numpy.column_stack((numpy.tile(R, len(z)), numpy.zeros(len(R)*len(z)), numpy.repeat(z, len(R))))
    # create grids in velocity space for computing the spline representation of VDF (optional)
    # range: 0.75 v_escape from the galactic center (excluding the central BH potential)
    v_max = 0.75 * (-2 * (model.potential.potential(0,0,0)-model.potential[0].potential(0,0,0)))**0.5
    gridv = numpy.linspace(-v_max, v_max, 80)  # use the same grid for all dimensions
    # compute the distributions (represented as cubic splines)
    splvR, splvphi, splvz = modelDisk.vdf(xyz, gridv=gridv)
    # output f(v) at a different grid of velocity values
    gridv = numpy.linspace(-v_max, v_max, 251)
    for i,p in enumerate(xyz):
        numpy.savetxt(&quot;veldist_R=&quot;+str(p[0])+&quot;_z=&quot;+str(p[2]),
            numpy.column_stack((gridv, splvR[i](gridv), splvphi[i](gridv), splvz[i](gridv))),
            fmt=&quot;%.6g&quot;, delimiter=&quot;\t&quot;, header=&quot;V\tf(V_R)\tf(V_phi)\tf(V_z) [1/(km/s)]&quot;)
        if i&lt;len(ax)-2:
            ax[i+2].plot(gridv, splvR  [i](gridv), 'r-', label=r'$f(v_R)$')
            ax[i+2].plot(gridv, splvphi[i](gridv), 'g-', label=r'$f(v_\phi)$')
            ax[i+2].plot(gridv, splvz  [i](gridv), 'b-', label=r'$f(v_z)$')
            ax[i+2].set_xlabel('v')
            ax[i+2].set_yscale('log')
            ax[i+2].legend(loc='upper left', frameon=False)
            ax[i+2].set_xlim(-v_max, v_max)
            ax[i+2].set_ylim(1e-7,10)
            ax[i+2].text(0, 5e-7, &quot;R=&quot;+str(p[0])+&quot;_z=&quot;+str(p[2]), ha='center')
    plt.tight_layout()
    plt.show()
</file>
    <file path="py/example_smoothing_spline.py">
#!/usr/bin/python
&quot;&quot;&quot;
This example demonstrates the use of splines for two separate tasks:
(1) constructing a non-parametric estimate for the probability density from discrete samples;
(2) constructing a non-parametric smooth approximation y=f(x) for a set of points (x,y)
In the first case, we generate sample points from a mixture of two normal distributions:
80% come from N(0,1) and 20% - from N(2,0.3).
We compare the recovered probability distribution function using the kernel density estimate
from scipy, and the penalized spline log-density estimate from Agama.
In the second case, we generate noisy &quot;measurements&quot;: y[i] = f(x[i]) + g[i],
where f is a known function (sine in our example) and g is Gaussian noise with spatially
varying dispersion. We then construct a smooth approximation curve for these data points
with several choices of smoothing parameter.
&quot;&quot;&quot;
import agama,numpy
from matplotlib.pyplot import *
from scipy.stats import gaussian_kde

### example 1: density estimate
def gaussian(x, x0, sigma):
    return (2*numpy.pi)**-0.5 / sigma * numpy.exp( -0.5 * ( (x-x0) / sigma)**2 )
# original probability distribution is a mixture of two gaussians
def myfnc(x):
    return 0.8 * gaussian(x, 0, 1) + 0.2 * gaussian(x, 2, 0.3)
# original data points drawn from a mixture of two gaussians - traditional way
data = numpy.hstack(( numpy.random.normal (0, 1, 800), numpy.random.normal(2., 0.3, 200)))
# same effect could be achieved by Agama sampling routine (draw discrete samples from a N-dim distr.fnc.):
# data = agama.sampleNdim(myfnc, 1000, [-4.], [4.])[0].reshape(-1)
# simple-minded histogram
hist,bins = numpy.histogram(data, bins=30, range=(-3,3), density=True)
# kernel density estimate with an automatic choice of bandwidth (results in oversmoothing)
kde0 = gaussian_kde(data)
# same with a manually provided bandwidth (decreases bias but not completely, and also increases noise)
kde1 = gaussian_kde(data, 0.1)
# estimate of log(f(x)) using Agama routines
grid = numpy.linspace(-3, 3, 20)  # x-grid nodes for the spline
spl  = agama.splineLogDensity(grid, data, infLeft=True, infRight=True)
# plot the results
x = numpy.linspace(-4., 4., 201)  # interval for plotting
plot(x, myfnc(x), label='Original f(x)')
step(bins[:-1], hist, where='post', color='lightgrey', label='Simple histogram')
plot(x, kde0(x), color='g', label='Kernel density, auto bandwidth')[0].set_dashes([6,2])
plot(x, kde1(x), color='c', label='Kernel density, manual bandwidth')[0].set_dashes([4,1,1,1])
plot(x, numpy.exp(spl(x)), color='r', label='Spline density estimate',lw=1.5)[0].set_dashes([1,1])
legend(loc='upper left', frameon=False)
ylim(0, 0.5)
show()

### example 2: curve fitting with penalized splines
xp   = numpy.random.uniform(0, 5, 1000)**1.5  # x-values for points (more dense around origin)
sig  = 0.3 / (1 + 0.2*xp)  # spatially-variable amplitude of added noise
yp   = numpy.sin(xp) + numpy.random.normal(0, sig)
grid = numpy.linspace(0., 11., 100)  # x-grid nodes for the spline (deliberately more than needed)
# spline fit without any smoothing (results in wiggly overfitted curve)
spl0 = agama.splineApprox(grid, xp, yp, w=sig**-2, smooth=None)
# spline fit with optimal smoothing (default, recommended - result is insensitive to grid size)
spl1 = agama.splineApprox(grid, xp, yp, w=sig**-2)
# spline fit with more-than-optimal smoothing
spl2 = agama.splineApprox(grid, xp, yp, w=sig**-2, smooth=1)
# plot the results
x    = numpy.linspace(0., 11., 200)  # interval for plotting
plot(xp, yp,'.', label='original points', ms=3, c='c')
plot(x, spl0(x), label='spline fit, no smoothing', lw=1.5, c='b')[0].set_dashes([4,2])
plot(x, spl1(x), label='spline fit, optimal smoothing', c='r')
plot(x, spl2(x), label='spline fit, extra smoothing', lw=2, c='g')[0].set_dashes([1,1])
legend(loc='upper right', frameon=False, numpoints=1)
ylim(-1.5, 2.)
show()
</file>
    <file path="py/example_spiral.py">
#!/usr/bin/python

&quot;&quot;&quot;
Example of working with a new user-defined potential model in Agama.
One needs to define a function `mypot` that takes a single argument
(a Nx3 array of points in Cartesian coords) and returns an array of N
potential values. Then one may convert this function into a full-fledged
instance of the Potential class as follows:
&gt;&gt;&gt; mypot_wrapper = agama.Potential(mypot)
and this wrapper provides access to various functions such as force,
density (which are computed by finite differences), total mass,
can be used in orbit integration, etc.
However, it is rather inefficient due to large overheads from switching
between Python and C++ on every potential evaluation, so the optimal
way of using such a user-defined potential is to approximate it with
either a Multipole or a CylSpline potential expansion:
&gt;&gt;&gt; mypot_exp = agama.Potential(type='Multipole', potential=mypot, ...)
Additional arguments '...' should specify the grid parameters and the
degree of symmetry.
In this example, we construct a class representing an N-arm logarithmic
spiral density perturbation from Cox&amp;Gomez (2002), which is converted to
a CylSpline potential and added to a purely axisymmetric disk model.
We then integrate some orbits in the rotating spiral potential.
&quot;&quot;&quot;

import numpy, agama

# A factory function creating a potential with the given parameters
# (it needs to be a free function and not an instance of some class)
def createSpiralPotential(numberOfArms, surfaceDensity, scaleRadius, scaleHeight, pitchAngle, phi0=0):
    '''
    Create a CylSpline approximation for a spiral arm potential from Cox&amp;Gomez(2002).
    The density generated by this potential approximately follows an exponential
    disk profile with the amplitude of surface density variation
    Sigma(R) = surfaceDensity * exp( - R / scaleRadius ),
    and isothermal vertical profile
    rho(R,z) = Sigma(R) / (4h) * sech^2( z / (2h) ),
    where h is the scaleHeight (note the extra factor 1/2 w.r.t. the original paper,
    which is introduced to match the definition of the Disk profile in Agama).
    The density at the crest of the spiral arm is  ~ 3 * rho(R,z=0),
    while in the inter-arm region it is ~ (-1.5 to -1) * rho(R,z=0).
    The spiral is logarithmic, so that the azimuthal angle (of one of the arms) is
    phi(R) ~ phi0 + ln(R/scaleRadius) / tan(pitchAngle).
    '''
    def potfnc(xyz):
        R = (xyz[:,0]**2 + xyz[:,1]**2)**0.5
        z = xyz[:,2]
        phi = numpy.arctan2(xyz[:,1], xyz[:,0])
        prefac = -4*numpy.pi * agama.G * surfaceDensity * numpy.exp(-R / scaleRadius)
        gamma  = numberOfArms * (phi - numpy.log(R / scaleRadius) / numpy.tan(pitchAngle) - phi0)
        Phi = numpy.zeros(len(R))
        for n in range(1,4):
            K_n   = n * numberOfArms / R / numpy.sin(pitchAngle)
            K_n_H = K_n * 2 * scaleHeight
            B_n   = K_n_H * (1 + 0.4 * K_n_H)
            D_n   = 1 / (1 + 0.3 * K_n_H) + K_n_H
            C_n   = [8./3/numpy.pi, 0.5, 8./15/numpy.pi][n-1]  # amplitudes of the three harmonic terms
            Phi  += prefac * ( C_n / D_n / K_n * numpy.cos(n * gamma) *
                (numpy.cosh(K_n * z / B_n))**-B_n )
        return numpy.nan_to_num(Phi)  # VERY IMPORTANT is to make sure it never produces a NaN

    # now create a CylSpline potential approximating this user-defined profile,
    # paying special attention to the grid parameters
    return agama.Potential(type='CylSpline', potential=potfnc,
    Rmin = 0.01 * scaleRadius,  # (these could be adjusted if needed)
    Rmax = 10.0 * scaleRadius,
    zmin = 0.25 * scaleHeight,
    zmax = 10.0 * scaleHeight,
    mmax = 3 * numberOfArms,    # each arm is represented by three harmonic terms: m, m*2, m*3
    symmetry  = 'bisymmetric' if numberOfArms % 2 == 0 else 4,  # 4 means the z-reflection symmetry
    gridSizeZ = 20,
    # rule of thumb for the radial grid spacing is to resolve
    # the change in the pitch angle of the spiral with one grid cell
    gridSizeR = max(25, numpy.log(10.0 / 0.01) / numpy.tan(pitchAngle) * numberOfArms))

agama.setUnits(length=1, velocity=1, mass=1)  # some arbitrary units - everything is scale-invariant here
numberOfArms    = 3
pitchAngle      = numpy.pi/8
scaleRadius     = 1.0
scaleHeight     = 0.1
surfaceDensityD = 1.0  # density of the underlying axisymmetric disk
surfaceDensityS = surfaceDensityD * 0.5  # amplitude of the density variation of the spiral pattern
phi0            = numpy.pi/10   # [arbitrary] phase angle at R=scaleRadius
pot_spiral = createSpiralPotential(numberOfArms, surfaceDensityS, scaleRadius, scaleHeight, pitchAngle, phi0)
pot_disk = agama.Potential(type='disk', surfaceDensity=surfaceDensityD, scaleRadius=scaleRadius,
    scaleHeight=-scaleHeight)  # minus sign means the isothermal (sech^2) vertical profile
pot_total = agama.Potential(pot_disk, pot_spiral)
pot_spiral.export('example_spiral.ini')

# illustration: compute the density of the axisymmetric and the perturbed disks in the equatorial plane
import matplotlib, matplotlib.pyplot as plt
plt.ion()
ax = plt.subplots(1, 2, figsize=(10,5))[1]
X = numpy.linspace(-5*scaleRadius, 5*scaleRadius, 501)
Y = numpy.linspace(-5*scaleRadius, 5*scaleRadius, 481)
XYZ = numpy.column_stack((numpy.repeat(X, len(Y)), numpy.tile(Y, len(X)), numpy.zeros(len(X)*len(Y)) ))
rhoD = pot_disk.density(XYZ)
rhoT = pot_total.density(XYZ)
rhoMax = numpy.max(rhoD) * 3.0
rhoMin = rhoMax * 1e-3
levels = numpy.logspace(numpy.log10(rhoMin), numpy.log10(rhoMax), 32)
norm = matplotlib.colors.LogNorm()
ax[0].contour(X, Y, rhoD.reshape(len(X), len(Y)).T, levels=levels, cmap='hell_r', norm=norm)
ax[1].contour(X, Y, rhoT.reshape(len(X), len(Y)).T, levels=levels, cmap='hell_r', norm=norm)
# overplot the log-spiral
RR = numpy.logspace(-2, 0.7, 200) * scaleRadius
phi = numpy.log(RR / scaleRadius) / numpy.tan(pitchAngle) + phi0
ax[1].plot(RR * numpy.cos(phi), RR * numpy.sin(phi), 'g-')
plt.tight_layout()
plt.show()
plt.pause(5)

# compute some orbits in the axisymmetric and perturbed potentials
# (the latter rotating with pattern speed Omega)
R0 = 3.0
V0 = (-R0 * pot_disk.force(R0,0,0)[0])**0.5   # circular velocity at the given radius
# note that we set the pattern speed to a negative value, so that the spirals are trailing
Omega = -0.8 * V0 / R0
ic = [-R0, 0.0, 0.0, 0.0, 0.9*V0, 0.1*V0]   # and make the angular momentum negative as well (i.e.prograde)
time  = 20 * R0 / V0
nsteps= 200
# trajectories are stored in the rotating frame
t, orbit_disk = agama.orbit(potential=pot_disk,  ic=ic, time=time, trajsize=nsteps, Omega=Omega)
_, orbit_spir = agama.orbit(potential=pot_total, ic=ic, time=time, trajsize=nsteps, Omega=Omega)
# convert the trajectories to the inertial frame
cosa, sina = numpy.cos(t * Omega), numpy.sin(t * Omega)
orbit_disk_x = orbit_disk[:,0] * cosa - orbit_disk[:,1] * sina
orbit_disk_y = orbit_disk[:,1] * cosa + orbit_disk[:,0] * sina
orbit_spir_x = orbit_spir[:,0] * cosa - orbit_spir[:,1] * sina
orbit_spir_y = orbit_spir[:,1] * cosa + orbit_spir[:,0] * sina

# plot the animated orbit and rotating potential
for i in range(nsteps):
    # the spirals need to be replotted in each frame at a different orientation
    XYZrot = numpy.column_stack((XYZ[:,0] * cosa[i] + XYZ[:,1] * sina[i],
        XYZ[:,1] * cosa[i] - XYZ[:,0] * sina[i], XYZ[:,2]))
    rhoT = pot_total.density(XYZrot)
    ax[1].cla()
    ax[1].contour(X, Y, rhoT.reshape(len(X), len(Y)).T, levels=levels, cmap='hell_r', norm=norm)
    # overplot the current position (for the left panel, which is not cleared) in the inertial frame
    ax[0].plot(orbit_disk_x[i], orbit_disk_y[i], 'ko', ms=3)
    # overplot the past trajectory up to the current time (for the right panel, which is cleared each time)
    ax[1].plot(orbit_spir_x[:i+1], orbit_spir_y[:i+1], 'ko', ms=3)
    plt.draw()
    plt.pause(0.1)

plt.ioff()
plt.show()
</file>
    <file path="py/example_target.py">
#!/usr/bin/python

&quot;&quot;&quot;
This example illustrates various usage scenarios for Target objects, used in Schwarzschild models.
&quot;&quot;&quot;
import agama,numpy

numpy.set_printoptions(linewidth=100, formatter={'all':lambda x: '%11.6f'%x})

# set up some random physical units, to test the correction of unit conversion
agama.setUnits(length=3.4567, mass=12345, velocity=6.7)

# physical constituents of a model: potential and a corresponding isotropic DF
pot   = agama.Potential(type='Plummer', scaleRadius=0.1, mass=100)
dens  = pot
df    = agama.DistributionFunction(type='QuasiSpherical', potential=pot)
gm    = agama.GalaxyModel(pot, df)
vesc  = (-2*pot.potential(0,0,0))**0.5  # escape velocity from r=0
#print(&quot;escape velocity: %g&quot; % vesc)

# define a grid in radius and a series of concentric rings for recording LOSVD
gridr = agama.nonuniformGrid(10, 0.025, 1)  # grid in radius (denser at small radii)
gridx = agama.symmetricGrid (19, 0.025, 1)  # grids in x,y - symmetrically mirror about origin
gridv = numpy.linspace(-vesc, vesc, 25)     # grid in velocity space
ang   = numpy.linspace(0, 2*numpy.pi, 73)   # approximate a circle with a polygon with this many vertices
sa    = numpy.sin(ang); sa[36]=sa[72]=0
ca    = numpy.cos(ang); ca[18]=ca[54]=0
circ  = [numpy.column_stack((rr*ca, rr*sa)) for rr in gridr[1:]]
poly  = [circ[0]] + [ numpy.vstack((p1, p2[::-1])) for p1,p2 in zip(circ[1:],circ[:-1]) ]
numaper = len(poly)   # total number of apertures (all concentric rings except the central one, which is a circle)

# define different types of target objects
tar_dens  = agama.Target(type='DensitySphHarm', gridr=gridr)
tar_shell = agama.Target(type='KinemShell', gridr=gridr, degree=1)
degree    = 2   # B-spline degree for LOSVD representation (2 or 3 are strongly recommended)
tar_losvd = agama.Target(type='LOSVD', degree=degree, apertures=poly, gridx=gridx, gridv=gridv, symmetry='s')

# generate N-body samples from the model,
# and integrate orbits with (some of) these initial conditions
xv, mass  = gm.sample(1000000)
ic = xv[:10000]  # use only a subset of ICs, to save time
mat_dens, mat_shell, mat_losvd = agama.orbit(potential=pot, ic=ic,
    time=100*pot.Tcirc(ic), targets=[tar_dens, tar_shell, tar_losvd])

# as the IC were drawn from the actual DF of the model,
# we expect that all orbits have the same weight in the model
orbitweight = pot.totalMass() / len(ic)

# now apply the targets to several kinds of objects:
print(&quot;Applying Targets to various objects (takes time)...&quot;)
# 1) collection of orbits, summing up equally-weighted contributions of all orbits
dens_orb   = numpy.sum(mat_dens,  axis=0) * orbitweight
shell_orb  = numpy.sum(mat_shell, axis=0) * orbitweight
losvd_orb  = numpy.sum(mat_losvd, axis=0) * orbitweight
# 2) the entire model (df + potential)
dens_df    = tar_dens (gm)
shell_df   = tar_shell(gm)
losvd_df   = tar_losvd(gm)   # this **is** expensive...
# 3) N-body realization of the model
dens_nb    = tar_dens ((xv,mass))
shell_nb   = tar_shell((xv,mass))
losvd_nb   = tar_losvd((xv,mass))
# 4) the 3d density profile of the model
dens_dens  = tar_dens (dens)
# all these operations should produce roughly equal results, so illustrate this

# Target DensitySphHarm produces an array of masses, which should sum up to nearly the total mass
print(&quot;3d density discretized on a radial grid (masses associated with grid nodes) computed from...&quot;)
print(&quot;[radius]   orbit library   smooth DF   N-body model   density profile&quot;)
print(numpy.column_stack((gridr, dens_orb, dens_df, dens_nb, dens_dens)))
print(&quot;Total: %6.1f %11.6f %11.6f %11.6f %11.6f&quot; %
    (pot.totalMass(), sum(dens_orb), sum(dens_df), sum(dens_nb), sum(dens_dens)))

# Target KinemShell produces an array of length 2*len(gridr), with the elements being
# density-weighted radial (first half) and tangential (second half) squared velocity dispersions.
# To get the actual velocity dispersion, we divide these numbers by the array produced by
# Target DensitySphHarm, which is the mass associated with each grid node computed in the same way.
print(&quot;3d velocity dispersion profiles on a radial grid (first radial, then tangential)&quot;)
print(&quot;[radius]   orbit library   smooth DF   N-body model   DF moments&quot;)
mom = gm.moments(numpy.column_stack((gridr, gridr*0, gridr*0)), dens=False, vel2=True)
print(numpy.column_stack((gridr,
    (shell_orb[:len(gridr)] / dens_orb)**0.5,
    (shell_df [:len(gridr)] / dens_df )**0.5,
    (shell_nb [:len(gridr)] / dens_nb )**0.5,
    mom[:,0]**0.5 )))
print(numpy.column_stack((gridr,
    (shell_orb[len(gridr):] * 0.5 / dens_orb)**0.5,  # tangenial contains a sum of two components
    (shell_df [len(gridr):] * 0.5 / dens_df )**0.5,  # (theta and phi), so divide by two to get
    (shell_nb [len(gridr):] * 0.5 / dens_nb )**0.5,  # a one-dimensional velocity dispersion
    ( (mom[:,1] + mom[:,2]) * 0.5)**0.5 )))          # similarly, average between theta and z

# Target LOSVD produces the line-of-sight velocity distributions in the given apertures
# in the image plane, when applied to objects with velocity information
# (GalaxyModel, N-body snapshot, or orbit library).
# Integrating these LOSVDs along the velocity axis, one obtains the projected mass
# in each aperture (integral of surface density over the area of the aperture),
# and this is also the result of applying Target LOSVD to a Density object.
print(&quot;2d surface density integrated over apertures (projected masses in each aperture)&quot;)
print(&quot;[radius]   orbit library   smooth DF   N-body model   density   GH moments&quot;)
bsi = agama.bsplineIntegrals(degree, gridv)
ghm = agama.ghMoments(degree=degree, gridv=gridv, matrix=losvd_df, ghorder=6).reshape(numaper,-1)
surf_dens  = tar_losvd(dens)
surf_orb   = losvd_orb.reshape(numaper,-1).dot(bsi)
surf_df    = losvd_df .reshape(numaper,-1).dot(bsi)
surf_nb    = losvd_nb .reshape(numaper,-1).dot(bsi)
print(numpy.column_stack((gridr[1:], surf_orb, surf_df, surf_nb, surf_dens, ghm[:,0])))
print(&quot;Total: %6.1f %11.6f %11.6f %11.6f %11.6f %11.6f&quot; %
    (pot.totalMass(), sum(surf_orb), sum(surf_df), sum(surf_nb), sum(surf_dens), sum(ghm[:,0])))

# Of course, the main result of Target LOSVD are the velocity profiles, not just their integrals;
# we compare the profiles produced from different objects in each aperture
import matplotlib.pyplot as plt
ax=plt.subplots(3, 3, figsize=(10,10))[1].reshape(-1)
gridvplot = numpy.linspace(-vesc, vesc, 201)
for i in range(numaper):
    ax[i].plot(gridvplot, agama.bsplineInterp(degree, gridv, losvd_orb.reshape(numaper,-1)[i], gridvplot), label='orbits')
    ax[i].plot(gridvplot, agama.bsplineInterp(degree, gridv, losvd_df .reshape(numaper,-1)[i], gridvplot), label='smooth DF')
    ax[i].plot(gridvplot, agama.bsplineInterp(degree, gridv, losvd_nb .reshape(numaper,-1)[i], gridvplot), label='N-body')
    ax[i].plot(gridvplot, agama.ghInterp(ghm[i,0], ghm[i,1], ghm[i,2], ghm[i,3:], gridvplot), label='GaussHermite')
    if i==0: ax[i].legend(loc='upper left', fontsize=8, frameon=False)
    ax[i].text(0, 0, 'r&lt;%.3g' % gridr[i+1], ha='center', va='bottom')
plt.tight_layout()
plt.show()
</file>
    <file path="py/example_tidal_stream.py">
#!/usr/bin/python
'''
Simulation of a disrupting satellite galaxy orbiting inside a host galaxy and
exposed to tidal stripping and dynamical friction.
The most straightforward approach would be to represent both galaxies as N-body
systems and evolve them with a conventional N-body code (in this example, we use
pyfalcon - the Python interface to Gyrfalcon - a fast-multipole code by W.Dehnen).
But this is rather expensive, since the host galaxy would need to be resolved
by many more particles than the satellite in order to correctly simulate
the dynamical friction (DF).
Instead, we rely on the Chandrasekhar approximation of the DF force, and simulate
only the satellite as an N-body system. It is embedded in a static external
potential of the host galaxy, which creates a realistic tidal force, and we add
the DF force manually, using the instantaneous position, velocity and mass of
the satellite galaxy recomputed at each timestep.
This approach is still expensive, so another approximation is put forward
under the name &quot;restricted N-body simulation&quot;.
Here the satellite galaxy moves in the host galaxy as a single massive body
experiencing dynamical friction. To produce the tidal stream and to determine
the mass evolution of the satellite, it is also represented by test particles,
which do not interact between themselves, but move in the time-dependent
potential created by the host and the moving satellite.
The potential and mass of the satellite are then recomputed every so often
from these particles, closing the loop. The update interval is much longer
than the timestep of the full N-body simulation, because the orbits of particles
are evolved with high precision using an adaptive-timestep integrator, and
the frequency of updates should be sufficient to resolve the mass and structural
evolution of the satellite rather than particle trajectories themselves.
Despite the obviously approximate nature of this approach, it produces
a realistic tidal stream and roughly matches the evolution of the system
in the full N-body + DF simulation.
This script implements both approaches, but the full N-body is run only if
pyfalcon is available.
'''
import os, numpy, agama, scipy.special, scipy.integrate, matplotlib.pyplot as plt
try: import pyfalcon
except ImportError: pyfalcon=None

# whether to plot a movie as the simulation progresses (slows it down considerably!)
# if set to False, plot only the final snapshot
plot = True

# working units: 1 Msun, 1 kpc, 1 km/s
agama.setUnits(length=1, velocity=1, mass=1)

# parameters of the host galaxy (a spherical NFW halo; one can add stellar disc
# or even use a standard potential such as McMillan17)
pot_host_params = dict(type='spheroid', gamma=1, beta=3, scaleradius=15.0, densitynorm=1)
# choose the density normalization such that the circular velocity at 10 kpc is 200 km/s
vcirc1 = (-agama.Potential(pot_host_params).force(10,0,0)[0] * 10)**0.5
pot_host_params['densitynorm'] = (200.0/vcirc1)**2
pot_host = agama.Potential(pot_host_params)

# prepare an interpolation table for the host velocity dispersion profile
df_host = agama.DistributionFunction(type='quasispherical', potential=pot_host)
grid_r  = numpy.logspace(-1, 2, 16)  # grid from 0.1 to 100 kpc
grid_sig= agama.GalaxyModel(pot_host, df_host).moments(
    numpy.column_stack((grid_r, grid_r*0, grid_r*0)), dens=False, vel=False, vel2=True)[:,0]**0.5
logspl  = agama.Spline(numpy.log(grid_r), numpy.log(grid_sig))  # log-scaled spline
sigma   = lambda r: numpy.exp(logspl(numpy.log(r)))   # and the un-scaled interpolator

# initial potential of the satellite (a single Dehnen component with a Gaussian cutoff)
pot_sat  = agama.Potential(type='spheroid', gamma=1, beta=4, scaleradius=2.0, outercutoffradius=8.0, mass=1e9)
initmass = pot_sat.totalMass()

# create a spherical isotropic DF for the satellite and sample it with particles
df_sat = agama.DistributionFunction(type='quasispherical', potential=pot_sat)
Nbody = 10000
xv, mass = agama.GalaxyModel(pot_sat, df_sat).sample(Nbody)

# place the satellite at the apocentre of a moderately eccentric orbit
R0 = 50.0
Vcirc = (-R0 * pot_host.force(R0,0,0)[0])**0.5
V0 = 0.7 * Vcirc

# initial displacement
r_center = numpy.array([R0, 0, 0, 0, V0, 0])
xv += r_center

# parameters for the simulation
tend = 3.0   # total simulation time
tupd = 2**-2 # interval for plotting and updating the satellite mass for the restricted N-body simulation
tau  = 2**-8 # timestep of the full N-body sim (typically should be smaller than eps/v, where v is characteristic internal velocity)
eps  = 0.1   # softening length for the full N-body simulation

def dynfricAccel(pos, vel, mass):
    # compute the Chandrasekhar's dynamical friction acceleration for a point mass in the host galaxy
    r   = sum(pos**2)**0.5
    v   = sum(vel**2)**0.5
    rho = pot_host.density(pos)
    coulombLog = 3.0
    X = v / (2**0.5 * sigma(r))
    return -vel / v * (4*numpy.pi * agama.G**2 * mass * rho * coulombLog *
        (scipy.special.erf(X) - 2/numpy.pi**.5 * X * numpy.exp(-X*X)) / v**2)

def orbitDF(ic, time, timestart, trajsize, mass):
    # integrate the orbit of a massive particle in the host galaxy, accounting for dynamical friction
    if mass == 0:
        return agama.orbit(ic=ic, potential=pot_host, time=time, timestart=timestart, trajsize=trajsize)
    times = numpy.linspace(timestart, timestart+time, trajsize)
    traj = scipy.integrate.odeint(
        lambda xv, t: numpy.hstack((xv[3:6], pot_host.force(xv[0:3], t=t) + dynfricAccel(xv[0:3], xv[3:6], initmass) )),
        ic, times)
    return times, traj

# simulate the evolution of the disrupting satellite using two methods:
# &quot;restricted N-body&quot; (r_ prefix) and &quot;full N-body&quot; (if available, f_ prefix)

r_mass   = [initmass]
r_traj   = [r_center]
r_xv     = xv.copy()
time     = 0.0   # current simulation time
times_t  = [time]
times_u  = [time]
f_center = r_center.copy()
f_mass   = [initmass]
f_traj   = [f_center]
f_xv     = xv.copy()
f_bound  = numpy.ones(len(xv), bool)

plt.figure(figsize=(9,6), dpi=100)
ax1=plt.axes([0.07, 0.08, 0.36, 0.54])
ax2=plt.axes([0.57, 0.08, 0.36, 0.54])
bx1=plt.axes([0.07, 0.72, 0.36, 0.24])
bx2=plt.axes([0.57, 0.72, 0.36, 0.24])
cx1=bx1.twinx()
cx2=bx2.twinx()
if plot:
    plt.ion()

print('time  mass' + ('  mass(Nbody)' if pyfalcon else ''))
while time &lt; tend:
    # Method 1: restricted N-body
    # first determine the trajectory of the satellite centre in the host potential
    # (assuming that it moves as a single massive particle)
    time_center, orbit_center = orbitDF(ic=r_center, time=tupd, timestart=time, trajsize=round(tupd/tau) + 1, mass=r_mass[-1])
    times_u.append(time_center[-1])
    times_t.extend(time_center[1:])
    r_traj.extend(orbit_center[1:])
    r_center = orbit_center[-1]  # current position and velocity of satellite CoM
    # initialize the time-dependent total potential (host + moving sat) on this time interval
    pot_total = agama.Potential(pot_host,
        agama.Potential(potential=pot_sat, center=numpy.column_stack((time_center, orbit_center))))
    # compute the trajectories of all particles moving in the combined potential of the host galaxy and the moving satellite
    r_xv = numpy.vstack(agama.orbit(ic=r_xv, potential=pot_total, time=tupd, timestart=time, trajsize=1)[:,1])
    # update the potential of the satellite (using a spherical monopole approximation)
    pot_sat = agama.Potential(type='multipole', particles=(r_xv[:,0:3] - r_center[0:3], mass), symmetry='s')
    # determine which particles remain bound to the satellite
    r_bound = pot_sat.potential(r_xv[:,0:3] - r_center[0:3]) + 0.5 * numpy.sum((r_xv[:,3:6] - r_center[3:6])**2, axis=1) &lt; 0
    r_mass.append(numpy.sum(mass[r_bound]))

    # Method 2: full N-body
    if pyfalcon:
        if time==0:   # initialize accelerations and potential
            f_acc, f_pot = pyfalcon.gravity(f_xv[:,0:3], agama.G * mass, eps)
            f_acc += pot_host.force(f_xv[:,0:3]) + dynfricAccel(f_center[0:3], f_center[3:6], initmass)

        # advance the N-body sim in smaller steps
        f_time = 0
        while f_time &lt; tupd:
            # kick-drift-kick leapfrog method:
            # kick for half-step, using accelerations computed at the end of the previous step
            f_xv[:,3:6] += f_acc * (tau/2)
            # drift for full step
            f_xv[:,0:3] += f_xv[:,3:6] * tau
            # recompute accelerations from self-gravity of the satellite
            # NB: falcON works with natural N-body units in which G=1, so we multiply particle mass passed to falcon by G
            f_acc, f_pot = pyfalcon.gravity(f_xv[:,0:3], agama.G * mass, eps)
            # add accelerations from the host galaxy
            f_acc += pot_host.force(f_xv[:,0:3])
            # add acceleration from dynamical friction (for simplicity, to all particles, not only the bound ones)
            f_acc += dynfricAccel(f_center[0:3], f_center[3:6], numpy.sum(mass[f_bound]))
            # kick again for half-step
            f_xv[:,3:6] += f_acc * (tau/2)

            # recompute the location and velocity of the satellite centre and its remaining bound mass
            f_center[0:3] += tau * f_center[3:6]  # linearly extrapolate from the previous timestep to get the first estimate
            Rmax = 10.0
            use  = numpy.sum((f_xv[:,0:3] - f_center[0:3])**2, axis=1) &lt; Rmax**2
            # iteratively refine the selection, retaining only bound particles (which have
            # negative total energy in the satellite-centered frame using its own potential only)
            prev_f_center = f_center
            for i in range(10):
                f_center = numpy.median(f_xv[use], axis=0)
                f_bound = f_pot + 0.5 * numpy.sum((f_xv[:,3:6] - f_center[3:6])**2, axis=1) &lt; 0
                if numpy.sum(f_bound)&lt;=1 or all(f_center==prev_f_center): break
                use = f_bound * (numpy.sum((f_xv[:,0:3] - f_center[0:3])**2, axis=1) &lt; Rmax**2)
                prev_f_center = f_center

            f_traj.append(f_center)
            f_mass.append(numpy.sum(mass[f_bound]))
            f_time += tau

    time += tupd
    print('%5.3f  %.4g' % (time, r_mass[-1]/initmass) + ('  %.4g' % (f_mass[-1]/initmass) if pyfalcon else ''))

    if plot or time==tend:
        ax1.cla()
        ax2.cla()
        bx1.cla()
        bx2.cla()
        cx1.cla()
        cx2.cla()
        bx1.text(0.5, 0.1, 'restricted N-body', ha='center', va='bottom', transform=bx1.transAxes)
        bx2.text(0.5, 0.1, 'full N-body' + ('' if pyfalcon else ' (n/a)'), ha='center', va='bottom', transform=bx2.transAxes)
        ax1.scatter(r_xv[:,0], r_xv[:,1], marker='o', s=1, linewidths=0, edgecolors='none',
            c=r_bound, cmap='bwr_r', vmin=0, vmax=1)  # blue: bound, red: unbound particles
        ax1.plot(numpy.vstack(r_traj)[:,0], numpy.vstack(r_traj)[:,1], 'g')
        if pyfalcon:
            ax2.scatter(f_xv[:,0], f_xv[:,1], marker='o', s=1, linewidths=0, edgecolors='none',
                c=f_bound, cmap='bwr_r', vmin=0, vmax=1)
            ax2.plot(numpy.vstack(f_traj)[:,0], numpy.vstack(f_traj)[:,1], 'g')
        ax1.set_xlim(-60,60)
        ax1.set_ylim(-60,60)
        ax2.set_xlim(-60,60)
        ax2.set_ylim(-60,60)
        ax1.set_xlabel('x')
        ax2.set_xlabel('x')
        ax1.set_ylabel('y', labelpad=0)
        ax2.set_ylabel('y', labelpad=0)
        bx1.plot(times_t, numpy.sum(numpy.vstack(r_traj)[:,0:2]**2, axis=1)**0.5, 'r')
        cx1.plot(times_u, r_mass, 'b')
        if pyfalcon:
            bx2.plot(times_t, numpy.sum(numpy.vstack(f_traj)[:,0:2]**2, axis=1)**0.5, 'r')
            cx2.plot(times_t, f_mass, 'b')
        bx1.set_ylim(0, R0)
        bx2.set_ylim(0, R0)
        cx1.set_ylim(0, initmass)
        cx2.set_ylim(0, initmass)
        bx1.set_xlim(0, tend)
        bx2.set_xlim(0, tend)
        bx1.set_xlabel('time')
        bx2.set_xlabel('time')
        bx1.set_ylabel('distance')
        bx2.set_ylabel('distance')
        cx1.set_ylabel('bound mass')
        cx2.set_ylabel('bound mass')
        cx1.yaxis.set_label_position('right')
        cx2.yaxis.set_label_position('right')
        plt.draw()
        plt.pause(.01)

if plot:
    plt.ioff()
plt.show()
</file>
    <file path="py/example_time_dependent_potential.py">
#!/usr/bin/python

&quot;&quot;&quot;
Example of simple time-dependent potentials -- two point masses on a circular orbit,
representing the star and the planet. We compute orbits of test particles in this system,
i.e., solve the restricted three-body problem; in this example, we pick the initial conditions
corresponding to a horseshoe orbit (a coorbital motion with the planet with low-frequency
libration in angle).
We illustrate four alternative ways of creating time-dependent potentials:
1) fix the two point masses in space, but integrate the orbit in a uniformly rotating frame
   (of course, this is only possible if the orbit of the planet is circular);
2) same as above, but make the potential itself rotating, and integrate the orbit
   in the original inertial frame;
3) let the two point masses move around on a pre-computed trajectory, and integrate the motion
   of the test particle in an inertial frame, but with a time-dependent potential;
4) same as above, but use a built-in potential of two moving point masses -- KeplerOrbit.
The second approach is identical to the first one in this case, but can be used more generally
with a non-uniformly rotating potential.
The fourth approach is more accurate than the third, because the orbit of the two massive
bodies is computed analytically, and is more general than the first one for this case,
because it can be used even for an eccentric planet.
However, the third approach is even more general, and can be used with an arbitrary number
of potentials (not necessarily point masses) moving on different trajectories.
On the other hand, the second approach can create non-uniformly rotating arbitrary potentials.
&quot;&quot;&quot;
import agama, numpy, matplotlib.pyplot as plt

plt.rc('font', size=10)
ax = plt.subplots(1, 3, figsize=(12,4), dpi=100)[1]

au = 4.84814e-9  # 1 astronomical unit in kpc
# work in solar system units: 1 AU, 1 Msun, 1 km/s, 4.74 yr
agama.setUnits(length=au, mass=1, velocity=1)

r0 = 1.            # AU
v0 = agama.G**0.5  # ~30 km/s - orbital velocity of Earth
om = v0/r0         # Omega - angular frequency of rotation
tu = om/2/numpy.pi # years in one time unit
ic = [r0, 0, 0, 0, v0, 0]  # initial conditions for the orbit - at the other side of the Sun from Earth
tmax = 20

# in cases the orbit is integrated in an inertial frame with a rotating potential,
# we need to transform it back to the corotating frame, in which the potential is stationary
def convertToCorotatingFrame(t, o):
    return numpy.column_stack((
    o[:,0] * numpy.cos(om*t) + o[:,1] * numpy.sin(om*t),
    o[:,1] * numpy.cos(om*t) - o[:,0] * numpy.sin(om*t),
    o[:,2],
    o[:,3] * numpy.cos(om*t) + o[:,4] * numpy.sin(om*t),
    o[:,4] * numpy.cos(om*t) - o[:,3] * numpy.sin(om*t),
    o[:,5] ))

# compute the Jacobi energy, which should be conserved along the orbit
# (note that here we evaluate the potential at t=0 for all points in the trajectory,
# because the orbit is represented in a rotating frame where the potential is stationary)
def JacobiEnergy(pot, orb):
    return pot.potential(orb[:,0:3]) + 0.5 * numpy.sum(orb[:,3:6]**2, axis=1) - (orb[:,0]*orb[:,4]-orb[:,1]*orb[:,3])*om

# variant 1: set up two fixed point masses (Sun and super-Earth of mass 0.001 Msun),
# and integrate the test-particle orbit in the rotating frame, in which Sun&amp;Earth are stationary.
# the potential is initialized as two components with different 'modifier' parameters
# (in this case, center=... creates a Shifted modifier on top of the potential,
# and we provide just a triplet of numbers to establish a constant shift;
# it could be a string or a list/array).
p1 = agama.Potential(
    dict(type='plummer', mass=0.999, scaleradius=0, center=&quot;0.001,0,0&quot;),  # Sun
    dict(type='plummer', mass=0.001, scaleradius=0, center=[-.999,0,0]))  # Earth (a very massive one)
t1, o1 = agama.orbit(potential=p1, ic=[r0,0,0,0,v0,0], time=tmax, trajsize=501, Omega=om, dtype=float)
E1 = JacobiEnergy(p1, o1)
ax[0].plot(o1[:,0], o1[:,1], c='b')
ax[1].plot(t1*tu, o1[:,0], c='b')
ax[1].plot(t1*tu, o1[:,1], c='b', dashes=[3,2])
ax[2].plot(t1*tu, E1, c='b', label='Two fixed point masses in rotating frame')

# variant 2: same setup, but now make the potential of the two point masses rotate
# in the inertial frame, and integrate the orbit of the test particle in this frame.
# If the original potential is a simple built-in model (e.g., type='Plummer'),
# one could construct both the potential and the modifier in one expression:
# p2 = agama.Potential(type=..., mass=..., rotation=...)
# if the potential consists of several components with the same modifier parameters,
# these components will be merged into a single Composite potential and then
# a common modifier created on top of it.
# However, in our case this doesn't apply because
# (a) the offsets are different, and
# (b) if multiple modifiers are applied to a single potential, their implied order is
# first rotation, then tilt, then shift - in other words, two point masses will be
# made rotating individually (which doesn't make physical sense for them) and then
# shifted by a constant offset each, but this does not create a two-body orbit.
# Therefore, we use the most general approach: first create a composite potential
# of two fixed point masses, both shifted from origin (reuse the potential from variant 1),
# and then wrap it into a 'Rotating' modifier by providing an array with the rotation angle
# as a function of time (changing linearly in this case, so we only need two timestamps,
# and it is extrapolated linearly beyond the end of the specified time interval).
p2 = agama.Potential(potential=p1, rotation=[[0, 0], [1, om]])
# integrate the orbit of a test particle in the inertial frame, but using a rotating potential
t2, o2 = agama.orbit(potential=p2, ic=[r0,0,0,0,v0,0], time=tmax, trajsize=501, dtype=float)
o2 = convertToCorotatingFrame(t2, o2)   # transform the orbit back into the corotating frame
E2 = JacobiEnergy(p2, o2)
ax[0].plot(o2[:,0], o2[:,1], c='g')
ax[1].plot(t2*tu, o2[:,0], c='g')
ax[1].plot(t2*tu, o2[:,1], c='g', dashes=[3,2])
ax[2].plot(t2*tu, E2, c='g', label='Two rotating point masses in inertial frame')

# variant 3: same setup, but now make the two point masses move on pre-computed circular orbits,
# and integrate the orbit of the test particle in the inertial frame
tt = numpy.linspace(0, tmax*1.01, 6000)
sinomt, cosomt = numpy.sin(om*tt), numpy.cos(om*tt)
center1 = numpy.column_stack((tt, cosomt*0.001, sinomt*0.001, 0*tt, -om*sinomt*0.001, om*cosomt*0.001, 0*tt))
center2 = numpy.column_stack((tt, cosomt*-.999, sinomt*-.999, 0*tt, -om*sinomt*-.999, om*cosomt*-.999, 0*tt))
# this time we create a composite potential in which each component has a different time-dependent shift
p3 = agama.Potential(
    dict(type='plummer', mass=0.999, scaleradius=0, center=center1),
    dict(type='plummer', mass=0.001, scaleradius=0, center=center2) )
t3,o3 = agama.orbit(potential=p3, ic=[r0,0,0,0,v0,0], time=tmax, trajsize=501, dtype=float)
o3 = convertToCorotatingFrame(t3, o3)   # transform the orbit back into the corotating frame
E3 = JacobiEnergy(p3, o3)
ax[0].plot(o3[:,0], o3[:,1], c='r')
ax[1].plot(t3*tu, o3[:,0], c='r')
ax[1].plot(t3*tu, o3[:,1], c='r', dashes=[3,2])
ax[2].plot(t3*tu, E3, c='r', label='Two moving point masses in inertial frame')

# variant 4: instead of manually creating two point masses and putting them on a Kepler orbit,
# use a special type of potential, which does just that without any modifiers: KeplerBinary
p4 = agama.Potential(type='KeplerBinary', mass=1, binary_sma=1.0, binary_q=1./999, binary_ecc=0)
t4,o4 = agama.orbit(potential=p4, ic=[r0,0,0,0,v0,0], time=tmax, trajsize=501, dtype=float)
o4 = convertToCorotatingFrame(t4, o4)   # transform the orbit back into the corotating frame
E4 = JacobiEnergy(p4, o4)
ax[0].plot(o4[:,0], o4[:,1], c='y')
ax[1].plot(t4*tu, o4[:,0], c='y')
ax[1].plot(t4*tu, o4[:,1], c='y', dashes=[3,2])
ax[2].plot(t4*tu, E4, c='y', label='KeplerOrbit potential in inertial frame')
# adorn the plot with the symbols representing the Sun and the Planet
ax[0].plot(0.001, 0, 'o', ms=12, c='k', markerfacecolor='none')
ax[0].plot(0.001, 0, 'o', ms=2, c='k')
ax[0].plot(-.999, 0, 'o', ms=10, c='k', markerfacecolor='none')
ax[0].plot(-.999, 0, '+', ms=9, c='k')
ax[0].set_xlim(-1.1, 1.1)
ax[0].set_ylim(-1.1, 1.1)
ax[0].set_xlabel('X [au]')
ax[0].set_ylabel('Y [au]')
ax[1].set_xlabel('time [yr]')
ax[1].set_ylabel('X (solid), Y (dashed) [au]')
ax[2].set_xlabel('time [yr]')
ax[2].set_ylabel('Jacobi energy [km/s]^2')
ax[2].legend(loc='upper left', frameon=False, fontsize=8)

print('Potentials used in the orbit integration:\n%s\n%s\n%s\n%s' % (p1, p2, p3, p4))
plt.tight_layout()
plt.show()
</file>
    <file path="py/example_torus.py">
#!/usr/bin/python
# illustrate the use of Torus Machine for transformation from action/angle to position/velocity
import agama, numpy, matplotlib.pyplot as plt
ax = plt.subplots(2,2, figsize=(15,10))[1]
pot = agama.Potential(type='Spheroid', gamma=0, beta=5, alpha=2, mass=10, axisratioz=.6)  # flattened Plummer
act = numpy.array([1.0, 2.0, 3.0])  # Jr, Jz, Jphi - some fiducial values
am = agama.ActionMapper(pot)  # J,theta -&gt; x,v (Torus)
af = agama.ActionFinder(pot)  # x,v -&gt; J,theta (Staeckel fudge)
t = numpy.linspace(0, 100, 1001)
# construct the orbit using Torus
Omega_torus = am(numpy.hstack((act, [0,0,0])), frequencies=True)[1]
xv_torus = am(numpy.column_stack((act + t[:,None]*0, Omega_torus*t[:,None])))
ax[0,0].plot((xv_torus[:,0]**2+xv_torus[:,1]**2)**0.5, xv_torus[:,2], label='torus', dashes=[4,2])
# construct the orbit by numerically integrating the equations of motion
_,xv_orbit = agama.orbit(ic=xv_torus[0], potential=pot, time=t[-1], trajsize=len(t))
ax[0,0].plot((xv_orbit[:,0]**2+xv_orbit[:,1]**2)**0.5, xv_orbit[:,2], label='orbit')
# compute actions for the torus orbit using Staeckel approximation
J,theta,Omega = af(xv_torus, angles=True)
ax[0,1].plot(t, J, label='J,torus', dashes=[4,2])
ax[1,1].plot(t, Omega, label='Omega,torus', dashes=[4,2])
ax[1,0].plot(t, theta, label='theta,torus', dashes=[4,2])
# same for the actual orbit
J,theta,Omega = af(xv_orbit, angles=True)
ax[0,1].plot(t, J, label='J,orbit')
ax[1,1].plot(t, Omega, label='Omega,orbit')
ax[1,0].plot(t, theta, label='theta,orbit')
ax[0,0].legend()
ax[0,1].legend()
ax[1,0].legend()
ax[1,1].legend()
plt.tight_layout()
plt.show()
</file>
    <file path="py/example_vdf_fit_bspline.py">
#!/usr/bin/python
&quot;&quot;&quot;
This example demonstrates the use of B-splines for fitting a distribution of points,
for instance, constructing a smooth velocity distribution function (VDF) from an array
of measured values, optionally deconvolving it from individual measurement errors.
We first create a plausible VDF from a certain tracer population mimicking a dwarf galaxy,
sample it with O(10^3) points to construct a mock kinematic dataset,
then launch a MCMC fit and show the results.
The fitted VDF is represented by a B-spline of degree 2 or 3 with nonnegative amplitudes.
&quot;&quot;&quot;
import sys, agama, numpy, matplotlib.pyplot as plt
numpy.random.seed(6)
addErrors = len(sys.argv)&gt;1

print('Creating mock kinematic dataset...')
# the units are needed only to create the mock kinematic dataset
agama.setUnits(length=1, velocity=1, mass=1)
pot = agama.Potential(type='nfw', mass=1e8, scaleradius=1)
df = agama.DistributionFunction(type='quasiisothermal', mass=1, rdisk=0.4, hdisk=0.2,
    sigmar0=5, rsigmar=1.0, sigmamin=1.0, jmin=0.5, qjr=0.4, potential=pot)
# take VDF from a spatial region centered on (x=0.5, z=0) with a radius 0.25
selfnc = lambda x: (x[:,0]-0.5)**2 + x[:,2]**2 &lt; 0.25**2
gm = agama.GalaxyModel(pot, df, sf=selfnc)
# sample a large number of points to construct a smooth &quot;true&quot; VDF,
# using the y-component of velocity (perpendicular to the sky plane, which is x,z in our case)
vlos_all = gm.sample(1000000)[0][:,4]
vmin = -15.0
vmax = +20.0
gridv_spline = numpy.linspace(vmin, vmax, 13)
log_vdf_true = agama.splineLogDensity(gridv_spline, vlos_all)
vdf_true = lambda x: numpy.exp(log_vdf_true(x))

# use a smaller subsample to create the mock catalogue
N = 500
vlos = vlos_all[numpy.random.choice(len(vlos_all), N)]
print('Mock dataset of %i stars created; mean v=%.2f, sigma=%.2f' % (N, numpy.mean(vlos), numpy.std(vlos)))
# assign individual measurement errors to each star, uniformly distributed between 2 and 4
if addErrors:
    vlos_err = numpy.random.random(size=N) * 2.0 + 2.0
else:
    vlos_err = numpy.zeros(N)
    print('Assuming no measurement errors; run the script with a non-empty command-line argument '
        'to add noise and run the fits with deconvolution (a few times slower)')
# add Gaussian noise to simulate measurement errors
vlos += numpy.random.normal(size=N) * vlos_err

# fit a K-th degree B-spline over the grid with ngrid points (K=2 or 3):
# such a function has ngrid+K-1 free parameters (amplitudes), but we fix the leftmost two and the rightmost two
# to be zero (i.e. the spline has zero value and zero derivative at endpoints), plus one more parameter
# is redundant because it is determined from the condition that the integral of the spline is unity.
ngrid = 11
degree = 3
nparams = ngrid + degree-1 - 4 - 1  # the actual number of free parameters in the fit
gridv_fit = numpy.linspace(vmin, vmax, ngrid)
# integrals of all basis functions, used to determine the &quot;redundant&quot; amplitude from the remaining ones
integ = agama.bsplineIntegrals(degree, gridv_fit)

def getampl(params):
    r&quot;&quot;&quot;
    Determine the full array of B-spline amplitudes from the provided array of parameters,
    from the condition  \sum_{k=1}^{N_ampl} integ_k ampl_k = 1.
    &quot;&quot;&quot;
    # the &quot;redundant&quot; amplutide is the one for the most central element
    amid = (1 - integ[2:2+nparams//2].dot(params[0:nparams//2]) -
        integ[3+nparams//2:3+nparams].dot(params[nparams//2:])) / integ[nparams//2+3]
    ampl = numpy.hstack([0, 0, params[0:nparams//2], amid, params[nparams//2:], 0, 0])
    return ampl

gridv_check = numpy.linspace(vmin, vmax, 200)
def loglikelihood(params):
    &quot;&quot;&quot;
    Construct the B-spline from the provided parameters and evaluate the log-likelihood of the dataset.
    &quot;&quot;&quot;
    ampl = getampl(params)
    spl = agama.Spline(gridv_fit, ampl=ampl)
    # one could enforce the amplitudes to be nonnegative, which guarantees that the interpolated function
    # is also nonnegative. However, only a weaker condition is actually needed, that the values of
    # the function at its extremal points are nonnegative; these are provided by the Spline class.
    if any(spl(spl.extrema()) &lt; 0):  # or any(ampl&lt;0):
        return -numpy.inf
    ll = numpy.sum(numpy.log(spl(vlos, conv=vlos_err)))
    if not numpy.isfinite(ll):
        ll = -numpy.inf
    return ll

import emcee
params = numpy.ones(nparams) * 0.1 / (vmax-vmin)
nwalkers = 2*nparams
nsteps = 1000
walkers  = numpy.empty((nwalkers, len(params)))
for i in range(nwalkers):
    while True:   # ensure that we initialize walkers with feasible values
        walker = numpy.array(params) + (numpy.random.normal(size=nparams)*0.001 if i&gt;0 else 0)
        prob = loglikelihood(walker)
        if numpy.isfinite(prob):
            walkers[i] = walker
            break
print('Start emcee...')
sampler = emcee.EnsembleSampler(nwalkers, len(params), loglikelihood)
prevmaxll  = -numpy.inf
prevmeanll = -numpy.inf
# perform several passes of length &quot;nsteps&quot;, monitoring the convergence of the MC chain
while True:
    sampler.run_mcmc(walkers, nsteps)
    chain = sampler.chain
    walkers = chain[:,-1]
    loglike = sampler.lnprobability
    currmaxll  = numpy.max (loglike[:,-nsteps:])
    currmeanll = numpy.mean(loglike[:,-nsteps:])
    params = chain[:,-nsteps:].reshape(-1, nparams)[numpy.argmax(loglike[:,-nsteps:].reshape(-1))]
    print('%i steps; log-likelihood max: %.1f, mean: %.1f' % (chain.shape[1], currmaxll, currmeanll))
    if abs(currmaxll-prevmaxll) &lt; 0.5 and abs(currmeanll-prevmeanll) &lt; 0.5:
        break
    prevmaxll  = currmaxll
    prevmeanll = currmeanll

# use the last section of the chain with &quot;nsteps&quot; to plot the results
lastchain = chain[:,-nsteps:].reshape(-1, nparams)
lastloglike = loglike[:,-nsteps:].reshape(-1)

print('Plotting MCMC chain...')
# plot the evolution of parameters along the chain
fig, axes = plt.subplots(nparams+1, 1, sharex=True, figsize=(20,15))
for i in range(nparams):
    axes[i].plot(chain[:,:,i].T, color='b', alpha=0.3)
# last panel shows the evolution of log-likelihood for the ensemble of walkers
axes[-1].plot(loglike.T, color='b', alpha=0.3)
axes[-1].set_ylabel('log(L)')
maxloglike = numpy.max(loglike)
axes[-1].set_ylim(maxloglike-max(nparams*2,20), maxloglike)   # restrict the range of log-likelihood arount its maximum
fig.tight_layout(h_pad=0.)
plt.subplots_adjust(hspace=0, wspace=0)
plt.savefig('example_vdf_fit_bspline_emcee_chain.png')
plt.close()

# plot the posterior distributions of parameters
import corner, scipy.special
corner.corner(lastchain, quantiles=[0.16, 0.5, 0.84], show_titles=True)
# overplot the distribution of values of log-likelihood and compare it with the expected chi^2 distribution
plt.axes([0.7,0.7,0.25,0.25])
gridll = numpy.linspace(-14,2,33)
histll = numpy.histogram(lastloglike - (currmeanll+nparams*0.5), bins=gridll, density=True)[0]
#     / (gridll[1]-gridll[0]) / len(lastloglike)
plt.plot(gridll.repeat(2)[1:-1], histll.repeat(2))
plt.plot(gridll, 1/scipy.special.gamma(0.5*nparams) * numpy.maximum(0,-gridll)**(0.5*nparams-1) *
    numpy.exp(gridll), 'r', lw=2)
plt.xlabel(r'$\ln L - \ln L_{\sf max}$')
plt.savefig('example_vdf_fit_bspline_emcee_corner.png')
plt.close()

# finally, plot the most interesting thing - the resulting VDF profiles with uncertainties
plt.figure(figsize=(8,6))
gridv_plot = numpy.linspace(vmin, vmax, 81)
plt.plot(gridv_plot, vdf_true(gridv_plot), label='true f(v)', c='b')
hist = numpy.histogram(vlos, bins=gridv_plot[::2], density=True)[0]
plt.plot(gridv_plot[::2].repeat(2)[1:-1], hist.repeat(2), c='r',
    label='observed%s' % (' (with errors)' if addErrors else ''))
plt.plot(gridv_fit, gridv_fit*0, 'ko')  # show the nodes of the B-spline
plt.xlim(vmin, vmax)
# draw nsamples realizations of parameters from the chain, and show the 16/84 percentile of resulting VDF profiles
nsamples = 500
profs = numpy.zeros((nsamples, len(gridv_plot)))
meanv, sigmav = numpy.zeros((2, nsamples))
# integrals of all basis functions weighted by v and v^2, used to determine the mean and dispersion of the VDFs
integ1 = agama.bsplineIntegrals(degree, gridv_fit, power=1)
integ2 = agama.bsplineIntegrals(degree, gridv_fit, power=2)
for i in range(nsamples):
    params = lastchain[numpy.random.choice(len(lastchain),1)][0]
    ampl = getampl(params)
    meanv [i] = integ1.dot(ampl) / integ.dot(ampl)
    sigmav[i] = (integ2.dot(ampl) / integ.dot(ampl) - meanv[i]**2)**0.5
    spl = agama.Spline(gridv_fit, ampl=ampl)
    profs[i] = spl(gridv_plot)
plt.fill_between(gridv_plot, numpy.percentile(profs, 16, axis=0), numpy.percentile(profs, 84, axis=0),
    alpha=0.5, color='g', lw=0)
plt.plot([numpy.nan], [numpy.nan], c='g', label='B-spline fit%s' % (' (deconvolved)' if addErrors else ''))
plt.legend(loc='upper left', frameon=False)
plt.text(0.98, 0.98, r'$\overline{v}=%.3f\pm%.3f$' % (numpy.mean(meanv), numpy.std(meanv)),
    ha='right', va='top', transform=plt.gca().transAxes)
plt.text(0.98, 0.92, r'$\sigma=%.3f\pm%.3f$' % (numpy.mean(sigmav), numpy.std(sigmav)),
    ha='right', va='top', transform=plt.gca().transAxes)

plt.savefig('example_vdf_fit_bspline_final_profiles.png')
plt.show()
</file>
    <file path="py/gc_resample.py">
#!/usr/bin/python
'''
This file is part of the Gaia Challenge, and contains the deprojection and resampling routine.
See gc_runfit.py for the overall description.

######################## SPHERICAL MODEL DEPROJECTION #########################
This module fills missing values for coordinate and velocity for the case of incomplete data.
On input, we have an array of particles with 9 parameters:
{x, y, [z?], [vx?], [vy?], [vz?], vx_err, vy_err, vz_err},
where [..?] denotes possibly missing data (denoted as NAN),
and velocities carry a Gaussian error with known dispersion (may be zero).
On output, an array of sub-samples and their weights is returned:
each particle is split into Nsamp sub-samples, where missing or imprecisely known data
are filled with randomly sampled values, so that in calculating the likelihood of a given
particle given a model, we sum up likelihoods of each of its subsamples with the provided
weights (this is essentially a Monte Carlo integration over the missing axes,
but always carried out using the same set of points for any model parameters, which
is necessary to remove sampling noise).
This random sampling may be uniform within a reasonable range (determined from the existing
input data), or according to some prior (in which case sub-sample weights will not be equal).
In case of missing z-coordinate, we construct a spherical deprojection of the density profile,
using the existing x- and y-coordinates, and sample the value of z-coordinate at each R
from this deprojected profile (thus having a non-uniform prior and placing sub-samples where
they are more likely to lie, that is, using a sort of importance sampling).
For missing velocity components, we sample from a heavy-tailed DF with a width estimated
from the known components of velocity of input points.

The spherical model deprojection is implemented in the class ``SphericalModel'',
and the resampling procedure -- in the routine ``sampleMissingData''
'''

import agama, numpy, scipy.integrate


class SphericalModel:
    '''
    Construct a spherically symmetric model using the information about projected particle positions;
    input: particles is a Nx(2 or more) array of coordinates, only the first two columns (x,y coordinates) are used
    '''
    def __init__(self, particles):
        Radii = (particles[:,0]**2 + particles[:,1]**2)**0.5
        Rmin,Rmax = numpy.percentile(Radii, [5, 95])
        GridSize  = max(int(round(numpy.log(len(Radii)))), 4)
        GridRadii = numpy.logspace(numpy.log10(Rmin), numpy.log10(Rmax), GridSize)
        self.spl_logSigma = agama.splineLogDensity(numpy.log(GridRadii), numpy.log(Radii), infLeft=True, infRight=True)

        def rho_integr(r):
            def integrand(xi):   # xi = ln(R)
                R2 = numpy.exp(2*xi)
                return numpy.exp(self.spl_logSigma(xi)) * (self.spl_logSigma(xi, 1)-2) / R2 / (R2-r**2)**0.5
            return -0.5 / numpy.pi**2 * scipy.integrate.quad(integrand, numpy.log(r), numpy.log(Radii[-1])+5., epsrel=1e-3)[0]

        # compute 3d density at the same radial grid
        rho_grid   = numpy.log([rho_integr(R) for R in GridRadii])
        good_elems = numpy.where(numpy.isfinite(rho_grid))[0]
        if(len(good_elems)&lt;len(rho_grid)):
            print(&quot;Invalid density encountered at r=&quot; + \
                str(GridRadii[numpy.where(numpy.logical_not(numpy.isfinite(rho_grid)))]))
        #print(numpy.column_stack((GridRadii, self.surface_density(GridRadii), numpy.exp(rho_grid))))
        rho_grid = rho_grid[good_elems]
        LogRadii = numpy.log(GridRadii[good_elems])

        # initialize an interpolating spline for 3d density (log-log scaled)
        spl_rho  = agama.Spline(LogRadii, rho_grid)
        # check and correct endpoint log-slopes, if necessary
        slopein  = spl_rho(LogRadii[0], 1)
        slopeout = spl_rho(LogRadii[-1],1)
        SlopeIn  = max(-2.0, min(0.0, slopein))
        SlopeOut = min(-3.5, slopeout)
        print(&quot;Density slope: inner=%f [%f], outer=%f [%f]&quot; % (SlopeIn, slopein, SlopeOut, slopeout))
        self.spl_rho = agama.Spline(LogRadii, rho_grid, left=SlopeIn, right=SlopeOut)

    def surface_density(self, R):
        ''' Return surface density Sigma(R) '''
        return numpy.exp(self.spl_logSigma(numpy.log(R))) / (2*numpy.pi*R**2)

    def rho(self, r):
        ''' Return 3d density rho(r) '''
        return numpy.exp(self.spl_rho(numpy.log(r)))



##################### RESAMPLING OF ORIGINAL DATA TO FILL MISSING VALUES #################

def sampleZPosition(R, sph_model):
    '''
    Sample the missing z-component of particle coordinates
    from the density distribution given by the spherical model.
    input argument 'R' contains the array of projected radii,
    and the output will contain the z-values assigned to them,
    and the weights of individual samples.
    '''
    print('Assigning missing z-component of position')
    rho_max = sph_model.rho(R) * 2.0
    R0      = numpy.maximum(2., R)
    result  = numpy.zeros_like(R)
    weights = sph_model.surface_density(R)
    indices = numpy.where(result==0)[0]   # index array initially containing all input points
    while len(indices)&gt;0:   # rejection sampling
        t = numpy.random.uniform(-1, 1, size=len(indices))
        z = R0[indices] * t/(1-t*t)**0.5
        rho = sph_model.rho( (R[indices]**2 + z**2)**0.5 )
        rho_bar = rho / (1-t*t)**1.5 / rho_max[indices]
        max_bar = numpy.amax(rho_bar)
        if max_bar&gt;1:
            rho_max *= max_bar
            rho_bar /= max_bar
            print('Overflow by %f' % max_bar)
        assigned = numpy.where(numpy.random.uniform(size=len(indices)) &lt; rho_bar)[0]
        #print('%i / %i' % (len(assigned), len(indices)))
        result [indices[assigned]]  = z[assigned]
        weights[indices[assigned]] /= rho[assigned]
        indices = numpy.where(result==0)[0]  # find out the unassigned elements
    return result, weights

def sampleMissingData(particles, Nsubsamples, fancy_z_assignment=True):
    '''
    Split each input particle into Nsamples samples, perturbing its velocity or
    assigning values for missing components of position/velocity.
    Input: particles -- array of Nx9 values (3 coordinates, 3 velocities, and 3 velocity errors),
    missing data (z, v_x, v_y, v_z) are indicated by NAN (may be different for each particle,
    but should have at least some particles with measured v_z, in order to estimate the velocity
    dispersion);
    Nsubsamples -- number of sub-samples created from each particle;
    fancy_z_assignment -- if True, use importance sampling for z-coordinate
    from a deprojected density profile; otherwise sample uniformly (not recommended)
    Return: two arrays -- NNx6 positions/velocities of subsamples and NN weights,
    where NN=len(particles)*Nsubsamples.
    '''
    numpy.random.seed(0)  # make resampling repeatable from run to run

    # duplicate the elements of the original particle array
    # (each particle is expanded into Nsubsamples identical samples)
    samples    = numpy.repeat(particles[:, 0:6], Nsubsamples, axis=0)
    nparticles = particles.shape[0]
    nsamples   = samples.shape[0]
    weights    = numpy.ones(nsamples, dtype=numpy.float64) / Nsubsamples
    vel_err    = particles[:, 6:9] if particles.shape[1]==9 else numpy.zeros((nparticles, 3))

    # compute maximum magnitude of distance and l.o.s. velocity used in assigning
    # missing z-coordinate and velocity components for resampled particles
    novz = numpy.isnan(particles[:,5])
    yesvz= numpy.logical_not(novz)
    novx = numpy.isnan(particles[:,3]+particles[:,4])
    yesvx= numpy.logical_not(novx)
    vmax = numpy.amax(numpy.abs(particles[yesvz,5]))
    vdisp= numpy.std(particles[yesvz,5])
    if not numpy.isfinite(vdisp):
        raise ValueError(&quot;No velocity (v_z) data!&quot;)
    Rmax = numpy.amax((particles[:,0]**2+particles[:,1]**2)**0.5)  # same here
    print('Resample %d input particles into %d internal samples (Rmax=%f, vmax=%f, sigma=%f)' % \
        (nparticles, nsamples, Rmax, vmax, vdisp))

    if numpy.any(numpy.isnan(samples[:,2])):   # z-coordinate is missing
        if fancy_z_assignment:  # use deprojection with unequal prior weights for resampled particles
            sph_model = SphericalModel(particles)
            samples_R = (samples[:,0]**2+samples[:,1]**2)**0.5
            samples[:,2], weights = sampleZPosition(samples_R, sph_model)
            weights  /= Nsubsamples
        else:                   # use uniformly distributed missing z component
            samples[:,2] = Rmax*numpy.random.uniform(-1, 1, size=nsamples)
            weights *= 2*Rmax

    # Sample missing vx,vy or add noise to existing measurements.
    # We sample the missing velocity components from a relatively heavy-tailed distribution
    # with the dispersion estimated from the known velocity (v_z) values.
    # Again, this is a kind of importance sampling with non-uniform weights assigned to the samples;
    # we use a heavy-tailed DF in order to reduce the Poisson noise from occasional (rare) outliers,
    # which are relatively more numerous (and hence less heavily weighted) in a heavy-tailed DF
    # compared to a Gaussian DF.
    # For particles with known (measured) components of velocity, these values are perturbed by
    # a Gaussian noise with the given dispersion (measurement errors), sampled with uniform weights.
    # Note that this would not be efficient if the errors (and measured values) are much larger than
    # the velocity dispersion -- in this case one would need to use importance sampling in order to
    # place more samples at smaller velocities, where we expect them to be located more probably.
    if numpy.any(novx):  # (some) vx,vy are missing
        sampnovx  = numpy.repeat(novx,  Nsubsamples)
        # resample vx,vy from a probability distribution ~ 1 / (vx^2+vy^2+1)^2
        cumul = numpy.random.uniform(0, 0.90, size=sum(sampnovx))  # 0 to 0.9 =&gt; 5.3-sigma region
        weights[sampnovx] *= (1-cumul)**-2
        vtrans_mag = 1.8 * vdisp * (cumul/(1-cumul))**0.5
        vtrans_ang = numpy.random.uniform(0, 2*numpy.pi, size=sum(sampnovx))
        samples[sampnovx,3] = vtrans_mag * numpy.cos(vtrans_ang)
        samples[sampnovx,4] = vtrans_mag * numpy.sin(vtrans_ang)
    if numpy.any(yesvx):
        sampyesvx = numpy.repeat(yesvx, Nsubsamples)
        samples[sampyesvx,3] += numpy.random.normal(size=sum(sampyesvx)) * numpy.repeat(vel_err[yesvx,0], Nsubsamples)
        samples[sampyesvx,4] += numpy.random.normal(size=sum(sampyesvx)) * numpy.repeat(vel_err[yesvx,1], Nsubsamples)
    # same for vz
    if numpy.any(novz):
        sampnovz  = numpy.repeat(novz,  Nsubsamples)
        # resample vz from Cauchy distribution
        cumul = numpy.random.uniform(0.05, 0.95, size=sum(sampnovz))  # +-6.3-sigma region
        value = numpy.tan( (cumul-0.5)*numpy.pi )
        weights[sampnovz] *= numpy.pi * (1 + value**2)
        samples[sampnovz,5] = value * vdisp
    if numpy.any(yesvz):
        sampyesvz = numpy.repeat(yesvz, Nsubsamples)
        samples[sampyesvz,5] += numpy.random.normal(size=sum(sampyesvz)) * numpy.repeat(vel_err[yesvz,2], Nsubsamples)

    return samples, weights/Nsubsamples
</file>
  </repository_files>
</compressed_repository>
